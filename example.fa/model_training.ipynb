{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acute-accreditation",
   "metadata": {},
   "source": [
    "# LDA Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "southeast-hampshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-pension",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "comparative-pointer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_no.</th>\n",
       "      <th>seq</th>\n",
       "      <th>module</th>\n",
       "      <th>motif_1</th>\n",
       "      <th>motif_2</th>\n",
       "      <th>motif_3</th>\n",
       "      <th>motif_4</th>\n",
       "      <th>motif_5</th>\n",
       "      <th>motif_string</th>\n",
       "      <th>motif_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GGAGGAGGAAGAGGCTGGGCCCCTGCTGTGTGGGGGCAAGTTCCCA...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_2,motif_3</td>\n",
       "      <td>[motif_2, motif_3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CAAATACCCTGGGGTGCAATACGACTTATATCTCACGTATTGGAAG...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "      <td>[motif_1, motif_4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AACTAGGACACAGAAGTTGATCTAACGTAAACATCAAGAGCTTCCT...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "      <td>[motif_1, motif_4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CACAGCTGGGCCTGGTTGGTCTTTGTCCAGGGAACAATGGAGCGCC...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "      <td>[motif_1, motif_4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>TTGTTTTATTTGTTTGTTGGGGGGCGGCGGGGAGCGACAGGGGAGT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_2,motif_3</td>\n",
       "      <td>[motif_2, motif_3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>CTATTATTAAGAAATATACACAATTTTAACTTCAAATATCTCTCAT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_2,motif_3</td>\n",
       "      <td>[motif_2, motif_3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>ATTGATTCTCACTTGCTTGACTCAAGGGAGGGTTTGATTTTGGTCA...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "      <td>[motif_1, motif_4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>ATGTGGTTCTACCATATAGTTTATCAATTTTAAACAGGTAAAATAT...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "      <td>[motif_1, motif_4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>ATTTTGTTGGTTAGGTGATGGAAGTATGATGCTATTGATATTTCCC...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>motif_2,motif_5</td>\n",
       "      <td>[motif_2, motif_5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>AAGGAAAAGTGAGGAAGTATGGCCATTCCTCTGATAGGACACAAGA...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "      <td>[motif_1, motif_4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    seq_no.                                                seq  module  \\\n",
       "0         0  GGAGGAGGAAGAGGCTGGGCCCCTGCTGTGTGGGGGCAAGTTCCCA...       0   \n",
       "1         1  CAAATACCCTGGGGTGCAATACGACTTATATCTCACGTATTGGAAG...       1   \n",
       "2         2  AACTAGGACACAGAAGTTGATCTAACGTAAACATCAAGAGCTTCCT...       1   \n",
       "3         3  CACAGCTGGGCCTGGTTGGTCTTTGTCCAGGGAACAATGGAGCGCC...       1   \n",
       "4         4  TTGTTTTATTTGTTTGTTGGGGGGCGGCGGGGAGCGACAGGGGAGT...       0   \n",
       "..      ...                                                ...     ...   \n",
       "995     995  CTATTATTAAGAAATATACACAATTTTAACTTCAAATATCTCTCAT...       0   \n",
       "996     996  ATTGATTCTCACTTGCTTGACTCAAGGGAGGGTTTGATTTTGGTCA...       1   \n",
       "997     997  ATGTGGTTCTACCATATAGTTTATCAATTTTAAACAGGTAAAATAT...       1   \n",
       "998     998  ATTTTGTTGGTTAGGTGATGGAAGTATGATGCTATTGATATTTCCC...       2   \n",
       "999     999  AAGGAAAAGTGAGGAAGTATGGCCATTCCTCTGATAGGACACAAGA...       1   \n",
       "\n",
       "     motif_1  motif_2  motif_3  motif_4  motif_5     motif_string  \\\n",
       "0        0.0      1.0      1.0      0.0      0.0  motif_2,motif_3   \n",
       "1        1.0      0.0      0.0      1.0      0.0  motif_1,motif_4   \n",
       "2        1.0      0.0      0.0      1.0      0.0  motif_1,motif_4   \n",
       "3        1.0      0.0      0.0      1.0      0.0  motif_1,motif_4   \n",
       "4        0.0      1.0      1.0      0.0      0.0  motif_2,motif_3   \n",
       "..       ...      ...      ...      ...      ...              ...   \n",
       "995      0.0      1.0      1.0      0.0      0.0  motif_2,motif_3   \n",
       "996      1.0      0.0      0.0      1.0      0.0  motif_1,motif_4   \n",
       "997      1.0      0.0      0.0      1.0      0.0  motif_1,motif_4   \n",
       "998      0.0      1.0      0.0      0.0      1.0  motif_2,motif_5   \n",
       "999      1.0      0.0      0.0      1.0      0.0  motif_1,motif_4   \n",
       "\n",
       "             motif_list  \n",
       "0    [motif_2, motif_3]  \n",
       "1    [motif_1, motif_4]  \n",
       "2    [motif_1, motif_4]  \n",
       "3    [motif_1, motif_4]  \n",
       "4    [motif_2, motif_3]  \n",
       "..                  ...  \n",
       "995  [motif_2, motif_3]  \n",
       "996  [motif_1, motif_4]  \n",
       "997  [motif_1, motif_4]  \n",
       "998  [motif_2, motif_5]  \n",
       "999  [motif_1, motif_4]  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file_path='DATA.pkl'\n",
    "data=pd.read_pickle(data_file_path)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "southern-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data[data['motif_string'].isna()])\n",
    "# data.dropna(subset=['motif_string'],inplace=True)\n",
    "# data['motif_list']=data['motif_string'].apply(lambda x:x.split(','))\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "concrete-freeze",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Motif-Index to Motif-Name Mapping:\n",
      "0 - motif_2\n",
      "1 - motif_3\n",
      "2 - motif_1\n",
      "3 - motif_4\n",
      "4 - motif_5\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "docs=data['motif_list'].values\n",
    "dictionary=Dictionary(docs)\n",
    "\n",
    "print('Motif-Index to Motif-Name Mapping:')\n",
    "for i,v in dictionary.items():\n",
    "    print(f'{i} - {v}')\n",
    "    if i==10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "renewable-particular",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW (Sequence-0):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['motif_2', 'motif_3'], [(0, 1), (1, 1)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(doc) for doc in docs]\n",
    "print('BOW (Sequence-0):')\n",
    "docs[0],corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-sampling",
   "metadata": {},
   "source": [
    "## Training Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "possible-residence",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-09 16:49:28,986 : INFO : using autotuned alpha, starting with [0.33333334, 0.33333334, 0.33333334]\n",
      "2021-03-09 16:49:28,987 : INFO : using serial LDA version on this node\n",
      "2021-03-09 16:49:29,007 : INFO : running online (multi-pass) LDA training, 3 topics, 5 passes over the supplied corpus of 1000 documents, updating model once every 1000 documents, evaluating perplexity every 1000 documents, iterating 1000x with a convergence threshold of 0.001000\n",
      "2021-03-09 16:49:29,008 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2021-03-09 16:49:29,011 : DEBUG : bound: at document #0\n",
      "2021-03-09 16:49:29,614 : INFO : -2.604 per-word bound, 6.1 perplexity estimate based on a held-out corpus of 1000 documents with 1976 words\n",
      "2021-03-09 16:49:29,615 : INFO : PROGRESS: pass 0, at document #1000/1000\n",
      "2021-03-09 16:49:29,616 : DEBUG : performing inference on a chunk of 1000 documents\n",
      "2021-03-09 16:49:30,231 : DEBUG : 1000/1000 documents converged within 1000 iterations\n",
      "2021-03-09 16:49:30,245 : INFO : optimized alpha [0.3966543, 0.2739079, 0.44297463]\n",
      "2021-03-09 16:49:30,246 : DEBUG : updating topics\n",
      "2021-03-09 16:49:30,246 : INFO : topic #0 (0.397): 0.540*\"motif_1\" + 0.411*\"motif_4\" + 0.022*\"motif_3\" + 0.021*\"motif_2\" + 0.006*\"motif_5\"\n",
      "2021-03-09 16:49:30,247 : INFO : topic #1 (0.274): 0.389*\"motif_1\" + 0.232*\"motif_3\" + 0.192*\"motif_4\" + 0.163*\"motif_2\" + 0.025*\"motif_5\"\n",
      "2021-03-09 16:49:30,248 : INFO : topic #2 (0.443): 0.431*\"motif_2\" + 0.391*\"motif_3\" + 0.133*\"motif_1\" + 0.032*\"motif_5\" + 0.014*\"motif_4\"\n",
      "2021-03-09 16:49:30,249 : INFO : topic diff=1.273417, rho=1.000000\n",
      "2021-03-09 16:49:30,258 : INFO : Epoch 0: Convergence estimate: 0.0\n",
      "2021-03-09 16:49:30,261 : DEBUG : bound: at document #0\n",
      "2021-03-09 16:49:30,519 : INFO : -1.612 per-word bound, 3.1 perplexity estimate based on a held-out corpus of 1000 documents with 1976 words\n",
      "2021-03-09 16:49:30,519 : INFO : PROGRESS: pass 1, at document #1000/1000\n",
      "2021-03-09 16:49:30,520 : DEBUG : performing inference on a chunk of 1000 documents\n",
      "2021-03-09 16:49:30,673 : DEBUG : 1000/1000 documents converged within 1000 iterations\n",
      "2021-03-09 16:49:30,677 : INFO : optimized alpha [0.42025125, 0.23103826, 0.47186857]\n",
      "2021-03-09 16:49:30,677 : DEBUG : updating topics\n",
      "2021-03-09 16:49:30,678 : INFO : topic #0 (0.420): 0.572*\"motif_1\" + 0.406*\"motif_4\" + 0.010*\"motif_3\" + 0.010*\"motif_2\" + 0.003*\"motif_5\"\n",
      "2021-03-09 16:49:30,679 : INFO : topic #1 (0.231): 0.413*\"motif_1\" + 0.225*\"motif_3\" + 0.177*\"motif_4\" + 0.158*\"motif_2\" + 0.027*\"motif_5\"\n",
      "2021-03-09 16:49:30,679 : INFO : topic #2 (0.472): 0.449*\"motif_2\" + 0.411*\"motif_3\" + 0.099*\"motif_1\" + 0.035*\"motif_5\" + 0.007*\"motif_4\"\n",
      "2021-03-09 16:49:30,681 : INFO : topic diff=0.279587, rho=0.577350\n",
      "2021-03-09 16:49:30,682 : INFO : Epoch 1: Convergence estimate: 0.0\n",
      "2021-03-09 16:49:30,685 : DEBUG : bound: at document #0\n",
      "2021-03-09 16:49:30,903 : INFO : -1.553 per-word bound, 2.9 perplexity estimate based on a held-out corpus of 1000 documents with 1976 words\n",
      "2021-03-09 16:49:30,903 : INFO : PROGRESS: pass 2, at document #1000/1000\n",
      "2021-03-09 16:49:30,904 : DEBUG : performing inference on a chunk of 1000 documents\n",
      "2021-03-09 16:49:31,046 : DEBUG : 1000/1000 documents converged within 1000 iterations\n",
      "2021-03-09 16:49:31,050 : INFO : optimized alpha [0.44208142, 0.20209204, 0.49231815]\n",
      "2021-03-09 16:49:31,051 : DEBUG : updating topics\n",
      "2021-03-09 16:49:31,051 : INFO : topic #0 (0.442): 0.590*\"motif_1\" + 0.397*\"motif_4\" + 0.006*\"motif_3\" + 0.005*\"motif_2\" + 0.002*\"motif_5\"\n",
      "2021-03-09 16:49:31,052 : INFO : topic #1 (0.202): 0.421*\"motif_1\" + 0.221*\"motif_3\" + 0.170*\"motif_4\" + 0.157*\"motif_2\" + 0.031*\"motif_5\"\n",
      "2021-03-09 16:49:31,053 : INFO : topic #2 (0.492): 0.461*\"motif_2\" + 0.424*\"motif_3\" + 0.075*\"motif_1\" + 0.037*\"motif_5\" + 0.004*\"motif_4\"\n",
      "2021-03-09 16:49:31,053 : INFO : topic diff=0.223639, rho=0.500000\n",
      "2021-03-09 16:49:31,055 : INFO : Epoch 2: Convergence estimate: 0.0\n",
      "2021-03-09 16:49:31,059 : DEBUG : bound: at document #0\n",
      "2021-03-09 16:49:31,263 : INFO : -1.517 per-word bound, 2.9 perplexity estimate based on a held-out corpus of 1000 documents with 1976 words\n",
      "2021-03-09 16:49:31,263 : INFO : PROGRESS: pass 3, at document #1000/1000\n",
      "2021-03-09 16:49:31,264 : DEBUG : performing inference on a chunk of 1000 documents\n",
      "2021-03-09 16:49:31,393 : DEBUG : 1000/1000 documents converged within 1000 iterations\n",
      "2021-03-09 16:49:31,397 : INFO : optimized alpha [0.46103016, 0.18136394, 0.5075902]\n",
      "2021-03-09 16:49:31,398 : DEBUG : updating topics\n",
      "2021-03-09 16:49:31,398 : INFO : topic #0 (0.461): 0.602*\"motif_1\" + 0.390*\"motif_4\" + 0.004*\"motif_3\" + 0.003*\"motif_2\" + 0.001*\"motif_5\"\n",
      "2021-03-09 16:49:31,399 : INFO : topic #1 (0.181): 0.421*\"motif_1\" + 0.218*\"motif_3\" + 0.167*\"motif_4\" + 0.157*\"motif_2\" + 0.037*\"motif_5\"\n",
      "2021-03-09 16:49:31,400 : INFO : topic #2 (0.508): 0.469*\"motif_2\" + 0.433*\"motif_3\" + 0.058*\"motif_1\" + 0.038*\"motif_5\" + 0.002*\"motif_4\"\n",
      "2021-03-09 16:49:31,401 : INFO : topic diff=0.193426, rho=0.447214\n",
      "2021-03-09 16:49:31,402 : INFO : Epoch 3: Convergence estimate: 0.0\n",
      "2021-03-09 16:49:31,406 : DEBUG : bound: at document #0\n",
      "2021-03-09 16:49:31,599 : INFO : -1.493 per-word bound, 2.8 perplexity estimate based on a held-out corpus of 1000 documents with 1976 words\n",
      "2021-03-09 16:49:31,600 : INFO : PROGRESS: pass 4, at document #1000/1000\n",
      "2021-03-09 16:49:31,600 : DEBUG : performing inference on a chunk of 1000 documents\n",
      "2021-03-09 16:49:31,728 : DEBUG : 1000/1000 documents converged within 1000 iterations\n",
      "2021-03-09 16:49:31,732 : INFO : optimized alpha [0.4772663, 0.16574262, 0.5194231]\n",
      "2021-03-09 16:49:31,733 : DEBUG : updating topics\n",
      "2021-03-09 16:49:31,734 : INFO : topic #0 (0.477): 0.609*\"motif_1\" + 0.385*\"motif_4\" + 0.002*\"motif_3\" + 0.002*\"motif_2\" + 0.001*\"motif_5\"\n",
      "2021-03-09 16:49:31,735 : INFO : topic #1 (0.166): 0.415*\"motif_1\" + 0.215*\"motif_3\" + 0.166*\"motif_4\" + 0.158*\"motif_2\" + 0.045*\"motif_5\"\n",
      "2021-03-09 16:49:31,736 : INFO : topic #2 (0.519): 0.476*\"motif_2\" + 0.439*\"motif_3\" + 0.046*\"motif_1\" + 0.038*\"motif_5\" + 0.002*\"motif_4\"\n",
      "2021-03-09 16:49:31,736 : INFO : topic diff=0.174079, rho=0.408248\n",
      "2021-03-09 16:49:31,738 : INFO : Epoch 4: Convergence estimate: 0.0\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 6084.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.89 s, sys: 43 ms, total: 2.93 s\n",
      "Wall time: 2.95 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import logging\n",
    "from gensim.models.callbacks import Callback,PerplexityMetric, ConvergenceMetric, CoherenceMetric\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.DEBUG)\n",
    "convergence_logger = ConvergenceMetric(logger='shell')\n",
    "from gensim.models import LdaModel,LdaMulticore\n",
    "\n",
    "temp = dictionary[0]\n",
    "id2word = dictionary.id2token\n",
    "lda = LdaModel(corpus, id2word=id2word, alpha='auto',chunksize=10000,\n",
    "               eta='auto',num_topics=3, iterations=1000, passes = 5,\n",
    "              minimum_probability=0.0,callbacks=[convergence_logger])\n",
    "\n",
    "lda_predictions=lda.get_document_topics(corpus,minimum_probability=0.0)\n",
    "lda_pred_topic=[]\n",
    "for pred in tqdm(lda_predictions):\n",
    "    top_topic=sorted(pred,key=lambda x:-x[1])[0][0]\n",
    "    lda_pred_topic.append(top_topic)\n",
    "lda_pred_data=data.copy()\n",
    "lda_pred_data['pred_topic']=lda_pred_topic\n",
    "\n",
    "logging.getLogger().setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-google",
   "metadata": {},
   "source": [
    "## Model Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bottom-equipment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.6094305),\n",
       " (3, 0.38511375),\n",
       " (1, 0.0023913234),\n",
       " (0, 0.0022632114),\n",
       " (4, 0.00080125243)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.get_topic_terms(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "exceptional-booth",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "194it [00:00, 1934.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.478, 1: 0, 2: 0.522}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:00, 2402.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1092.4173899022528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1092.4173899022528"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getTopicDistribution(pred_data,ntopics):\n",
    "    topic_dist_dict={i:0 for i in range(ntopics)}\n",
    "    value_count=pred_data['pred_topic'].value_counts(normalize=True)\n",
    "    for k,v in value_count.to_dict().items():\n",
    "        topic_dist_dict[k]=v\n",
    "    return topic_dist_dict\n",
    "\n",
    "def likelihoodMetric(model,pred_data,dictionary,ntopics):\n",
    "    likelihood=0\n",
    "    P_T=getTopicDistribution(pred_data,ntopics)\n",
    "    print(P_T)\n",
    "    for idx,row in tqdm(pred_data.iterrows()):\n",
    "        motif_list=dictionary.doc2idx(row['motif_list'])\n",
    "        assigned_topic_no=row['pred_topic']\n",
    "        P_Xi_M=0\n",
    "        for topic_no in range(ntopics):\n",
    "            ttd=model.get_topic_terms(topic_no)\n",
    "#             print(ttd)\n",
    "            filtered_ttd=list(filter(lambda x:x[0] in motif_list,ttd))\n",
    "            P_X_Ti=1\n",
    "            for motif,P_mj_T in filtered_ttd:\n",
    "                P_X_Ti*=P_mj_T\n",
    "            P_Xi_M+=P_X_Ti*P_T[topic_no]\n",
    "        likelihood+=np.log10(P_Xi_M)\n",
    "    print(likelihood)\n",
    "    return likelihood\n",
    "likelihoodMetric(lda,lda_pred_data,dictionary,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fitting-extreme",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getTopicDistribution(predictions,ntopics):\n",
    "#     topic_count_dict={i:0 for i in range(ntopics)}\n",
    "#     ndocs=len(predictions)\n",
    "#     for pred in predictions:\n",
    "#         top_topic=sorted(pred,key=lambda x:-x[1])[0][0]\n",
    "#         topic_count_dict[top_topic]+=1\n",
    "#     topic_dist_dict={k:v/ndocs for k,v in topic_count_dict.items()}\n",
    "#     print(topic_dist_dict)\n",
    "#     return topic_dist_dict\n",
    "\n",
    "# def likelihoodMetric(predictions,ntopics):\n",
    "#     likelihood=0\n",
    "#     P_T=getTopicDistribution(predictions,ntopics)\n",
    "# #     print(P_T)\n",
    "#     for pred in tqdm(predictions):\n",
    "#         P_Xi_M=0\n",
    "#         for topic_no,P_Xi_T in pred:\n",
    "#             P_Xi_M+=P_Xi_T*P_T[topic_no]\n",
    "#         likelihood+=np.log10(P_Xi_M)\n",
    "#     print(likelihood)\n",
    "#     return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "macro-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "def coherenceMetric_cv(model,dictionary,docs):\n",
    "    cm=CoherenceModel(model=model,dictionary=dictionary ,\n",
    "                      texts=docs, coherence='c_v',processes=30,\n",
    "                     window_size=2000)\n",
    "    coherence = cm.get_coherence()\n",
    "    print(coherence)\n",
    "    return coherence\n",
    "# coherenceMetric_cv(lda,dictionary ,docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "rural-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "def coherenceMetric_umass(model,dictionary,corpus):\n",
    "    cm = CoherenceModel(model=model, corpus=corpus, \\\n",
    "                        coherence='u_mass',processes=30)\n",
    "    coherence = cm.get_coherence()\n",
    "    print(coherence)\n",
    "    return coherence\n",
    "# coherenceMetric_umass(lda,dictionary ,corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "burning-scenario",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-12.292968805048053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-12.292968805048053"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "def coherenceMetric_uci(model,dictionary,docs):\n",
    "    cm=CoherenceModel(model=model,dictionary=dictionary ,\n",
    "                      texts=docs, coherence='c_uci',processes=30,\n",
    "                     window_size =2000)\n",
    "    coherence = cm.get_coherence()\n",
    "    print(coherence)\n",
    "    return coherence\n",
    "coherenceMetric_uci(lda,dictionary ,docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "induced-penetration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexityMetric(model,corpus):\n",
    "    perplexity=model.log_perplexity(corpus)\n",
    "    print(perplexity)\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "stretch-satellite",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "\n",
    "def randIndexMetric(predictions,data):\n",
    "    pred_topic=[]\n",
    "    for pred in tqdm(predictions):\n",
    "        topic_prob=sorted(pred,key=lambda x:-x[1])\n",
    "#         print(topic_prob)\n",
    "        top_topic=topic_prob[0][0]\n",
    "        pred_topic.append(top_topic)\n",
    "    _data=data.copy()\n",
    "    _data['pred_topic']=pred_topic\n",
    "    ari=adjusted_rand_score(_data['module'], _data['pred_topic'])\n",
    "    print(ari)\n",
    "    return ari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "characteristic-retreat",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def findTopMotifs(pred_data,ntopics,ntop=5,outdir=None):     \n",
    "    gb=pred_data[['motif_string','pred_topic']].groupby('pred_topic').\\\n",
    "    agg(lambda x: ','.join(x))\n",
    "    gb['top_motif']=gb['motif_string'].\\\n",
    "    apply(lambda x:Counter(x.split(',')).most_common(ntop))\n",
    "    gb.reset_index(inplace=True)\n",
    "    gb=gb[['pred_topic','top_motif']]\n",
    "    if outdir is not None:\n",
    "        gb.to_csv(f'{outdir}/top{ntop}_motifs_topics_{ntopics}.csv',index=False)\n",
    "    print(gb)\n",
    "    return gb\n",
    "# findTopMotifs(lda_pred_data,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-argument",
   "metadata": {},
   "source": [
    "## Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "south-desperate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Num of Topics = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 5116.47it/s]\n",
      "267it [00:00, 2668.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding likelihood...\n",
      "{0: 0.481, 1: 0.519}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:00, 2647.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1115.2293026321174\n",
      "\n",
      "Finding coherence_cv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22450482415521444\n",
      "\n",
      "Finding coherence_umass...\n",
      "-13.792294337173225\n",
      "\n",
      "Finding coherence_uci...\n",
      "-12.292968805048053\n",
      "\n",
      "Finding perplexity...\n",
      "-1.4222376219143993\n",
      "\n",
      "Finding Top Motifs...\n",
      "   pred_topic                                          top_motif\n",
      "0           0     [(motif_1, 478), (motif_4, 343), (motif_5, 3)]\n",
      "1           1  [(motif_2, 519), (motif_3, 480), (motif_1, 114...\n",
      "\n",
      "========================================\n",
      "Num of Topics = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 3427.22it/s]\n",
      "230it [00:00, 2290.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding likelihood...\n",
      "{0: 0.522, 1: 0.135, 2: 0.343}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:00, 2513.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1187.0911612814077\n",
      "\n",
      "Finding coherence_cv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22450482415521444\n",
      "\n",
      "Finding coherence_umass...\n",
      "-13.894599967488512\n",
      "\n",
      "Finding coherence_uci...\n",
      "-12.292968805048053\n",
      "\n",
      "Finding perplexity...\n",
      "-1.532063183031584\n",
      "\n",
      "Finding Top Motifs...\n",
      "   pred_topic                                          top_motif\n",
      "0           0  [(motif_2, 519), (motif_3, 480), (motif_1, 114...\n",
      "1           1                                   [(motif_1, 135)]\n",
      "2           2                   [(motif_1, 343), (motif_4, 343)]\n",
      "\n",
      "========================================\n",
      "Num of Topics = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 3798.32it/s]\n",
      "428it [00:00, 1978.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding likelihood...\n",
      "{0: 0.478, 1: 0.48, 2: 0, 3: 0.042}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:00, 1934.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1186.3800143385113\n",
      "\n",
      "Finding coherence_cv...\n",
      "0.2245048241552145\n",
      "\n",
      "Finding coherence_umass...\n",
      "-13.813003008973224\n",
      "\n",
      "Finding coherence_uci...\n",
      "-12.292968805048053\n",
      "\n",
      "Finding perplexity...\n",
      "-1.5200592862641975\n",
      "\n",
      "Finding Top Motifs...\n",
      "   pred_topic                                         top_motif\n",
      "0           0                  [(motif_1, 478), (motif_4, 343)]\n",
      "1           1  [(motif_2, 480), (motif_3, 480), (motif_1, 114)]\n",
      "2           3                    [(motif_5, 42), (motif_2, 39)]\n",
      "\n",
      "========================================\n",
      "Num of Topics = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 4442.81it/s]\n",
      "524it [00:00, 2562.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding likelihood...\n",
      "{0: 0.112, 1: 0.042, 2: 0.001, 3: 0.367, 4: 0.478}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:00, 2298.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1107.6002348155819\n",
      "\n",
      "Finding coherence_cv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22450482415521447\n",
      "\n",
      "Finding coherence_umass...\n",
      "-13.776889051478008\n",
      "\n",
      "Finding coherence_uci...\n",
      "-12.292968805048053\n",
      "\n",
      "Finding perplexity...\n",
      "-1.6768657571451384\n",
      "\n",
      "Finding Top Motifs...\n",
      "   pred_topic                                         top_motif\n",
      "0           0  [(motif_1, 112), (motif_2, 112), (motif_3, 112)]\n",
      "1           1                    [(motif_5, 42), (motif_2, 39)]\n",
      "2           2                      [(motif_2, 1), (motif_3, 1)]\n",
      "3           3    [(motif_2, 367), (motif_3, 367), (motif_1, 2)]\n",
      "4           4                  [(motif_1, 478), (motif_4, 343)]\n",
      "\n",
      "========================================\n",
      "Num of Topics = 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 2686.23it/s]\n",
      "300it [00:00, 1489.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding likelihood...\n",
      "{0: 0.343, 1: 0, 2: 0.042, 3: 0.434, 4: 0.135, 5: 0.046}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:00, 1526.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1173.969833803714\n",
      "\n",
      "Finding coherence_cv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22450482415521447\n",
      "\n",
      "Finding coherence_umass...\n",
      "-13.81250466842699\n",
      "\n",
      "Finding coherence_uci...\n",
      "-12.292968805048053\n",
      "\n",
      "Finding perplexity...\n",
      "-1.8287697968672705\n",
      "\n",
      "Finding Top Motifs...\n",
      "   pred_topic                                         top_motif\n",
      "0           0                  [(motif_1, 343), (motif_4, 343)]\n",
      "1           2                    [(motif_5, 42), (motif_2, 39)]\n",
      "2           3  [(motif_2, 434), (motif_3, 434), (motif_1, 107)]\n",
      "3           4                                  [(motif_1, 135)]\n",
      "4           5      [(motif_2, 46), (motif_3, 46), (motif_1, 7)]\n",
      "\n",
      "========================================\n",
      "Num of Topics = 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 2993.86it/s]\n",
      "382it [00:00, 1908.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding likelihood...\n",
      "{0: 0.186, 1: 0.042, 2: 0.23, 3: 0.342, 4: 0.001, 5: 0.064, 6: 0.135}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:00, 1630.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1135.7891378358813\n",
      "\n",
      "Finding coherence_cv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22450482415521447\n",
      "\n",
      "Finding coherence_umass...\n",
      "-13.72232954018428\n",
      "\n",
      "Finding coherence_uci...\n",
      "-12.292968805048051\n",
      "\n",
      "Finding perplexity...\n",
      "-1.9121518351273377\n",
      "\n",
      "Finding Top Motifs...\n",
      "   pred_topic                                        top_motif\n",
      "0           0  [(motif_2, 186), (motif_3, 186), (motif_1, 10)]\n",
      "1           1                   [(motif_5, 42), (motif_2, 39)]\n",
      "2           2  [(motif_2, 230), (motif_3, 230), (motif_1, 40)]\n",
      "3           3                 [(motif_1, 342), (motif_4, 342)]\n",
      "4           4                     [(motif_1, 1), (motif_4, 1)]\n",
      "5           5    [(motif_1, 64), (motif_2, 64), (motif_3, 64)]\n",
      "6           6                                 [(motif_1, 135)]\n",
      "\n",
      "========================================\n",
      "Num of Topics = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 4864.41it/s]\n",
      "400it [00:00, 1829.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding likelihood...\n",
      "{0: 0, 1: 0.478, 2: 0.366, 3: 0, 4: 0, 5: 0.114, 6: 0, 7: 0.042}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:00, 1832.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1095.2703647158364\n",
      "\n",
      "Finding coherence_cv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22450482415521444\n",
      "\n",
      "Finding coherence_umass...\n",
      "-13.865865181765843\n",
      "\n",
      "Finding coherence_uci...\n",
      "-12.292968805048053\n",
      "\n",
      "Finding perplexity...\n",
      "-1.8431932463080656\n",
      "\n",
      "Finding Top Motifs...\n",
      "   pred_topic                                         top_motif\n",
      "0           1                  [(motif_1, 478), (motif_4, 343)]\n",
      "1           2                  [(motif_2, 366), (motif_3, 366)]\n",
      "2           5  [(motif_1, 114), (motif_2, 114), (motif_3, 114)]\n",
      "3           7                    [(motif_5, 42), (motif_2, 39)]\n",
      "\n",
      "========================================\n",
      "Num of Topics = 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 4552.96it/s]\n",
      "390it [00:00, 1894.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding likelihood...\n",
      "{0: 0.044, 1: 0.049, 2: 0, 3: 0.387, 4: 0.135, 5: 0.042, 6: 0.11, 7: 0.233, 8: 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:00, 1753.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1143.98340634628\n",
      "\n",
      "Finding coherence_cv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22450482415521444\n",
      "\n",
      "Finding coherence_umass...\n",
      "-13.851133946774283\n",
      "\n",
      "Finding coherence_uci...\n",
      "-12.292968805048053\n",
      "\n",
      "Finding perplexity...\n",
      "-2.007941265518849\n",
      "\n",
      "Finding Top Motifs...\n",
      "   pred_topic                                        top_motif\n",
      "0           0    [(motif_1, 44), (motif_2, 44), (motif_3, 44)]\n",
      "1           1    [(motif_1, 49), (motif_2, 49), (motif_3, 49)]\n",
      "2           3  [(motif_2, 387), (motif_3, 387), (motif_1, 21)]\n",
      "3           4                                 [(motif_1, 135)]\n",
      "4           5                   [(motif_5, 42), (motif_2, 39)]\n",
      "5           6                 [(motif_1, 110), (motif_4, 110)]\n",
      "6           7                 [(motif_1, 233), (motif_4, 233)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_topics</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>coherence_cv</th>\n",
       "      <th>coherence_umass</th>\n",
       "      <th>coherence_uci</th>\n",
       "      <th>perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>-1115.229303</td>\n",
       "      <td>0.224505</td>\n",
       "      <td>-13.792294</td>\n",
       "      <td>-12.292969</td>\n",
       "      <td>-1.422238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>-1187.091161</td>\n",
       "      <td>0.224505</td>\n",
       "      <td>-13.894600</td>\n",
       "      <td>-12.292969</td>\n",
       "      <td>-1.532063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>-1186.380014</td>\n",
       "      <td>0.224505</td>\n",
       "      <td>-13.813003</td>\n",
       "      <td>-12.292969</td>\n",
       "      <td>-1.520059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>-1107.600235</td>\n",
       "      <td>0.224505</td>\n",
       "      <td>-13.776889</td>\n",
       "      <td>-12.292969</td>\n",
       "      <td>-1.676866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>-1173.969834</td>\n",
       "      <td>0.224505</td>\n",
       "      <td>-13.812505</td>\n",
       "      <td>-12.292969</td>\n",
       "      <td>-1.828770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>-1135.789138</td>\n",
       "      <td>0.224505</td>\n",
       "      <td>-13.722330</td>\n",
       "      <td>-12.292969</td>\n",
       "      <td>-1.912152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>-1095.270365</td>\n",
       "      <td>0.224505</td>\n",
       "      <td>-13.865865</td>\n",
       "      <td>-12.292969</td>\n",
       "      <td>-1.843193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>-1143.983406</td>\n",
       "      <td>0.224505</td>\n",
       "      <td>-13.851134</td>\n",
       "      <td>-12.292969</td>\n",
       "      <td>-2.007941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_topics   likelihood  coherence_cv  coherence_umass  coherence_uci  \\\n",
       "0           2 -1115.229303      0.224505       -13.792294     -12.292969   \n",
       "1           3 -1187.091161      0.224505       -13.894600     -12.292969   \n",
       "2           4 -1186.380014      0.224505       -13.813003     -12.292969   \n",
       "3           5 -1107.600235      0.224505       -13.776889     -12.292969   \n",
       "4           6 -1173.969834      0.224505       -13.812505     -12.292969   \n",
       "5           7 -1135.789138      0.224505       -13.722330     -12.292969   \n",
       "6           8 -1095.270365      0.224505       -13.865865     -12.292969   \n",
       "7           9 -1143.983406      0.224505       -13.851134     -12.292969   \n",
       "\n",
       "   perplexity  \n",
       "0   -1.422238  \n",
       "1   -1.532063  \n",
       "2   -1.520059  \n",
       "3   -1.676866  \n",
       "4   -1.828770  \n",
       "5   -1.912152  \n",
       "6   -1.843193  \n",
       "7   -2.007941  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from gensim.models import LdaModel,LdaMulticore\n",
    "\n",
    "outdir='model_output'\n",
    "eval_dict={'num_topics':[],'likelihood':[],'coherence_cv':[],\\\n",
    "          'coherence_umass':[],'coherence_uci':[],'perplexity':[]}\n",
    "temp = dictionary[0]\n",
    "id2word = dictionary.id2token\n",
    "for ntopics in range(2,10):\n",
    "    print('\\n'+'='*40)\n",
    "    print('Num of Topics = '+str(ntopics))\n",
    "    model = LdaModel(corpus, id2word=id2word, alpha='auto',chunksize=10000,\n",
    "                   eta='auto',num_topics=ntopics, iterations=1000, passes = 5,\n",
    "                  minimum_probability=0.0)\n",
    "    \n",
    "    predictions=model.get_document_topics(corpus,minimum_probability=0.0)\n",
    "    pred_topic=[]\n",
    "    for pred in tqdm(predictions):\n",
    "        top_topic=sorted(pred,key=lambda x:-x[1])[0][0]\n",
    "        pred_topic.append(top_topic)\n",
    "    pred_data=data.copy()\n",
    "    pred_data['pred_topic']=pred_topic\n",
    "    print('\\nFinding likelihood...')\n",
    "#     likelihood=likelihoodMetric(pred_data,predictions,ntopics)\n",
    "    likelihood=likelihoodMetric(model,pred_data,dictionary,ntopics)\n",
    "    print('\\nFinding coherence_cv...')\n",
    "    coherence_cv=coherenceMetric_cv(model,dictionary,docs)\n",
    "    print('\\nFinding coherence_umass...')\n",
    "    coherence_umass=coherenceMetric_umass(model,dictionary ,corpus)\n",
    "    print('\\nFinding coherence_uci...')\n",
    "    coherence_uci=coherenceMetric_uci(model,dictionary,docs)\n",
    "    print('\\nFinding perplexity...')\n",
    "    perplexity=perplexityMetric(model,corpus)\n",
    "    print('\\nFinding Top Motifs...')\n",
    "    findTopMotifs(pred_data,ntopics,outdir=outdir)\n",
    "#     print('\\nFindng avg. distance from TSS per topic...')\n",
    "#     getAvgTssDist(pred_data,ntopics,outdir=outdir)\n",
    "    eval_dict['num_topics'].append(ntopics)\n",
    "    eval_dict['likelihood'].append(likelihood)\n",
    "    eval_dict['coherence_cv'].append(coherence_cv)\n",
    "    eval_dict['coherence_umass'].append(coherence_umass)\n",
    "    eval_dict['coherence_uci'].append(coherence_uci)\n",
    "    eval_dict['perplexity'].append(perplexity)\n",
    "eval_df=pd.DataFrame(eval_dict)\n",
    "eval_df.to_csv(f'{outdir}/metrics.csv',index=False)\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "assisted-diesel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(eval_df['num_topics'],eval_df['likelihood'],marker='o')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "unlikely-accommodation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #setup logging for trainging metrics \n",
    "# import logging\n",
    "# logging.basicConfig(filename='test_output/model_callbacks.log', filemode='w',\n",
    "#                     format=\"%(asctime)s:%(levelname)s:%(message)s\",\n",
    "#                     level=logging.NOTSET)\n",
    "\n",
    "# from gensim.models.callbacks import Callback,PerplexityMetric, ConvergenceMetric, CoherenceMetric\n",
    "# perplexity_logger = PerplexityMetric(corpus=corpus, logger='shell')\n",
    "# convergence_logger = ConvergenceMetric(logger='shell')\n",
    "# # coherence_cv_logger = CoherenceMetric(corpus=corpus, coherence = 'c_v', texts = docs)\n",
    "\n",
    "# %%time\n",
    "# from gensim.models import LdaModel,LdaMulticore\n",
    "\n",
    "# #HYPERPARAMETERS\n",
    "# #passes = epochs\n",
    "# temp = dictionary[0]\n",
    "# id2word = dictionary.id2token\n",
    "# lda = LdaModel(corpus, id2word=id2word, alpha='auto',eval_every = 1,\\\n",
    "#                eta='auto',num_topics=3, iterations=5, passes = 10,\n",
    "#               callbacks=[perplexity_logger,convergence_logger])\n",
    "\n",
    "# lda.print_topics()\n",
    "\n",
    "# %%time\n",
    "# from gensim.models import LdaModel,LdaMulticore\n",
    "\n",
    "# id2word = dictionary.id2token\n",
    "# lda = LdaMulticore(corpus, id2word=id2word,eval_every = 1,\\\n",
    "#                eta='auto',num_topics=3, iterations=500, passes = 100)\n",
    "\n",
    "# import pyLDAvis.gensim\n",
    "\n",
    "# pyLDAvis.enable_notebook()\n",
    "# pyLDAvis.gensim.prepare(lda, corpus, dictionary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
