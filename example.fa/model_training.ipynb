{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acute-accreditation",
   "metadata": {},
   "source": [
    "# LDA Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "southeast-hampshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-pension",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "downtown-phrase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_no.</th>\n",
       "      <th>seq</th>\n",
       "      <th>module</th>\n",
       "      <th>motif_1</th>\n",
       "      <th>motif_2</th>\n",
       "      <th>motif_3</th>\n",
       "      <th>motif_4</th>\n",
       "      <th>motif_5</th>\n",
       "      <th>motif_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GGAGGAGGAAGAGGCTGGGCCCCTGCTGTGTGGGGGCAAGTTCCCA...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_2,motif_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CAAATACCCTGGGGTGCAATACGACTTATATCTCACGTATTGGAAG...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AACTAGGACACAGAAGTTGATCTAACGTAAACATCAAGAGCTTCCT...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CACAGCTGGGCCTGGTTGGTCTTTGTCCAGGGAACAATGGAGCGCC...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>TTGTTTTATTTGTTTGTTGGGGGGCGGCGGGGAGCGACAGGGGAGT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_2,motif_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>CTATTATTAAGAAATATACACAATTTTAACTTCAAATATCTCTCAT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_2,motif_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>ATTGATTCTCACTTGCTTGACTCAAGGGAGGGTTTGATTTTGGTCA...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>ATGTGGTTCTACCATATAGTTTATCAATTTTAAACAGGTAAAATAT...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>ATTTTGTTGGTTAGGTGATGGAAGTATGATGCTATTGATATTTCCC...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>motif_2,motif_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>AAGGAAAAGTGAGGAAGTATGGCCATTCCTCTGATAGGACACAAGA...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     seq_no.                                                seq  module  \\\n",
       "0          0  GGAGGAGGAAGAGGCTGGGCCCCTGCTGTGTGGGGGCAAGTTCCCA...       0   \n",
       "1          1  CAAATACCCTGGGGTGCAATACGACTTATATCTCACGTATTGGAAG...       1   \n",
       "2          2  AACTAGGACACAGAAGTTGATCTAACGTAAACATCAAGAGCTTCCT...       1   \n",
       "3          3  CACAGCTGGGCCTGGTTGGTCTTTGTCCAGGGAACAATGGAGCGCC...       1   \n",
       "4          4  TTGTTTTATTTGTTTGTTGGGGGGCGGCGGGGAGCGACAGGGGAGT...       0   \n",
       "..       ...                                                ...     ...   \n",
       "995      995  CTATTATTAAGAAATATACACAATTTTAACTTCAAATATCTCTCAT...       0   \n",
       "996      996  ATTGATTCTCACTTGCTTGACTCAAGGGAGGGTTTGATTTTGGTCA...       1   \n",
       "997      997  ATGTGGTTCTACCATATAGTTTATCAATTTTAAACAGGTAAAATAT...       1   \n",
       "998      998  ATTTTGTTGGTTAGGTGATGGAAGTATGATGCTATTGATATTTCCC...       2   \n",
       "999      999  AAGGAAAAGTGAGGAAGTATGGCCATTCCTCTGATAGGACACAAGA...       1   \n",
       "\n",
       "     motif_1  motif_2  motif_3  motif_4  motif_5     motif_string  \n",
       "0        0.0      1.0      1.0      0.0      0.0  motif_2,motif_3  \n",
       "1        1.0      0.0      0.0      1.0      0.0  motif_1,motif_4  \n",
       "2        1.0      0.0      0.0      1.0      0.0  motif_1,motif_4  \n",
       "3        1.0      0.0      0.0      1.0      0.0  motif_1,motif_4  \n",
       "4        0.0      1.0      1.0      0.0      0.0  motif_2,motif_3  \n",
       "..       ...      ...      ...      ...      ...              ...  \n",
       "995      0.0      1.0      1.0      0.0      0.0  motif_2,motif_3  \n",
       "996      1.0      0.0      0.0      1.0      0.0  motif_1,motif_4  \n",
       "997      1.0      0.0      0.0      1.0      0.0  motif_1,motif_4  \n",
       "998      0.0      1.0      0.0      0.0      1.0  motif_2,motif_5  \n",
       "999      1.0      0.0      0.0      0.0      0.0          motif_1  \n",
       "\n",
       "[1000 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file_path='DATA.csv'\n",
    "data=pd.read_csv(data_file_path)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "southern-oracle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [seq_no., seq, module, motif_1, motif_2, motif_3, motif_4, motif_5, motif_string]\n",
      "Index: []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_no.</th>\n",
       "      <th>seq</th>\n",
       "      <th>module</th>\n",
       "      <th>motif_1</th>\n",
       "      <th>motif_2</th>\n",
       "      <th>motif_3</th>\n",
       "      <th>motif_4</th>\n",
       "      <th>motif_5</th>\n",
       "      <th>motif_string</th>\n",
       "      <th>motif_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GGAGGAGGAAGAGGCTGGGCCCCTGCTGTGTGGGGGCAAGTTCCCA...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_2,motif_3</td>\n",
       "      <td>[motif_2, motif_3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CAAATACCCTGGGGTGCAATACGACTTATATCTCACGTATTGGAAG...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "      <td>[motif_1, motif_4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AACTAGGACACAGAAGTTGATCTAACGTAAACATCAAGAGCTTCCT...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "      <td>[motif_1, motif_4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CACAGCTGGGCCTGGTTGGTCTTTGTCCAGGGAACAATGGAGCGCC...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "      <td>[motif_1, motif_4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>TTGTTTTATTTGTTTGTTGGGGGGCGGCGGGGAGCGACAGGGGAGT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_2,motif_3</td>\n",
       "      <td>[motif_2, motif_3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>CTATTATTAAGAAATATACACAATTTTAACTTCAAATATCTCTCAT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_2,motif_3</td>\n",
       "      <td>[motif_2, motif_3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>ATTGATTCTCACTTGCTTGACTCAAGGGAGGGTTTGATTTTGGTCA...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "      <td>[motif_1, motif_4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>ATGTGGTTCTACCATATAGTTTATCAATTTTAAACAGGTAAAATAT...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "      <td>[motif_1, motif_4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>ATTTTGTTGGTTAGGTGATGGAAGTATGATGCTATTGATATTTCCC...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>motif_2,motif_5</td>\n",
       "      <td>[motif_2, motif_5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>AAGGAAAAGTGAGGAAGTATGGCCATTCCTCTGATAGGACACAAGA...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1</td>\n",
       "      <td>[motif_1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     seq_no.                                                seq  module  \\\n",
       "0          0  GGAGGAGGAAGAGGCTGGGCCCCTGCTGTGTGGGGGCAAGTTCCCA...       0   \n",
       "1          1  CAAATACCCTGGGGTGCAATACGACTTATATCTCACGTATTGGAAG...       1   \n",
       "2          2  AACTAGGACACAGAAGTTGATCTAACGTAAACATCAAGAGCTTCCT...       1   \n",
       "3          3  CACAGCTGGGCCTGGTTGGTCTTTGTCCAGGGAACAATGGAGCGCC...       1   \n",
       "4          4  TTGTTTTATTTGTTTGTTGGGGGGCGGCGGGGAGCGACAGGGGAGT...       0   \n",
       "..       ...                                                ...     ...   \n",
       "995      995  CTATTATTAAGAAATATACACAATTTTAACTTCAAATATCTCTCAT...       0   \n",
       "996      996  ATTGATTCTCACTTGCTTGACTCAAGGGAGGGTTTGATTTTGGTCA...       1   \n",
       "997      997  ATGTGGTTCTACCATATAGTTTATCAATTTTAAACAGGTAAAATAT...       1   \n",
       "998      998  ATTTTGTTGGTTAGGTGATGGAAGTATGATGCTATTGATATTTCCC...       2   \n",
       "999      999  AAGGAAAAGTGAGGAAGTATGGCCATTCCTCTGATAGGACACAAGA...       1   \n",
       "\n",
       "     motif_1  motif_2  motif_3  motif_4  motif_5     motif_string  \\\n",
       "0        0.0      1.0      1.0      0.0      0.0  motif_2,motif_3   \n",
       "1        1.0      0.0      0.0      1.0      0.0  motif_1,motif_4   \n",
       "2        1.0      0.0      0.0      1.0      0.0  motif_1,motif_4   \n",
       "3        1.0      0.0      0.0      1.0      0.0  motif_1,motif_4   \n",
       "4        0.0      1.0      1.0      0.0      0.0  motif_2,motif_3   \n",
       "..       ...      ...      ...      ...      ...              ...   \n",
       "995      0.0      1.0      1.0      0.0      0.0  motif_2,motif_3   \n",
       "996      1.0      0.0      0.0      1.0      0.0  motif_1,motif_4   \n",
       "997      1.0      0.0      0.0      1.0      0.0  motif_1,motif_4   \n",
       "998      0.0      1.0      0.0      0.0      1.0  motif_2,motif_5   \n",
       "999      1.0      0.0      0.0      0.0      0.0          motif_1   \n",
       "\n",
       "             motif_list  \n",
       "0    [motif_2, motif_3]  \n",
       "1    [motif_1, motif_4]  \n",
       "2    [motif_1, motif_4]  \n",
       "3    [motif_1, motif_4]  \n",
       "4    [motif_2, motif_3]  \n",
       "..                  ...  \n",
       "995  [motif_2, motif_3]  \n",
       "996  [motif_1, motif_4]  \n",
       "997  [motif_1, motif_4]  \n",
       "998  [motif_2, motif_5]  \n",
       "999           [motif_1]  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data[data['motif_string'].isna()])\n",
    "data.dropna(subset=['motif_string'],inplace=True)\n",
    "data['motif_list']=data['motif_string'].apply(lambda x:x.split(','))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "concrete-freeze",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Motif-Index to Motif-Name Mapping:\n",
      "0 - motif_2\n",
      "1 - motif_3\n",
      "2 - motif_1\n",
      "3 - motif_4\n",
      "4 - motif_5\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "docs=data['motif_list'].values\n",
    "dictionary=Dictionary(docs)\n",
    "\n",
    "print('Motif-Index to Motif-Name Mapping:')\n",
    "for i,v in dictionary.items():\n",
    "    print(f'{i} - {v}')\n",
    "    if i==10:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "renewable-particular",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW (Sequence-0):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['motif_2', 'motif_3'], [(0, 1), (1, 1)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(doc) for doc in docs]\n",
    "print('BOW (Sequence-0):')\n",
    "docs[0],corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-sampling",
   "metadata": {},
   "source": [
    "## Training Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "possible-residence",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-24 13:30:59,628 : INFO : using autotuned alpha, starting with [0.33333334, 0.33333334, 0.33333334]\n",
      "2021-02-24 13:30:59,629 : INFO : using serial LDA version on this node\n",
      "2021-02-24 13:30:59,630 : INFO : running online (multi-pass) LDA training, 3 topics, 5 passes over the supplied corpus of 1000 documents, updating model once every 1000 documents, evaluating perplexity every 1000 documents, iterating 1000x with a convergence threshold of 0.001000\n",
      "2021-02-24 13:30:59,631 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2021-02-24 13:30:59,633 : DEBUG : bound: at document #0\n",
      "2021-02-24 13:31:00,079 : INFO : -2.593 per-word bound, 6.0 perplexity estimate based on a held-out corpus of 1000 documents with 1931 words\n",
      "2021-02-24 13:31:00,079 : INFO : PROGRESS: pass 0, at document #1000/1000\n",
      "2021-02-24 13:31:00,080 : DEBUG : performing inference on a chunk of 1000 documents\n",
      "2021-02-24 13:31:00,431 : DEBUG : 1000/1000 documents converged within 1000 iterations\n",
      "2021-02-24 13:31:00,435 : INFO : optimized alpha [0.4045695, 0.42178893, 0.2923484]\n",
      "2021-02-24 13:31:00,435 : DEBUG : updating topics\n",
      "2021-02-24 13:31:00,436 : INFO : topic #0 (0.405): 0.552*\"motif_1\" + 0.394*\"motif_4\" + 0.035*\"motif_2\" + 0.016*\"motif_3\" + 0.003*\"motif_5\"\n",
      "2021-02-24 13:31:00,437 : INFO : topic #1 (0.422): 0.444*\"motif_3\" + 0.430*\"motif_2\" + 0.112*\"motif_1\" + 0.011*\"motif_4\" + 0.002*\"motif_5\"\n",
      "2021-02-24 13:31:00,438 : INFO : topic #2 (0.292): 0.392*\"motif_2\" + 0.230*\"motif_5\" + 0.160*\"motif_1\" + 0.158*\"motif_3\" + 0.061*\"motif_4\"\n",
      "2021-02-24 13:31:00,439 : INFO : topic diff=1.416201, rho=1.000000\n",
      "2021-02-24 13:31:00,441 : INFO : Epoch 0: Convergence estimate: 0.0\n",
      "2021-02-24 13:31:00,444 : DEBUG : bound: at document #0\n",
      "2021-02-24 13:31:00,643 : INFO : -1.566 per-word bound, 3.0 perplexity estimate based on a held-out corpus of 1000 documents with 1931 words\n",
      "2021-02-24 13:31:00,644 : INFO : PROGRESS: pass 1, at document #1000/1000\n",
      "2021-02-24 13:31:00,645 : DEBUG : performing inference on a chunk of 1000 documents\n",
      "2021-02-24 13:31:00,775 : DEBUG : 1000/1000 documents converged within 1000 iterations\n",
      "2021-02-24 13:31:00,779 : INFO : optimized alpha [0.4245334, 0.44110298, 0.2487739]\n",
      "2021-02-24 13:31:00,779 : DEBUG : updating topics\n",
      "2021-02-24 13:31:00,780 : INFO : topic #0 (0.425): 0.586*\"motif_1\" + 0.389*\"motif_4\" + 0.016*\"motif_2\" + 0.007*\"motif_3\" + 0.001*\"motif_5\"\n",
      "2021-02-24 13:31:00,781 : INFO : topic #1 (0.441): 0.463*\"motif_3\" + 0.455*\"motif_2\" + 0.075*\"motif_1\" + 0.005*\"motif_4\" + 0.001*\"motif_5\"\n",
      "2021-02-24 13:31:00,782 : INFO : topic #2 (0.249): 0.425*\"motif_2\" + 0.323*\"motif_5\" + 0.109*\"motif_1\" + 0.104*\"motif_3\" + 0.039*\"motif_4\"\n",
      "2021-02-24 13:31:00,783 : INFO : topic diff=0.440685, rho=0.577350\n",
      "2021-02-24 13:31:00,784 : INFO : Epoch 1: Convergence estimate: 0.0\n",
      "2021-02-24 13:31:00,789 : DEBUG : bound: at document #0\n",
      "2021-02-24 13:31:00,987 : INFO : -1.502 per-word bound, 2.8 perplexity estimate based on a held-out corpus of 1000 documents with 1931 words\n",
      "2021-02-24 13:31:00,987 : INFO : PROGRESS: pass 2, at document #1000/1000\n",
      "2021-02-24 13:31:00,988 : DEBUG : performing inference on a chunk of 1000 documents\n",
      "2021-02-24 13:31:01,102 : DEBUG : 1000/1000 documents converged within 1000 iterations\n",
      "2021-02-24 13:31:01,106 : INFO : optimized alpha [0.4397945, 0.45307562, 0.21906957]\n",
      "2021-02-24 13:31:01,106 : DEBUG : updating topics\n",
      "2021-02-24 13:31:01,107 : INFO : topic #0 (0.440): 0.603*\"motif_1\" + 0.383*\"motif_4\" + 0.009*\"motif_2\" + 0.004*\"motif_3\" + 0.001*\"motif_5\"\n",
      "2021-02-24 13:31:01,108 : INFO : topic #1 (0.453): 0.474*\"motif_3\" + 0.470*\"motif_2\" + 0.053*\"motif_1\" + 0.003*\"motif_4\" + 0.001*\"motif_5\"\n",
      "2021-02-24 13:31:01,109 : INFO : topic #2 (0.219): 0.442*\"motif_2\" + 0.392*\"motif_5\" + 0.072*\"motif_1\" + 0.068*\"motif_3\" + 0.026*\"motif_4\"\n",
      "2021-02-24 13:31:01,109 : INFO : topic diff=0.369259, rho=0.500000\n",
      "2021-02-24 13:31:01,110 : INFO : Epoch 2: Convergence estimate: 0.0\n",
      "2021-02-24 13:31:01,115 : DEBUG : bound: at document #0\n",
      "2021-02-24 13:31:01,298 : INFO : -1.465 per-word bound, 2.8 perplexity estimate based on a held-out corpus of 1000 documents with 1931 words\n",
      "2021-02-24 13:31:01,299 : INFO : PROGRESS: pass 3, at document #1000/1000\n",
      "2021-02-24 13:31:01,300 : DEBUG : performing inference on a chunk of 1000 documents\n",
      "2021-02-24 13:31:01,412 : DEBUG : 1000/1000 documents converged within 1000 iterations\n",
      "2021-02-24 13:31:01,416 : INFO : optimized alpha [0.4513837, 0.46094835, 0.19778013]\n",
      "2021-02-24 13:31:01,416 : DEBUG : updating topics\n",
      "2021-02-24 13:31:01,417 : INFO : topic #0 (0.451): 0.613*\"motif_1\" + 0.378*\"motif_4\" + 0.006*\"motif_2\" + 0.003*\"motif_3\" + 0.001*\"motif_5\"\n",
      "2021-02-24 13:31:01,418 : INFO : topic #1 (0.461): 0.480*\"motif_3\" + 0.479*\"motif_2\" + 0.038*\"motif_1\" + 0.002*\"motif_4\" + 0.001*\"motif_5\"\n",
      "2021-02-24 13:31:01,419 : INFO : topic #2 (0.198): 0.450*\"motif_2\" + 0.440*\"motif_5\" + 0.047*\"motif_1\" + 0.045*\"motif_3\" + 0.018*\"motif_4\"\n",
      "2021-02-24 13:31:01,419 : INFO : topic diff=0.320705, rho=0.447214\n",
      "2021-02-24 13:31:01,421 : INFO : Epoch 3: Convergence estimate: 0.0\n",
      "2021-02-24 13:31:01,425 : DEBUG : bound: at document #0\n",
      "2021-02-24 13:31:01,611 : INFO : -1.441 per-word bound, 2.7 perplexity estimate based on a held-out corpus of 1000 documents with 1931 words\n",
      "2021-02-24 13:31:01,611 : INFO : PROGRESS: pass 4, at document #1000/1000\n",
      "2021-02-24 13:31:01,612 : DEBUG : performing inference on a chunk of 1000 documents\n",
      "2021-02-24 13:31:01,722 : DEBUG : 1000/1000 documents converged within 1000 iterations\n",
      "2021-02-24 13:31:01,726 : INFO : optimized alpha [0.46020108, 0.46626037, 0.18172944]\n",
      "2021-02-24 13:31:01,727 : DEBUG : updating topics\n",
      "2021-02-24 13:31:01,728 : INFO : topic #0 (0.460): 0.619*\"motif_1\" + 0.375*\"motif_4\" + 0.004*\"motif_2\" + 0.002*\"motif_3\" + 0.001*\"motif_5\"\n",
      "2021-02-24 13:31:01,729 : INFO : topic #1 (0.466): 0.485*\"motif_2\" + 0.485*\"motif_3\" + 0.028*\"motif_1\" + 0.001*\"motif_4\" + 0.000*\"motif_5\"\n",
      "2021-02-24 13:31:01,729 : INFO : topic #2 (0.182): 0.472*\"motif_5\" + 0.453*\"motif_2\" + 0.032*\"motif_1\" + 0.030*\"motif_3\" + 0.013*\"motif_4\"\n",
      "2021-02-24 13:31:01,730 : INFO : topic diff=0.281621, rho=0.408248\n",
      "2021-02-24 13:31:01,731 : INFO : Epoch 4: Convergence estimate: 0.0\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 6097.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.26 s, sys: 203 ms, total: 2.46 s\n",
      "Wall time: 2.28 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import logging\n",
    "from gensim.models.callbacks import Callback,PerplexityMetric, ConvergenceMetric, CoherenceMetric\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.DEBUG)\n",
    "convergence_logger = ConvergenceMetric(logger='shell')\n",
    "from gensim.models import LdaModel,LdaMulticore\n",
    "\n",
    "temp = dictionary[0]\n",
    "id2word = dictionary.id2token\n",
    "lda = LdaModel(corpus, id2word=id2word, alpha='auto',chunksize=10000,\n",
    "               eta='auto',num_topics=3, iterations=1000, passes = 5,\n",
    "              minimum_probability=0.0,callbacks=[convergence_logger])\n",
    "\n",
    "lda_predictions=lda.get_document_topics(corpus,minimum_probability=0.0)\n",
    "lda_pred_topic=[]\n",
    "for pred in tqdm(lda_predictions):\n",
    "    top_topic=sorted(pred,key=lambda x:-x[1])[0][0]\n",
    "    lda_pred_topic.append(top_topic)\n",
    "lda_pred_data=data.copy()\n",
    "lda_pred_data['pred_topic']=lda_pred_topic\n",
    "\n",
    "logging.getLogger().setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-google",
   "metadata": {},
   "source": [
    "## Model Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bottom-equipment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.6189055),\n",
       " (3, 0.37495264),\n",
       " (0, 0.0037638969),\n",
       " (1, 0.0018303924),\n",
       " (4, 0.0005475782)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.get_topic_terms(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "exceptional-booth",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "622it [00:00, 3136.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.478, 1: 0.48, 2: 0.042}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:00, 3177.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1059.6488458157767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1059.6488458157767"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getTopicDistribution(pred_data,ntopics):\n",
    "    topic_dist_dict={i:0 for i in range(ntopics)}\n",
    "    value_count=pred_data['pred_topic'].value_counts(normalize=True)\n",
    "    for k,v in value_count.to_dict().items():\n",
    "        topic_dist_dict[k]=v\n",
    "    return topic_dist_dict\n",
    "\n",
    "def likelihoodMetric(model,pred_data,dictionary,ntopics):\n",
    "    likelihood=0\n",
    "    P_T=getTopicDistribution(pred_data,ntopics)\n",
    "    print(P_T)\n",
    "    for idx,row in tqdm(pred_data.iterrows()):\n",
    "        motif_list=dictionary.doc2idx(row['motif_list'])\n",
    "        assigned_topic_no=row['pred_topic']\n",
    "        P_Xi_M=0\n",
    "        for topic_no in range(ntopics):\n",
    "            ttd=model.get_topic_terms(topic_no)\n",
    "            filtered_ttd=list(filter(lambda x:x[0] in motif_list,ttd))\n",
    "            P_X_Ti=1\n",
    "            for motif,P_mj_T in filtered_ttd:\n",
    "                P_X_Ti*=P_mj_T\n",
    "            P_Xi_M+=P_X_Ti*P_T[topic_no]\n",
    "        likelihood+=np.log10(P_Xi_M)\n",
    "    print(likelihood)\n",
    "    return likelihood\n",
    "likelihoodMetric(lda,lda_pred_data,dictionary,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fitting-extreme",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getTopicDistribution(predictions,ntopics):\n",
    "#     topic_count_dict={i:0 for i in range(ntopics)}\n",
    "#     ndocs=len(predictions)\n",
    "#     for pred in predictions:\n",
    "#         top_topic=sorted(pred,key=lambda x:-x[1])[0][0]\n",
    "#         topic_count_dict[top_topic]+=1\n",
    "#     topic_dist_dict={k:v/ndocs for k,v in topic_count_dict.items()}\n",
    "#     print(topic_dist_dict)\n",
    "#     return topic_dist_dict\n",
    "\n",
    "# def likelihoodMetric(predictions,ntopics):\n",
    "#     likelihood=0\n",
    "#     P_T=getTopicDistribution(predictions,ntopics)\n",
    "# #     print(P_T)\n",
    "#     for pred in tqdm(predictions):\n",
    "#         P_Xi_M=0\n",
    "#         for topic_no,P_Xi_T in pred:\n",
    "#             P_Xi_M+=P_Xi_T*P_T[topic_no]\n",
    "#         likelihood+=np.log10(P_Xi_M)\n",
    "#     print(likelihood)\n",
    "#     return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "macro-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "def coherenceMetric_cv(model,dictionary,docs):\n",
    "    cm=CoherenceModel(model=model,dictionary=dictionary ,\n",
    "                      texts=docs, coherence='c_v',processes=30,\n",
    "                     window_size=2000)\n",
    "    coherence = cm.get_coherence()\n",
    "    print(coherence)\n",
    "    return coherence\n",
    "# coherenceMetric_cv(lda,dictionary ,docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "rural-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "def coherenceMetric_umass(model,dictionary,corpus):\n",
    "    cm = CoherenceModel(model=model, corpus=corpus, \\\n",
    "                        coherence='u_mass',processes=30)\n",
    "    coherence = cm.get_coherence()\n",
    "    print(coherence)\n",
    "    return coherence\n",
    "# coherenceMetric_umass(lda,dictionary ,corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "burning-scenario",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-12.312024693235893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-12.312024693235893"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "def coherenceMetric_uci(model,dictionary,docs):\n",
    "    cm=CoherenceModel(model=model,dictionary=dictionary ,\n",
    "                      texts=docs, coherence='c_uci',processes=30,\n",
    "                     window_size =2000)\n",
    "    coherence = cm.get_coherence()\n",
    "    print(coherence)\n",
    "    return coherence\n",
    "coherenceMetric_uci(lda,dictionary ,docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "induced-penetration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexityMetric(model,corpus):\n",
    "    perplexity=model.log_perplexity(corpus)\n",
    "    print(perplexity)\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "stretch-satellite",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "\n",
    "def randIndexMetric(predictions,data):\n",
    "    pred_topic=[]\n",
    "    for pred in tqdm(predictions):\n",
    "        topic_prob=sorted(pred,key=lambda x:-x[1])\n",
    "#         print(topic_prob)\n",
    "        top_topic=topic_prob[0][0]\n",
    "        pred_topic.append(top_topic)\n",
    "    _data=data.copy()\n",
    "    _data['pred_topic']=pred_topic\n",
    "    ari=adjusted_rand_score(_data['module'], _data['pred_topic'])\n",
    "    print(ari)\n",
    "    return ari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "characteristic-retreat",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def findTopMotifs(pred_data,ntopics,ntop=5,outdir=None):     \n",
    "    gb=pred_data[['motif_string','pred_topic']].groupby('pred_topic').\\\n",
    "    agg(lambda x: ','.join(x))\n",
    "    gb['top_motif']=gb['motif_string'].\\\n",
    "    apply(lambda x:Counter(x.split(',')).most_common(ntop))\n",
    "    gb.reset_index(inplace=True)\n",
    "    gb=gb[['pred_topic','top_motif']]\n",
    "    if outdir is not None:\n",
    "        gb.to_csv(f'{outdir}/top{ntop}_motifs_topics_{ntopics}.csv',index=False)\n",
    "    print(gb)\n",
    "    return gb\n",
    "# findTopMotifs(lda_pred_data,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-argument",
   "metadata": {},
   "source": [
    "## Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "south-desperate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Num of Topics = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 6826.10it/s]\n",
      "365it [00:00, 3644.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding likelihood...\n",
      "{0: 0.52, 1: 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:00, 3129.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1081.7886364118724\n",
      "\n",
      "Finding coherence_cv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22050510349084831\n",
      "\n",
      "Finding coherence_umass...\n",
      "-13.724379999203142\n",
      "\n",
      "Finding coherence_uci...\n",
      "-12.312024693235895\n",
      "\n",
      "Finding perplexity...\n",
      "-1.396633046292876\n",
      "\n",
      "Finding Top Motifs...\n",
      "   pred_topic                                          top_motif\n",
      "0           0  [(motif_2, 520), (motif_3, 480), (motif_1, 86)...\n",
      "1           1     [(motif_1, 478), (motif_4, 325), (motif_5, 2)]\n",
      "\n",
      "========================================\n",
      "Num of Topics = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 5427.35it/s]\n",
      "682it [00:00, 3391.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding likelihood...\n",
      "{0: 0.478, 1: 0.522, 2: 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1000it [00:00, 3373.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1068.3325802563206\n",
      "\n",
      "Finding coherence_cv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2205051034908483\n",
      "\n",
      "Finding coherence_umass...\n",
      "-13.906557615131524\n",
      "\n",
      "Finding coherence_uci...\n",
      "-12.312024693235893\n",
      "\n",
      "Finding perplexity...\n",
      "-1.4665321661578998\n",
      "\n",
      "Finding Top Motifs...\n",
      "   pred_topic                                          top_motif\n",
      "0           0                   [(motif_1, 478), (motif_4, 325)]\n",
      "1           1  [(motif_2, 520), (motif_3, 480), (motif_1, 86)...\n",
      "\n",
      "========================================\n",
      "Num of Topics = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 3398.55it/s]\n",
      "486it [00:00, 2419.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding likelihood...\n",
      "{0: 0.48, 1: 0.195, 2: 0.325, 3: 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:00, 2424.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1168.120157469577\n",
      "\n",
      "Finding coherence_cv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2205051034908483\n",
      "\n",
      "Finding coherence_umass...\n",
      "-13.889621325543992\n",
      "\n",
      "Finding coherence_uci...\n",
      "-12.312024693235895\n",
      "\n",
      "Finding perplexity...\n",
      "-1.633577910592902\n",
      "\n",
      "Finding Top Motifs...\n",
      "   pred_topic                                        top_motif\n",
      "0           0  [(motif_2, 480), (motif_3, 480), (motif_1, 86)]\n",
      "1           1   [(motif_1, 153), (motif_5, 42), (motif_2, 40)]\n",
      "2           2                 [(motif_1, 325), (motif_4, 325)]\n",
      "\n",
      "========================================\n",
      "Num of Topics = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 4586.24it/s]\n",
      "552it [00:00, 2676.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding likelihood...\n",
      "{0: 0, 1: 0.478, 2: 0.074, 3: 0.406, 4: 0.042}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:00, 2559.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1064.7247840617276\n",
      "\n",
      "Finding coherence_cv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22050510349084834\n",
      "\n",
      "Finding coherence_umass...\n",
      "-13.799190528738105\n",
      "\n",
      "Finding coherence_uci...\n",
      "-12.312024693235895\n",
      "\n",
      "Finding perplexity...\n",
      "-1.619948157192758\n",
      "\n",
      "Finding Top Motifs...\n",
      "   pred_topic                                        top_motif\n",
      "0           1                 [(motif_1, 478), (motif_4, 325)]\n",
      "1           2    [(motif_1, 74), (motif_2, 74), (motif_3, 74)]\n",
      "2           3  [(motif_2, 406), (motif_3, 406), (motif_1, 12)]\n",
      "3           4                   [(motif_5, 42), (motif_2, 40)]\n",
      "\n",
      "========================================\n",
      "Num of Topics = 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 4337.88it/s]\n",
      "241it [00:00, 2407.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding likelihood...\n",
      "{0: 0.086, 1: 0, 2: 0.436, 3: 0, 4: 0.438, 5: 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:00, 1791.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1062.5569480590254\n",
      "\n",
      "Finding coherence_cv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22050510349084831\n",
      "\n",
      "Finding coherence_umass...\n",
      "-13.98128186149676\n",
      "\n",
      "Finding coherence_uci...\n",
      "-12.312024693235896\n",
      "\n",
      "Finding perplexity...\n",
      "-1.8017196841017067\n",
      "\n",
      "Finding Top Motifs...\n",
      "   pred_topic                                        top_motif\n",
      "0           0    [(motif_1, 86), (motif_2, 86), (motif_3, 86)]\n",
      "1           2  [(motif_2, 434), (motif_3, 394), (motif_5, 42)]\n",
      "2           4                 [(motif_1, 438), (motif_4, 285)]\n",
      "3           5                   [(motif_1, 40), (motif_4, 40)]\n",
      "\n",
      "========================================\n",
      "Num of Topics = 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 2793.48it/s]\n",
      "320it [00:00, 1563.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding likelihood...\n",
      "{0: 0.132, 1: 0.001, 2: 0.042, 3: 0.346, 4: 0.007, 5: 0, 6: 0.472}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:00, 1609.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1096.3353722094048\n",
      "\n",
      "Finding coherence_cv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2205051034908483\n",
      "\n",
      "Finding coherence_umass...\n",
      "-13.852793135717643\n",
      "\n",
      "Finding coherence_uci...\n",
      "-12.312024693235896\n",
      "\n",
      "Finding perplexity...\n",
      "-1.8877449549121106\n",
      "\n",
      "Finding Top Motifs...\n",
      "   pred_topic                                        top_motif\n",
      "0           0                 [(motif_1, 132), (motif_4, 131)]\n",
      "1           1       [(motif_1, 1), (motif_2, 1), (motif_3, 1)]\n",
      "2           2                   [(motif_5, 42), (motif_2, 40)]\n",
      "3           3                 [(motif_1, 346), (motif_4, 194)]\n",
      "4           4       [(motif_2, 7), (motif_3, 7), (motif_1, 1)]\n",
      "5           6  [(motif_2, 472), (motif_3, 472), (motif_1, 84)]\n",
      "\n",
      "========================================\n",
      "Num of Topics = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 6263.81it/s]\n",
      "425it [00:00, 2128.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding likelihood...\n",
      "{0: 0.042, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0.48, 6: 0, 7: 0.478}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:00, 2051.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1034.6766384514988\n",
      "\n",
      "Finding coherence_cv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22050510349084834\n",
      "\n",
      "Finding coherence_umass...\n",
      "-13.859140301167534\n",
      "\n",
      "Finding coherence_uci...\n",
      "-12.312024693235895\n",
      "\n",
      "Finding perplexity...\n",
      "-1.8336653828925724\n",
      "\n",
      "Finding Top Motifs...\n",
      "   pred_topic                                        top_motif\n",
      "0           0                   [(motif_5, 42), (motif_2, 40)]\n",
      "1           5  [(motif_2, 480), (motif_3, 480), (motif_1, 86)]\n",
      "2           7                 [(motif_1, 478), (motif_4, 325)]\n",
      "\n",
      "========================================\n",
      "Num of Topics = 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 3393.95it/s]\n",
      "149it [00:00, 1483.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding likelihood...\n",
      "{0: 0.24, 1: 0, 2: 0, 3: 0, 4: 0.238, 5: 0.074, 6: 0, 7: 0.406, 8: 0.042}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:00, 1620.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1066.661195476034\n",
      "\n",
      "Finding coherence_cv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22050510349084831\n",
      "\n",
      "Finding coherence_umass...\n",
      "-13.822465014852243\n",
      "\n",
      "Finding coherence_uci...\n",
      "-12.312024693235895\n",
      "\n",
      "Finding perplexity...\n",
      "-1.9764882143584945\n",
      "\n",
      "Finding Top Motifs...\n",
      "   pred_topic                                        top_motif\n",
      "0           0                 [(motif_1, 240), (motif_4, 240)]\n",
      "1           4                  [(motif_1, 238), (motif_4, 85)]\n",
      "2           5    [(motif_1, 74), (motif_2, 74), (motif_3, 74)]\n",
      "3           7  [(motif_2, 406), (motif_3, 406), (motif_1, 12)]\n",
      "4           8                   [(motif_5, 42), (motif_2, 40)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_topics</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>coherence_cv</th>\n",
       "      <th>coherence_umass</th>\n",
       "      <th>coherence_uci</th>\n",
       "      <th>perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>-1081.788636</td>\n",
       "      <td>0.220505</td>\n",
       "      <td>-13.724380</td>\n",
       "      <td>-12.312025</td>\n",
       "      <td>-1.396633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>-1068.332580</td>\n",
       "      <td>0.220505</td>\n",
       "      <td>-13.906558</td>\n",
       "      <td>-12.312025</td>\n",
       "      <td>-1.466532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>-1168.120157</td>\n",
       "      <td>0.220505</td>\n",
       "      <td>-13.889621</td>\n",
       "      <td>-12.312025</td>\n",
       "      <td>-1.633578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>-1064.724784</td>\n",
       "      <td>0.220505</td>\n",
       "      <td>-13.799191</td>\n",
       "      <td>-12.312025</td>\n",
       "      <td>-1.619948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>-1062.556948</td>\n",
       "      <td>0.220505</td>\n",
       "      <td>-13.981282</td>\n",
       "      <td>-12.312025</td>\n",
       "      <td>-1.801720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>-1096.335372</td>\n",
       "      <td>0.220505</td>\n",
       "      <td>-13.852793</td>\n",
       "      <td>-12.312025</td>\n",
       "      <td>-1.887745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>-1034.676638</td>\n",
       "      <td>0.220505</td>\n",
       "      <td>-13.859140</td>\n",
       "      <td>-12.312025</td>\n",
       "      <td>-1.833665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>-1066.661195</td>\n",
       "      <td>0.220505</td>\n",
       "      <td>-13.822465</td>\n",
       "      <td>-12.312025</td>\n",
       "      <td>-1.976488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_topics   likelihood  coherence_cv  coherence_umass  coherence_uci  \\\n",
       "0           2 -1081.788636      0.220505       -13.724380     -12.312025   \n",
       "1           3 -1068.332580      0.220505       -13.906558     -12.312025   \n",
       "2           4 -1168.120157      0.220505       -13.889621     -12.312025   \n",
       "3           5 -1064.724784      0.220505       -13.799191     -12.312025   \n",
       "4           6 -1062.556948      0.220505       -13.981282     -12.312025   \n",
       "5           7 -1096.335372      0.220505       -13.852793     -12.312025   \n",
       "6           8 -1034.676638      0.220505       -13.859140     -12.312025   \n",
       "7           9 -1066.661195      0.220505       -13.822465     -12.312025   \n",
       "\n",
       "   perplexity  \n",
       "0   -1.396633  \n",
       "1   -1.466532  \n",
       "2   -1.633578  \n",
       "3   -1.619948  \n",
       "4   -1.801720  \n",
       "5   -1.887745  \n",
       "6   -1.833665  \n",
       "7   -1.976488  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from gensim.models import LdaModel,LdaMulticore\n",
    "\n",
    "outdir='model_output'\n",
    "eval_dict={'num_topics':[],'likelihood':[],'coherence_cv':[],\\\n",
    "          'coherence_umass':[],'coherence_uci':[],'perplexity':[]}\n",
    "temp = dictionary[0]\n",
    "id2word = dictionary.id2token\n",
    "for ntopics in range(2,10):\n",
    "    print('\\n'+'='*40)\n",
    "    print('Num of Topics = '+str(ntopics))\n",
    "    model = LdaModel(corpus, id2word=id2word, alpha='auto',chunksize=10000,\n",
    "                   eta='auto',num_topics=ntopics, iterations=1000, passes = 5,\n",
    "                  minimum_probability=0.0)\n",
    "    \n",
    "    predictions=model.get_document_topics(corpus,minimum_probability=0.0)\n",
    "    pred_topic=[]\n",
    "    for pred in tqdm(predictions):\n",
    "        top_topic=sorted(pred,key=lambda x:-x[1])[0][0]\n",
    "        pred_topic.append(top_topic)\n",
    "    pred_data=data.copy()\n",
    "    pred_data['pred_topic']=pred_topic\n",
    "    print('\\nFinding likelihood...')\n",
    "#     likelihood=likelihoodMetric(pred_data,predictions,ntopics)\n",
    "    likelihood=likelihoodMetric(model,pred_data,dictionary,ntopics)\n",
    "    print('\\nFinding coherence_cv...')\n",
    "    coherence_cv=coherenceMetric_cv(model,dictionary,docs)\n",
    "    print('\\nFinding coherence_umass...')\n",
    "    coherence_umass=coherenceMetric_umass(model,dictionary ,corpus)\n",
    "    print('\\nFinding coherence_uci...')\n",
    "    coherence_uci=coherenceMetric_uci(model,dictionary,docs)\n",
    "    print('\\nFinding perplexity...')\n",
    "    perplexity=perplexityMetric(model,corpus)\n",
    "    print('\\nFinding Top Motifs...')\n",
    "    findTopMotifs(pred_data,ntopics,outdir=outdir)\n",
    "#     print('\\nFindng avg. distance from TSS per topic...')\n",
    "#     getAvgTssDist(pred_data,ntopics,outdir=outdir)\n",
    "    eval_dict['num_topics'].append(ntopics)\n",
    "    eval_dict['likelihood'].append(likelihood)\n",
    "    eval_dict['coherence_cv'].append(coherence_cv)\n",
    "    eval_dict['coherence_umass'].append(coherence_umass)\n",
    "    eval_dict['coherence_uci'].append(coherence_uci)\n",
    "    eval_dict['perplexity'].append(perplexity)\n",
    "eval_df=pd.DataFrame(eval_dict)\n",
    "eval_df.to_csv(f'{outdir}/metrics.csv',index=False)\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "assisted-diesel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(eval_df['num_topics'],eval_df['likelihood'],marker='o')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "unlikely-accommodation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #setup logging for trainging metrics \n",
    "# import logging\n",
    "# logging.basicConfig(filename='test_output/model_callbacks.log', filemode='w',\n",
    "#                     format=\"%(asctime)s:%(levelname)s:%(message)s\",\n",
    "#                     level=logging.NOTSET)\n",
    "\n",
    "# from gensim.models.callbacks import Callback,PerplexityMetric, ConvergenceMetric, CoherenceMetric\n",
    "# perplexity_logger = PerplexityMetric(corpus=corpus, logger='shell')\n",
    "# convergence_logger = ConvergenceMetric(logger='shell')\n",
    "# # coherence_cv_logger = CoherenceMetric(corpus=corpus, coherence = 'c_v', texts = docs)\n",
    "\n",
    "# %%time\n",
    "# from gensim.models import LdaModel,LdaMulticore\n",
    "\n",
    "# #HYPERPARAMETERS\n",
    "# #passes = epochs\n",
    "# temp = dictionary[0]\n",
    "# id2word = dictionary.id2token\n",
    "# lda = LdaModel(corpus, id2word=id2word, alpha='auto',eval_every = 1,\\\n",
    "#                eta='auto',num_topics=3, iterations=5, passes = 10,\n",
    "#               callbacks=[perplexity_logger,convergence_logger])\n",
    "\n",
    "# lda.print_topics()\n",
    "\n",
    "# %%time\n",
    "# from gensim.models import LdaModel,LdaMulticore\n",
    "\n",
    "# id2word = dictionary.id2token\n",
    "# lda = LdaMulticore(corpus, id2word=id2word,eval_every = 1,\\\n",
    "#                eta='auto',num_topics=3, iterations=500, passes = 100)\n",
    "\n",
    "# import pyLDAvis.gensim\n",
    "\n",
    "# pyLDAvis.enable_notebook()\n",
    "# pyLDAvis.gensim.prepare(lda, corpus, dictionary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
