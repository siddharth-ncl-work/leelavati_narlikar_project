{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acute-accreditation",
   "metadata": {},
   "source": [
    "# LDA Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "southeast-hampshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-pension",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "downtown-phrase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_no.</th>\n",
       "      <th>seq</th>\n",
       "      <th>module</th>\n",
       "      <th>motif_1</th>\n",
       "      <th>motif_2</th>\n",
       "      <th>motif_3</th>\n",
       "      <th>motif_4</th>\n",
       "      <th>motif_5</th>\n",
       "      <th>motif_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GGAGGAGGAAGAGGCTGGGCCCCTGCTGTGTGGGGGCAAGTTCCCA...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_2,motif_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CAAATACCCTGGGGTGCAATACGACTTATATCTCACGTATTGGAAG...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AACTAGGACACAGAAGTTGATCTAACGTAAACATCAAGAGCTTCCT...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CACAGCTGGGCCTGGTTGGTCTTTGTCCAGGGAACAATGGAGCGCC...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>TTGTTTTATTTGTTTGTTGGGGGGCGGCGGGGAGCGACAGGGGAGT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_2,motif_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>CTATTATTAAGAAATATACACAATTTTAACTTCAAATATCTCTCAT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_2,motif_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>ATTGATTCTCACTTGCTTGACTCAAGGGAGGGTTTGATTTTGGTCA...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>ATGTGGTTCTACCATATAGTTTATCAATTTTAAACAGGTAAAATAT...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>ATTTTGTTGGTTAGGTGATGGAAGTATGATGCTATTGATATTTCCC...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>motif_2,motif_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>AAGGAAAAGTGAGGAAGTATGGCCATTCCTCTGATAGGACACAAGA...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     seq_no.                                                seq  module  \\\n",
       "0          0  GGAGGAGGAAGAGGCTGGGCCCCTGCTGTGTGGGGGCAAGTTCCCA...       0   \n",
       "1          1  CAAATACCCTGGGGTGCAATACGACTTATATCTCACGTATTGGAAG...       1   \n",
       "2          2  AACTAGGACACAGAAGTTGATCTAACGTAAACATCAAGAGCTTCCT...       1   \n",
       "3          3  CACAGCTGGGCCTGGTTGGTCTTTGTCCAGGGAACAATGGAGCGCC...       1   \n",
       "4          4  TTGTTTTATTTGTTTGTTGGGGGGCGGCGGGGAGCGACAGGGGAGT...       0   \n",
       "..       ...                                                ...     ...   \n",
       "995      995  CTATTATTAAGAAATATACACAATTTTAACTTCAAATATCTCTCAT...       0   \n",
       "996      996  ATTGATTCTCACTTGCTTGACTCAAGGGAGGGTTTGATTTTGGTCA...       1   \n",
       "997      997  ATGTGGTTCTACCATATAGTTTATCAATTTTAAACAGGTAAAATAT...       1   \n",
       "998      998  ATTTTGTTGGTTAGGTGATGGAAGTATGATGCTATTGATATTTCCC...       2   \n",
       "999      999  AAGGAAAAGTGAGGAAGTATGGCCATTCCTCTGATAGGACACAAGA...       1   \n",
       "\n",
       "     motif_1  motif_2  motif_3  motif_4  motif_5     motif_string  \n",
       "0        0.0      1.0      1.0      0.0      0.0  motif_2,motif_3  \n",
       "1        1.0      0.0      0.0      1.0      0.0  motif_1,motif_4  \n",
       "2        1.0      0.0      0.0      1.0      0.0  motif_1,motif_4  \n",
       "3        1.0      0.0      0.0      1.0      0.0  motif_1,motif_4  \n",
       "4        0.0      1.0      1.0      0.0      0.0  motif_2,motif_3  \n",
       "..       ...      ...      ...      ...      ...              ...  \n",
       "995      0.0      1.0      1.0      0.0      0.0  motif_2,motif_3  \n",
       "996      1.0      0.0      0.0      1.0      0.0  motif_1,motif_4  \n",
       "997      1.0      0.0      0.0      1.0      0.0  motif_1,motif_4  \n",
       "998      0.0      1.0      0.0      0.0      1.0  motif_2,motif_5  \n",
       "999      1.0      0.0      0.0      0.0      0.0          motif_1  \n",
       "\n",
       "[1000 rows x 9 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file_path='DATA.csv'\n",
    "data=pd.read_csv(data_file_path)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "southern-oracle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [seq_no., seq, module, motif_1, motif_2, motif_3, motif_4, motif_5, motif_string]\n",
      "Index: []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_no.</th>\n",
       "      <th>seq</th>\n",
       "      <th>module</th>\n",
       "      <th>motif_1</th>\n",
       "      <th>motif_2</th>\n",
       "      <th>motif_3</th>\n",
       "      <th>motif_4</th>\n",
       "      <th>motif_5</th>\n",
       "      <th>motif_string</th>\n",
       "      <th>motif_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GGAGGAGGAAGAGGCTGGGCCCCTGCTGTGTGGGGGCAAGTTCCCA...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_2,motif_3</td>\n",
       "      <td>[motif_2, motif_3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CAAATACCCTGGGGTGCAATACGACTTATATCTCACGTATTGGAAG...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "      <td>[motif_1, motif_4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AACTAGGACACAGAAGTTGATCTAACGTAAACATCAAGAGCTTCCT...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "      <td>[motif_1, motif_4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CACAGCTGGGCCTGGTTGGTCTTTGTCCAGGGAACAATGGAGCGCC...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "      <td>[motif_1, motif_4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>TTGTTTTATTTGTTTGTTGGGGGGCGGCGGGGAGCGACAGGGGAGT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_2,motif_3</td>\n",
       "      <td>[motif_2, motif_3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>CTATTATTAAGAAATATACACAATTTTAACTTCAAATATCTCTCAT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_2,motif_3</td>\n",
       "      <td>[motif_2, motif_3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>ATTGATTCTCACTTGCTTGACTCAAGGGAGGGTTTGATTTTGGTCA...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "      <td>[motif_1, motif_4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>ATGTGGTTCTACCATATAGTTTATCAATTTTAAACAGGTAAAATAT...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "      <td>[motif_1, motif_4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>ATTTTGTTGGTTAGGTGATGGAAGTATGATGCTATTGATATTTCCC...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>motif_2,motif_5</td>\n",
       "      <td>[motif_2, motif_5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>AAGGAAAAGTGAGGAAGTATGGCCATTCCTCTGATAGGACACAAGA...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1</td>\n",
       "      <td>[motif_1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     seq_no.                                                seq  module  \\\n",
       "0          0  GGAGGAGGAAGAGGCTGGGCCCCTGCTGTGTGGGGGCAAGTTCCCA...       0   \n",
       "1          1  CAAATACCCTGGGGTGCAATACGACTTATATCTCACGTATTGGAAG...       1   \n",
       "2          2  AACTAGGACACAGAAGTTGATCTAACGTAAACATCAAGAGCTTCCT...       1   \n",
       "3          3  CACAGCTGGGCCTGGTTGGTCTTTGTCCAGGGAACAATGGAGCGCC...       1   \n",
       "4          4  TTGTTTTATTTGTTTGTTGGGGGGCGGCGGGGAGCGACAGGGGAGT...       0   \n",
       "..       ...                                                ...     ...   \n",
       "995      995  CTATTATTAAGAAATATACACAATTTTAACTTCAAATATCTCTCAT...       0   \n",
       "996      996  ATTGATTCTCACTTGCTTGACTCAAGGGAGGGTTTGATTTTGGTCA...       1   \n",
       "997      997  ATGTGGTTCTACCATATAGTTTATCAATTTTAAACAGGTAAAATAT...       1   \n",
       "998      998  ATTTTGTTGGTTAGGTGATGGAAGTATGATGCTATTGATATTTCCC...       2   \n",
       "999      999  AAGGAAAAGTGAGGAAGTATGGCCATTCCTCTGATAGGACACAAGA...       1   \n",
       "\n",
       "     motif_1  motif_2  motif_3  motif_4  motif_5     motif_string  \\\n",
       "0        0.0      1.0      1.0      0.0      0.0  motif_2,motif_3   \n",
       "1        1.0      0.0      0.0      1.0      0.0  motif_1,motif_4   \n",
       "2        1.0      0.0      0.0      1.0      0.0  motif_1,motif_4   \n",
       "3        1.0      0.0      0.0      1.0      0.0  motif_1,motif_4   \n",
       "4        0.0      1.0      1.0      0.0      0.0  motif_2,motif_3   \n",
       "..       ...      ...      ...      ...      ...              ...   \n",
       "995      0.0      1.0      1.0      0.0      0.0  motif_2,motif_3   \n",
       "996      1.0      0.0      0.0      1.0      0.0  motif_1,motif_4   \n",
       "997      1.0      0.0      0.0      1.0      0.0  motif_1,motif_4   \n",
       "998      0.0      1.0      0.0      0.0      1.0  motif_2,motif_5   \n",
       "999      1.0      0.0      0.0      0.0      0.0          motif_1   \n",
       "\n",
       "             motif_list  \n",
       "0    [motif_2, motif_3]  \n",
       "1    [motif_1, motif_4]  \n",
       "2    [motif_1, motif_4]  \n",
       "3    [motif_1, motif_4]  \n",
       "4    [motif_2, motif_3]  \n",
       "..                  ...  \n",
       "995  [motif_2, motif_3]  \n",
       "996  [motif_1, motif_4]  \n",
       "997  [motif_1, motif_4]  \n",
       "998  [motif_2, motif_5]  \n",
       "999           [motif_1]  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data[data['motif_string'].isna()])\n",
    "data.dropna(subset=['motif_string'],inplace=True)\n",
    "data['motif_list']=data['motif_string'].apply(lambda x:x.split(','))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "concrete-freeze",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-21 09:05:56,248 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2021-02-21 09:05:56,263 : INFO : built Dictionary(5 unique tokens: ['motif_2', 'motif_3', 'motif_1', 'motif_4', 'motif_5']) from 1000 documents (total 1931 corpus positions)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Motif-Index to Motif-Name Mapping:\n",
      "0 - motif_2\n",
      "1 - motif_3\n",
      "2 - motif_1\n",
      "3 - motif_4\n",
      "4 - motif_5\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "docs=data['motif_list'].values\n",
    "dictionary=Dictionary(docs)\n",
    "\n",
    "print('Motif-Index to Motif-Name Mapping:')\n",
    "for i,v in dictionary.items():\n",
    "    print(f'{i} - {v}')\n",
    "    if i==10:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "renewable-particular",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW (Sequence-0):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['motif_2', 'motif_3'], [(0, 1), (1, 1)])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(doc) for doc in docs]\n",
    "print('BOW (Sequence-0):')\n",
    "docs[0],corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-sampling",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "unlikely-accommodation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #setup logging for trainging metrics \n",
    "# import logging\n",
    "# logging.basicConfig(filename='test_output/model_callbacks.log', filemode='w',\n",
    "#                     format=\"%(asctime)s:%(levelname)s:%(message)s\",\n",
    "#                     level=logging.NOTSET)\n",
    "\n",
    "# from gensim.models.callbacks import Callback,PerplexityMetric, ConvergenceMetric, CoherenceMetric\n",
    "# perplexity_logger = PerplexityMetric(corpus=corpus, logger='shell')\n",
    "# convergence_logger = ConvergenceMetric(logger='shell')\n",
    "# # coherence_cv_logger = CoherenceMetric(corpus=corpus, coherence = 'c_v', texts = docs)\n",
    "\n",
    "# %%time\n",
    "# from gensim.models import LdaModel,LdaMulticore\n",
    "\n",
    "# #HYPERPARAMETERS\n",
    "# #passes = epochs\n",
    "# temp = dictionary[0]\n",
    "# id2word = dictionary.id2token\n",
    "# lda = LdaModel(corpus, id2word=id2word, alpha='auto',eval_every = 1,\\\n",
    "#                eta='auto',num_topics=3, iterations=5, passes = 10,\n",
    "#               callbacks=[perplexity_logger,convergence_logger])\n",
    "\n",
    "# lda.print_topics()\n",
    "\n",
    "# %%time\n",
    "# from gensim.models import LdaModel,LdaMulticore\n",
    "\n",
    "# id2word = dictionary.id2token\n",
    "# lda = LdaMulticore(corpus, id2word=id2word,eval_every = 1,\\\n",
    "#                eta='auto',num_topics=3, iterations=500, passes = 100)\n",
    "\n",
    "# import pyLDAvis.gensim\n",
    "\n",
    "# pyLDAvis.enable_notebook()\n",
    "# pyLDAvis.gensim.prepare(lda, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "focal-sessions",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "possible-residence",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-21 09:05:56,445 : INFO : using autotuned alpha, starting with [0.33333334, 0.33333334, 0.33333334]\n",
      "2021-02-21 09:05:56,446 : INFO : using serial LDA version on this node\n",
      "2021-02-21 09:05:56,447 : INFO : running online (multi-pass) LDA training, 3 topics, 5 passes over the supplied corpus of 1000 documents, updating model once every 1000 documents, evaluating perplexity every 1000 documents, iterating 1000x with a convergence threshold of 0.001000\n",
      "2021-02-21 09:05:56,448 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2021-02-21 09:05:56,449 : DEBUG : bound: at document #0\n",
      "2021-02-21 09:05:57,404 : INFO : -2.605 per-word bound, 6.1 perplexity estimate based on a held-out corpus of 1000 documents with 1931 words\n",
      "2021-02-21 09:05:57,405 : INFO : PROGRESS: pass 0, at document #1000/1000\n",
      "2021-02-21 09:05:57,406 : DEBUG : performing inference on a chunk of 1000 documents\n",
      "2021-02-21 09:05:58,129 : DEBUG : 1000/1000 documents converged within 1000 iterations\n",
      "2021-02-21 09:05:58,134 : INFO : optimized alpha [0.43378192, 0.39489016, 0.32790127]\n",
      "2021-02-21 09:05:58,134 : DEBUG : updating topics\n",
      "2021-02-21 09:05:58,135 : INFO : topic #0 (0.434): 0.441*\"motif_2\" + 0.405*\"motif_3\" + 0.106*\"motif_1\" + 0.034*\"motif_5\" + 0.015*\"motif_4\"\n",
      "2021-02-21 09:05:58,135 : INFO : topic #1 (0.395): 0.433*\"motif_1\" + 0.423*\"motif_4\" + 0.070*\"motif_2\" + 0.067*\"motif_3\" + 0.008*\"motif_5\"\n",
      "2021-02-21 09:05:58,136 : INFO : topic #2 (0.328): 0.641*\"motif_1\" + 0.148*\"motif_2\" + 0.137*\"motif_3\" + 0.059*\"motif_4\" + 0.015*\"motif_5\"\n",
      "2021-02-21 09:05:58,137 : INFO : topic diff=1.149045, rho=1.000000\n",
      "2021-02-21 09:05:58,138 : DEBUG : bound: at document #0\n",
      "2021-02-21 09:05:58,379 : INFO : -1.652 per-word bound, 3.1 perplexity estimate based on a held-out corpus of 1000 documents with 1931 words\n",
      "2021-02-21 09:05:58,380 : INFO : PROGRESS: pass 1, at document #1000/1000\n",
      "2021-02-21 09:05:58,380 : DEBUG : performing inference on a chunk of 1000 documents\n",
      "2021-02-21 09:05:58,541 : DEBUG : 1000/1000 documents converged within 1000 iterations\n",
      "2021-02-21 09:05:58,544 : INFO : optimized alpha [0.46699888, 0.39479035, 0.31009236]\n",
      "2021-02-21 09:05:58,545 : DEBUG : updating topics\n",
      "2021-02-21 09:05:58,546 : INFO : topic #0 (0.467): 0.466*\"motif_2\" + 0.429*\"motif_3\" + 0.062*\"motif_1\" + 0.037*\"motif_5\" + 0.006*\"motif_4\"\n",
      "2021-02-21 09:05:58,546 : INFO : topic #1 (0.395): 0.470*\"motif_1\" + 0.460*\"motif_4\" + 0.034*\"motif_2\" + 0.033*\"motif_3\" + 0.004*\"motif_5\"\n",
      "2021-02-21 09:05:58,547 : INFO : topic #2 (0.310): 0.775*\"motif_1\" + 0.096*\"motif_2\" + 0.091*\"motif_3\" + 0.030*\"motif_4\" + 0.008*\"motif_5\"\n",
      "2021-02-21 09:05:58,547 : INFO : topic diff=0.429401, rho=0.577350\n",
      "2021-02-21 09:05:58,548 : DEBUG : bound: at document #0\n",
      "2021-02-21 09:05:58,778 : INFO : -1.578 per-word bound, 3.0 perplexity estimate based on a held-out corpus of 1000 documents with 1931 words\n",
      "2021-02-21 09:05:58,778 : INFO : PROGRESS: pass 2, at document #1000/1000\n",
      "2021-02-21 09:05:58,779 : DEBUG : performing inference on a chunk of 1000 documents\n",
      "2021-02-21 09:05:58,927 : DEBUG : 1000/1000 documents converged within 1000 iterations\n",
      "2021-02-21 09:05:58,931 : INFO : optimized alpha [0.48813286, 0.39089653, 0.29612553]\n",
      "2021-02-21 09:05:58,932 : DEBUG : updating topics\n",
      "2021-02-21 09:05:58,933 : INFO : topic #0 (0.488): 0.478*\"motif_2\" + 0.440*\"motif_3\" + 0.039*\"motif_1\" + 0.039*\"motif_5\" + 0.004*\"motif_4\"\n",
      "2021-02-21 09:05:58,933 : INFO : topic #1 (0.391): 0.485*\"motif_1\" + 0.476*\"motif_4\" + 0.019*\"motif_2\" + 0.018*\"motif_3\" + 0.002*\"motif_5\"\n",
      "2021-02-21 09:05:58,934 : INFO : topic #2 (0.296): 0.849*\"motif_1\" + 0.066*\"motif_2\" + 0.063*\"motif_3\" + 0.017*\"motif_4\" + 0.005*\"motif_5\"\n",
      "2021-02-21 09:05:58,934 : INFO : topic diff=0.356034, rho=0.500000\n",
      "2021-02-21 09:05:58,936 : DEBUG : bound: at document #0\n",
      "2021-02-21 09:05:59,157 : INFO : -1.544 per-word bound, 2.9 perplexity estimate based on a held-out corpus of 1000 documents with 1931 words\n",
      "2021-02-21 09:05:59,157 : INFO : PROGRESS: pass 3, at document #1000/1000\n",
      "2021-02-21 09:05:59,158 : DEBUG : performing inference on a chunk of 1000 documents\n",
      "2021-02-21 09:05:59,299 : DEBUG : 1000/1000 documents converged within 1000 iterations\n",
      "2021-02-21 09:05:59,303 : INFO : optimized alpha [0.5021604, 0.38627803, 0.2848921]\n",
      "2021-02-21 09:05:59,304 : DEBUG : updating topics\n",
      "2021-02-21 09:05:59,305 : INFO : topic #0 (0.502): 0.485*\"motif_2\" + 0.447*\"motif_3\" + 0.040*\"motif_5\" + 0.027*\"motif_1\" + 0.002*\"motif_4\"\n",
      "2021-02-21 09:05:59,305 : INFO : topic #1 (0.386): 0.492*\"motif_1\" + 0.484*\"motif_4\" + 0.011*\"motif_2\" + 0.011*\"motif_3\" + 0.002*\"motif_5\"\n",
      "2021-02-21 09:05:59,306 : INFO : topic #2 (0.285): 0.894*\"motif_1\" + 0.047*\"motif_2\" + 0.045*\"motif_3\" + 0.011*\"motif_4\" + 0.004*\"motif_5\"\n",
      "2021-02-21 09:05:59,307 : INFO : topic diff=0.310389, rho=0.447214\n",
      "2021-02-21 09:05:59,308 : DEBUG : bound: at document #0\n",
      "2021-02-21 09:05:59,525 : INFO : -1.526 per-word bound, 2.9 perplexity estimate based on a held-out corpus of 1000 documents with 1931 words\n",
      "2021-02-21 09:05:59,526 : INFO : PROGRESS: pass 4, at document #1000/1000\n",
      "2021-02-21 09:05:59,527 : DEBUG : performing inference on a chunk of 1000 documents\n",
      "2021-02-21 09:05:59,664 : DEBUG : 1000/1000 documents converged within 1000 iterations\n",
      "2021-02-21 09:05:59,668 : INFO : optimized alpha [0.5115232, 0.38165358, 0.27554524]\n",
      "2021-02-21 09:05:59,669 : DEBUG : updating topics\n",
      "2021-02-21 09:05:59,670 : INFO : topic #0 (0.512): 0.489*\"motif_2\" + 0.451*\"motif_3\" + 0.040*\"motif_5\" + 0.019*\"motif_1\" + 0.001*\"motif_4\"\n",
      "2021-02-21 09:05:59,670 : INFO : topic #1 (0.382): 0.496*\"motif_1\" + 0.488*\"motif_4\" + 0.007*\"motif_2\" + 0.007*\"motif_3\" + 0.001*\"motif_5\"\n",
      "2021-02-21 09:05:59,671 : INFO : topic #2 (0.276): 0.923*\"motif_1\" + 0.034*\"motif_2\" + 0.033*\"motif_3\" + 0.007*\"motif_4\" + 0.003*\"motif_5\"\n",
      "2021-02-21 09:05:59,672 : INFO : topic diff=0.277464, rho=0.408248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.25 s, sys: 42 ms, total: 3.29 s\n",
      "Wall time: 3.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from gensim.models import LdaModel,LdaMulticore\n",
    "\n",
    "temp = dictionary[0]\n",
    "id2word = dictionary.id2token\n",
    "lda = LdaModel(corpus, id2word=id2word, alpha='auto',chunksize=10000,\n",
    "               eta='auto',num_topics=3, iterations=1000, passes = 5,\n",
    "              minimum_probability=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fitting-extreme",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopicDistribution(predictions,ntopic):\n",
    "    topic_count_dict={i:0 for i in range(ntopics)}\n",
    "    ndocs=len(predictions)\n",
    "    print(ndocs)\n",
    "    for pred in predictions:\n",
    "        top_topic=sorted(pred,key=lambda x:-x[1])[0][0]\n",
    "        topic_count_dict[top_topic]+=1\n",
    "    topic_dist_dict={k:v/ndocs for k,v in topic_count_dict.items()}\n",
    "    return topic_dist_dict\n",
    "\n",
    "def likelihoodMetric(model,corpus):\n",
    "    likelihood=0\n",
    "#     P_T=model.alpha\n",
    "    predictions=lda.get_document_topics(corpus,minimum_probability=0.0)\n",
    "    P_T=getTopicDistribution(predictions,model.num_topics)\n",
    "    print(P_T)\n",
    "    for pred in predictions:\n",
    "        P_Xi_M=0\n",
    "        for topic_no,P_Xi_T in pred:\n",
    "            P_Xi_M+=P_Xi_T*P_T[topic_no]\n",
    "        likelihood+=np.log10(P_Xi_M)\n",
    "    print(likelihood)\n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "characteristic-retreat",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def findTopMotifs(model,corpus,data,ntopics,ntop=5,outdir=None):\n",
    "    pred_topic=[]\n",
    "    for pred in lda.get_document_topics(corpus,minimum_probability=0.0):\n",
    "        top_topic=sorted(pred,key=lambda x:-x[1])[0][0]\n",
    "        pred_topic.append(top_topic)\n",
    "    _data=data.copy()\n",
    "    _data['pred_topic']=pred_topic      \n",
    "    gb=_data[['motif_string','pred_topic']].groupby('pred_topic').\\\n",
    "    agg(lambda x: ','.join(x))\n",
    "    gb['top_motif']=gb['motif_string'].\\\n",
    "    apply(lambda x:Counter(x.split(',')).most_common(ntop))\n",
    "    gb.reset_index(inplace=True)\n",
    "    gb=gb[['pred_topic','top_motif']]\n",
    "    if outdir is not None:\n",
    "        gb.to_csv(f'{outdir}/top{ntop}_motifs_topics_{ntopics}.csv',index=False)\n",
    "    print(gb)\n",
    "    return gb\n",
    "# findTopMotifs(lda,corpus,data,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-stocks",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "south-desperate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Topic 2\n",
      "2\n",
      "Finding likelihood...\n",
      "1000\n",
      "{0: 0.48, 1: 0.52}\n",
      "-301.7673207418115\n",
      "Finding Top Motifs...\n",
      "   pred_topic                                          top_motif\n",
      "0           0    [(motif_2, 480), (motif_3, 480), (motif_1, 86)]\n",
      "1           1  [(motif_1, 478), (motif_4, 325), (motif_5, 42)...\n",
      "Num of Topic 3\n",
      "3\n",
      "Finding likelihood...\n",
      "1000\n",
      "{0: 0.042, 1: 0.48, 2: 0.478}\n",
      "-359.71865087936095\n",
      "Finding Top Motifs...\n",
      "   pred_topic                                        top_motif\n",
      "0           0                   [(motif_5, 42), (motif_2, 40)]\n",
      "1           1  [(motif_2, 480), (motif_3, 480), (motif_1, 86)]\n",
      "2           2                 [(motif_1, 478), (motif_4, 325)]\n",
      "Num of Topic 4\n",
      "4\n",
      "Finding likelihood...\n",
      "1000\n",
      "{0: 0.325, 1: 0.004, 2: 0.518, 3: 0.153}\n",
      "-458.08317952349034\n",
      "Finding Top Motifs...\n",
      "   pred_topic                                          top_motif\n",
      "0           0                   [(motif_1, 325), (motif_4, 325)]\n",
      "1           1         [(motif_1, 4), (motif_2, 4), (motif_3, 4)]\n",
      "2           2  [(motif_2, 516), (motif_3, 476), (motif_1, 82)...\n",
      "3           3                                   [(motif_1, 153)]\n",
      "Num of Topic 5\n",
      "5\n",
      "Finding likelihood...\n",
      "1000\n",
      "{0: 0.325, 1: 0.153, 2: 0.042, 3: 0.0, 4: 0.48}\n",
      "-502.8178509774133\n",
      "Finding Top Motifs...\n",
      "   pred_topic                                        top_motif\n",
      "0           0                 [(motif_1, 325), (motif_4, 325)]\n",
      "1           1                                 [(motif_1, 153)]\n",
      "2           2                   [(motif_5, 42), (motif_2, 40)]\n",
      "3           4  [(motif_2, 480), (motif_3, 480), (motif_1, 86)]\n",
      "Num of Topic 6\n",
      "6\n",
      "Finding likelihood...\n",
      "1000\n",
      "{0: 0.0, 1: 0.042, 2: 0.055, 3: 0.425, 4: 0.478, 5: 0.0}\n",
      "-466.2063061031499\n",
      "Finding Top Motifs...\n",
      "   pred_topic                                        top_motif\n",
      "0           1                   [(motif_5, 42), (motif_2, 40)]\n",
      "1           2    [(motif_1, 56), (motif_2, 56), (motif_3, 56)]\n",
      "2           3  [(motif_2, 424), (motif_3, 424), (motif_1, 30)]\n",
      "3           4                 [(motif_1, 478), (motif_4, 325)]\n",
      "Num of Topic 7\n",
      "7\n",
      "Finding likelihood...\n",
      "1000\n",
      "{0: 0.062, 1: 0.013, 2: 0.478, 3: 0.042, 4: 0.0, 5: 0.084, 6: 0.321}\n",
      "-570.154808634615\n",
      "Finding Top Motifs...\n",
      "   pred_topic                                        top_motif\n",
      "0           0    [(motif_1, 66), (motif_2, 66), (motif_3, 66)]\n",
      "1           1     [(motif_2, 11), (motif_3, 11), (motif_1, 6)]\n",
      "2           2                 [(motif_1, 478), (motif_4, 325)]\n",
      "3           3                   [(motif_5, 42), (motif_2, 40)]\n",
      "4           5     [(motif_2, 61), (motif_3, 61), (motif_1, 1)]\n",
      "5           6  [(motif_2, 342), (motif_3, 342), (motif_1, 13)]\n",
      "Num of Topic 8\n",
      "8\n",
      "Finding likelihood...\n",
      "1000\n",
      "{0: 0.422, 1: 0.042, 2: 0.0, 3: 0.153, 4: 0.325, 5: 0.058, 6: 0.0, 7: 0.0}\n",
      "-591.0267498606734\n",
      "Finding Top Motifs...\n",
      "   pred_topic                                        top_motif\n",
      "0           0  [(motif_2, 425), (motif_3, 425), (motif_1, 31)]\n",
      "1           1                   [(motif_5, 42), (motif_2, 40)]\n",
      "2           3                                 [(motif_1, 153)]\n",
      "3           4                 [(motif_1, 325), (motif_4, 325)]\n",
      "4           5    [(motif_1, 55), (motif_2, 55), (motif_3, 55)]\n",
      "Num of Topic 9\n",
      "9\n",
      "Finding likelihood...\n",
      "1000\n",
      "{0: 0.0, 1: 0.335, 2: 0.473, 3: 0.143, 4: 0.004, 5: 0.003, 6: 0.0, 7: 0.0, 8: 0.042}\n",
      "-557.8104973313884\n",
      "Finding Top Motifs...\n",
      "   pred_topic                                        top_motif\n",
      "0           1                 [(motif_1, 329), (motif_4, 325)]\n",
      "1           2  [(motif_2, 472), (motif_3, 472), (motif_1, 78)]\n",
      "2           3                                 [(motif_1, 149)]\n",
      "3           4       [(motif_1, 3), (motif_2, 3), (motif_3, 3)]\n",
      "4           5       [(motif_1, 5), (motif_2, 5), (motif_3, 5)]\n",
      "5           8                   [(motif_5, 42), (motif_2, 40)]\n",
      "CPU times: user 26.5 s, sys: 106 ms, total: 26.6 s\n",
      "Wall time: 26.4 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_topics</th>\n",
       "      <th>likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>-301.767321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>-359.718651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>-458.083180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>-502.817851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>-466.206306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>-570.154809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>-591.026750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>-557.810497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_topics  likelihood\n",
       "0           2 -301.767321\n",
       "1           3 -359.718651\n",
       "2           4 -458.083180\n",
       "3           5 -502.817851\n",
       "4           6 -466.206306\n",
       "5           7 -570.154809\n",
       "6           8 -591.026750\n",
       "7           9 -557.810497"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "from gensim.models import LdaModel,LdaMulticore\n",
    "\n",
    "outdir='model_output'\n",
    "eval_dict={'num_topics':[],'likelihood':[]}\n",
    "temp = dictionary[0]\n",
    "id2word = dictionary.id2token\n",
    "for ntopics in range(2,10):\n",
    "    print('Num of Topic '+str(ntopics))\n",
    "    lda = LdaModel(corpus, id2word=id2word, alpha='auto',chunksize=10000,\n",
    "                   eta='auto',num_topics=ntopics, iterations=1000, passes = 5,\n",
    "                  minimum_probability=0.0)\n",
    "    print(lda.num_topics)\n",
    "    print('Finding likelihood...')\n",
    "    likelihood=likelihoodMetric(lda,corpus)\n",
    "    print('Finding Top Motifs...')\n",
    "    findTopMotifs(lda,corpus,data,ntopics,outdir=outdir)\n",
    "#     print('Findng avg. distance from TSS per topic...')\n",
    "#     getAvgTssDist(lda,corpus,data,ntopics,outdir=outdir)\n",
    "    eval_dict['num_topics'].append(ntopics)\n",
    "    eval_dict['likelihood'].append(likelihood)\n",
    "eval_df=pd.DataFrame(eval_dict)\n",
    "eval_df.to_csv(f'{outdir}/likelihood.csv',index=False)\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-marsh",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
