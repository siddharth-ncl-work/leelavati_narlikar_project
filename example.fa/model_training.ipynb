{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acute-accreditation",
   "metadata": {},
   "source": [
    "# LDA Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "southeast-hampshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-pension",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "downtown-phrase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_no.</th>\n",
       "      <th>seq</th>\n",
       "      <th>module</th>\n",
       "      <th>motif_1</th>\n",
       "      <th>motif_2</th>\n",
       "      <th>motif_3</th>\n",
       "      <th>motif_4</th>\n",
       "      <th>motif_5</th>\n",
       "      <th>motif_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GGAGGAGGAAGAGGCTGGGCCCCTGCTGTGTGGGGGCAAGTTCCCA...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_2,motif_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CAAATACCCTGGGGTGCAATACGACTTATATCTCACGTATTGGAAG...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AACTAGGACACAGAAGTTGATCTAACGTAAACATCAAGAGCTTCCT...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CACAGCTGGGCCTGGTTGGTCTTTGTCCAGGGAACAATGGAGCGCC...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>TTGTTTTATTTGTTTGTTGGGGGGCGGCGGGGAGCGACAGGGGAGT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_2,motif_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>CTATTATTAAGAAATATACACAATTTTAACTTCAAATATCTCTCAT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_2,motif_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>ATTGATTCTCACTTGCTTGACTCAAGGGAGGGTTTGATTTTGGTCA...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>ATGTGGTTCTACCATATAGTTTATCAATTTTAAACAGGTAAAATAT...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>ATTTTGTTGGTTAGGTGATGGAAGTATGATGCTATTGATATTTCCC...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>motif_2,motif_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>AAGGAAAAGTGAGGAAGTATGGCCATTCCTCTGATAGGACACAAGA...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     seq_no.                                                seq  module  \\\n",
       "0          0  GGAGGAGGAAGAGGCTGGGCCCCTGCTGTGTGGGGGCAAGTTCCCA...       0   \n",
       "1          1  CAAATACCCTGGGGTGCAATACGACTTATATCTCACGTATTGGAAG...       1   \n",
       "2          2  AACTAGGACACAGAAGTTGATCTAACGTAAACATCAAGAGCTTCCT...       1   \n",
       "3          3  CACAGCTGGGCCTGGTTGGTCTTTGTCCAGGGAACAATGGAGCGCC...       1   \n",
       "4          4  TTGTTTTATTTGTTTGTTGGGGGGCGGCGGGGAGCGACAGGGGAGT...       0   \n",
       "..       ...                                                ...     ...   \n",
       "995      995  CTATTATTAAGAAATATACACAATTTTAACTTCAAATATCTCTCAT...       0   \n",
       "996      996  ATTGATTCTCACTTGCTTGACTCAAGGGAGGGTTTGATTTTGGTCA...       1   \n",
       "997      997  ATGTGGTTCTACCATATAGTTTATCAATTTTAAACAGGTAAAATAT...       1   \n",
       "998      998  ATTTTGTTGGTTAGGTGATGGAAGTATGATGCTATTGATATTTCCC...       2   \n",
       "999      999  AAGGAAAAGTGAGGAAGTATGGCCATTCCTCTGATAGGACACAAGA...       1   \n",
       "\n",
       "     motif_1  motif_2  motif_3  motif_4  motif_5     motif_string  \n",
       "0        0.0      1.0      1.0      0.0      0.0  motif_2,motif_3  \n",
       "1        1.0      0.0      0.0      1.0      0.0  motif_1,motif_4  \n",
       "2        1.0      0.0      0.0      1.0      0.0  motif_1,motif_4  \n",
       "3        1.0      0.0      0.0      1.0      0.0  motif_1,motif_4  \n",
       "4        0.0      1.0      1.0      0.0      0.0  motif_2,motif_3  \n",
       "..       ...      ...      ...      ...      ...              ...  \n",
       "995      0.0      1.0      1.0      0.0      0.0  motif_2,motif_3  \n",
       "996      1.0      0.0      0.0      1.0      0.0  motif_1,motif_4  \n",
       "997      1.0      0.0      0.0      1.0      0.0  motif_1,motif_4  \n",
       "998      0.0      1.0      0.0      0.0      1.0  motif_2,motif_5  \n",
       "999      1.0      0.0      0.0      0.0      0.0          motif_1  \n",
       "\n",
       "[1000 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file_path='DATA.csv'\n",
    "data=pd.read_csv(data_file_path)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "southern-oracle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [seq_no., seq, module, motif_1, motif_2, motif_3, motif_4, motif_5, motif_string]\n",
      "Index: []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_no.</th>\n",
       "      <th>seq</th>\n",
       "      <th>module</th>\n",
       "      <th>motif_1</th>\n",
       "      <th>motif_2</th>\n",
       "      <th>motif_3</th>\n",
       "      <th>motif_4</th>\n",
       "      <th>motif_5</th>\n",
       "      <th>motif_string</th>\n",
       "      <th>motif_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GGAGGAGGAAGAGGCTGGGCCCCTGCTGTGTGGGGGCAAGTTCCCA...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_2,motif_3</td>\n",
       "      <td>[motif_2, motif_3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CAAATACCCTGGGGTGCAATACGACTTATATCTCACGTATTGGAAG...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "      <td>[motif_1, motif_4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AACTAGGACACAGAAGTTGATCTAACGTAAACATCAAGAGCTTCCT...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "      <td>[motif_1, motif_4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CACAGCTGGGCCTGGTTGGTCTTTGTCCAGGGAACAATGGAGCGCC...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "      <td>[motif_1, motif_4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>TTGTTTTATTTGTTTGTTGGGGGGCGGCGGGGAGCGACAGGGGAGT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_2,motif_3</td>\n",
       "      <td>[motif_2, motif_3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>CTATTATTAAGAAATATACACAATTTTAACTTCAAATATCTCTCAT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_2,motif_3</td>\n",
       "      <td>[motif_2, motif_3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>ATTGATTCTCACTTGCTTGACTCAAGGGAGGGTTTGATTTTGGTCA...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "      <td>[motif_1, motif_4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>ATGTGGTTCTACCATATAGTTTATCAATTTTAAACAGGTAAAATAT...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1,motif_4</td>\n",
       "      <td>[motif_1, motif_4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>ATTTTGTTGGTTAGGTGATGGAAGTATGATGCTATTGATATTTCCC...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>motif_2,motif_5</td>\n",
       "      <td>[motif_2, motif_5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>AAGGAAAAGTGAGGAAGTATGGCCATTCCTCTGATAGGACACAAGA...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motif_1</td>\n",
       "      <td>[motif_1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     seq_no.                                                seq  module  \\\n",
       "0          0  GGAGGAGGAAGAGGCTGGGCCCCTGCTGTGTGGGGGCAAGTTCCCA...       0   \n",
       "1          1  CAAATACCCTGGGGTGCAATACGACTTATATCTCACGTATTGGAAG...       1   \n",
       "2          2  AACTAGGACACAGAAGTTGATCTAACGTAAACATCAAGAGCTTCCT...       1   \n",
       "3          3  CACAGCTGGGCCTGGTTGGTCTTTGTCCAGGGAACAATGGAGCGCC...       1   \n",
       "4          4  TTGTTTTATTTGTTTGTTGGGGGGCGGCGGGGAGCGACAGGGGAGT...       0   \n",
       "..       ...                                                ...     ...   \n",
       "995      995  CTATTATTAAGAAATATACACAATTTTAACTTCAAATATCTCTCAT...       0   \n",
       "996      996  ATTGATTCTCACTTGCTTGACTCAAGGGAGGGTTTGATTTTGGTCA...       1   \n",
       "997      997  ATGTGGTTCTACCATATAGTTTATCAATTTTAAACAGGTAAAATAT...       1   \n",
       "998      998  ATTTTGTTGGTTAGGTGATGGAAGTATGATGCTATTGATATTTCCC...       2   \n",
       "999      999  AAGGAAAAGTGAGGAAGTATGGCCATTCCTCTGATAGGACACAAGA...       1   \n",
       "\n",
       "     motif_1  motif_2  motif_3  motif_4  motif_5     motif_string  \\\n",
       "0        0.0      1.0      1.0      0.0      0.0  motif_2,motif_3   \n",
       "1        1.0      0.0      0.0      1.0      0.0  motif_1,motif_4   \n",
       "2        1.0      0.0      0.0      1.0      0.0  motif_1,motif_4   \n",
       "3        1.0      0.0      0.0      1.0      0.0  motif_1,motif_4   \n",
       "4        0.0      1.0      1.0      0.0      0.0  motif_2,motif_3   \n",
       "..       ...      ...      ...      ...      ...              ...   \n",
       "995      0.0      1.0      1.0      0.0      0.0  motif_2,motif_3   \n",
       "996      1.0      0.0      0.0      1.0      0.0  motif_1,motif_4   \n",
       "997      1.0      0.0      0.0      1.0      0.0  motif_1,motif_4   \n",
       "998      0.0      1.0      0.0      0.0      1.0  motif_2,motif_5   \n",
       "999      1.0      0.0      0.0      0.0      0.0          motif_1   \n",
       "\n",
       "             motif_list  \n",
       "0    [motif_2, motif_3]  \n",
       "1    [motif_1, motif_4]  \n",
       "2    [motif_1, motif_4]  \n",
       "3    [motif_1, motif_4]  \n",
       "4    [motif_2, motif_3]  \n",
       "..                  ...  \n",
       "995  [motif_2, motif_3]  \n",
       "996  [motif_1, motif_4]  \n",
       "997  [motif_1, motif_4]  \n",
       "998  [motif_2, motif_5]  \n",
       "999           [motif_1]  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data[data['motif_string'].isna()])\n",
    "data.dropna(subset=['motif_string'],inplace=True)\n",
    "data['motif_list']=data['motif_string'].apply(lambda x:x.split(','))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "concrete-freeze",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Motif-Index to Motif-Name Mapping:\n",
      "0 - motif_2\n",
      "1 - motif_3\n",
      "2 - motif_1\n",
      "3 - motif_4\n",
      "4 - motif_5\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "docs=data['motif_list'].values\n",
    "dictionary=Dictionary(docs)\n",
    "\n",
    "print('Motif-Index to Motif-Name Mapping:')\n",
    "for i,v in dictionary.items():\n",
    "    print(f'{i} - {v}')\n",
    "    if i==10:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "renewable-particular",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW (Sequence-0):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['motif_2', 'motif_3'], [(0, 1), (1, 1)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(doc) for doc in docs]\n",
    "print('BOW (Sequence-0):')\n",
    "docs[0],corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-sampling",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unlikely-accommodation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #setup logging for trainging metrics \n",
    "# import logging\n",
    "# logging.basicConfig(filename='test_output/model_callbacks.log', filemode='w',\n",
    "#                     format=\"%(asctime)s:%(levelname)s:%(message)s\",\n",
    "#                     level=logging.NOTSET)\n",
    "\n",
    "# from gensim.models.callbacks import Callback,PerplexityMetric, ConvergenceMetric, CoherenceMetric\n",
    "# perplexity_logger = PerplexityMetric(corpus=corpus, logger='shell')\n",
    "# convergence_logger = ConvergenceMetric(logger='shell')\n",
    "# # coherence_cv_logger = CoherenceMetric(corpus=corpus, coherence = 'c_v', texts = docs)\n",
    "\n",
    "# %%time\n",
    "# from gensim.models import LdaModel,LdaMulticore\n",
    "\n",
    "# #HYPERPARAMETERS\n",
    "# #passes = epochs\n",
    "# temp = dictionary[0]\n",
    "# id2word = dictionary.id2token\n",
    "# lda = LdaModel(corpus, id2word=id2word, alpha='auto',eval_every = 1,\\\n",
    "#                eta='auto',num_topics=3, iterations=5, passes = 10,\n",
    "#               callbacks=[perplexity_logger,convergence_logger])\n",
    "\n",
    "# lda.print_topics()\n",
    "\n",
    "# %%time\n",
    "# from gensim.models import LdaModel,LdaMulticore\n",
    "\n",
    "# id2word = dictionary.id2token\n",
    "# lda = LdaMulticore(corpus, id2word=id2word,eval_every = 1,\\\n",
    "#                eta='auto',num_topics=3, iterations=500, passes = 100)\n",
    "\n",
    "# import pyLDAvis.gensim\n",
    "\n",
    "# pyLDAvis.enable_notebook()\n",
    "# pyLDAvis.gensim.prepare(lda, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "possible-residence",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-22 04:53:31,950 : INFO : using autotuned alpha, starting with [0.33333334, 0.33333334, 0.33333334]\n",
      "2021-02-22 04:53:31,951 : INFO : using serial LDA version on this node\n",
      "2021-02-22 04:53:31,952 : INFO : running online (multi-pass) LDA training, 3 topics, 5 passes over the supplied corpus of 1000 documents, updating model once every 1000 documents, evaluating perplexity every 1000 documents, iterating 1000x with a convergence threshold of 0.001000\n",
      "2021-02-22 04:53:31,953 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2021-02-22 04:53:31,956 : DEBUG : bound: at document #0\n",
      "2021-02-22 04:53:32,581 : INFO : -2.623 per-word bound, 6.2 perplexity estimate based on a held-out corpus of 1000 documents with 1931 words\n",
      "2021-02-22 04:53:32,582 : INFO : PROGRESS: pass 0, at document #1000/1000\n",
      "2021-02-22 04:53:32,583 : DEBUG : performing inference on a chunk of 1000 documents\n",
      "2021-02-22 04:53:33,078 : DEBUG : 1000/1000 documents converged within 1000 iterations\n",
      "2021-02-22 04:53:33,082 : INFO : optimized alpha [0.40847948, 0.4121309, 0.34562325]\n",
      "2021-02-22 04:53:33,083 : DEBUG : updating topics\n",
      "2021-02-22 04:53:33,084 : INFO : topic #0 (0.408): 0.337*\"motif_2\" + 0.318*\"motif_3\" + 0.299*\"motif_1\" + 0.029*\"motif_5\" + 0.016*\"motif_4\"\n",
      "2021-02-22 04:53:33,085 : INFO : topic #1 (0.412): 0.380*\"motif_1\" + 0.371*\"motif_4\" + 0.126*\"motif_2\" + 0.120*\"motif_3\" + 0.003*\"motif_5\"\n",
      "2021-02-22 04:53:33,086 : INFO : topic #2 (0.346): 0.432*\"motif_2\" + 0.378*\"motif_3\" + 0.094*\"motif_1\" + 0.049*\"motif_5\" + 0.047*\"motif_4\"\n",
      "2021-02-22 04:53:33,087 : INFO : topic diff=1.136525, rho=1.000000\n",
      "2021-02-22 04:53:33,089 : INFO : Epoch 0: Convergence estimate: 0.0\n",
      "2021-02-22 04:53:33,095 : DEBUG : bound: at document #0\n",
      "2021-02-22 04:53:33,564 : INFO : -1.765 per-word bound, 3.4 perplexity estimate based on a held-out corpus of 1000 documents with 1931 words\n",
      "2021-02-22 04:53:33,565 : INFO : PROGRESS: pass 1, at document #1000/1000\n",
      "2021-02-22 04:53:33,566 : DEBUG : performing inference on a chunk of 1000 documents\n",
      "2021-02-22 04:53:33,800 : DEBUG : 1000/1000 documents converged within 1000 iterations\n",
      "2021-02-22 04:53:33,804 : INFO : optimized alpha [0.3836075, 0.43520436, 0.3719089]\n",
      "2021-02-22 04:53:33,804 : DEBUG : updating topics\n",
      "2021-02-22 04:53:33,805 : INFO : topic #0 (0.384): 0.334*\"motif_2\" + 0.323*\"motif_3\" + 0.311*\"motif_1\" + 0.021*\"motif_5\" + 0.011*\"motif_4\"\n",
      "2021-02-22 04:53:33,806 : INFO : topic #1 (0.435): 0.485*\"motif_1\" + 0.395*\"motif_4\" + 0.061*\"motif_2\" + 0.058*\"motif_3\" + 0.002*\"motif_5\"\n",
      "2021-02-22 04:53:33,807 : INFO : topic #2 (0.372): 0.479*\"motif_2\" + 0.428*\"motif_3\" + 0.050*\"motif_5\" + 0.030*\"motif_1\" + 0.014*\"motif_4\"\n",
      "2021-02-22 04:53:33,808 : INFO : topic diff=0.412055, rho=0.577350\n",
      "2021-02-22 04:53:33,809 : INFO : Epoch 1: Convergence estimate: 0.0\n",
      "2021-02-22 04:53:33,812 : DEBUG : bound: at document #0\n",
      "2021-02-22 04:53:34,044 : INFO : -1.643 per-word bound, 3.1 perplexity estimate based on a held-out corpus of 1000 documents with 1931 words\n",
      "2021-02-22 04:53:34,045 : INFO : PROGRESS: pass 2, at document #1000/1000\n",
      "2021-02-22 04:53:34,045 : DEBUG : performing inference on a chunk of 1000 documents\n",
      "2021-02-22 04:53:34,226 : DEBUG : 1000/1000 documents converged within 1000 iterations\n",
      "2021-02-22 04:53:34,231 : INFO : optimized alpha [0.3488361, 0.4451995, 0.3894935]\n",
      "2021-02-22 04:53:34,232 : DEBUG : updating topics\n",
      "2021-02-22 04:53:34,234 : INFO : topic #0 (0.349): 0.333*\"motif_2\" + 0.326*\"motif_3\" + 0.318*\"motif_1\" + 0.015*\"motif_5\" + 0.008*\"motif_4\"\n",
      "2021-02-22 04:53:34,235 : INFO : topic #1 (0.445): 0.534*\"motif_1\" + 0.401*\"motif_4\" + 0.033*\"motif_2\" + 0.031*\"motif_3\" + 0.001*\"motif_5\"\n",
      "2021-02-22 04:53:34,236 : INFO : topic #2 (0.389): 0.490*\"motif_2\" + 0.440*\"motif_3\" + 0.049*\"motif_5\" + 0.014*\"motif_1\" + 0.006*\"motif_4\"\n",
      "2021-02-22 04:53:34,237 : INFO : topic diff=0.302012, rho=0.500000\n",
      "2021-02-22 04:53:34,238 : INFO : Epoch 2: Convergence estimate: 0.0\n",
      "2021-02-22 04:53:34,244 : DEBUG : bound: at document #0\n",
      "2021-02-22 04:53:34,669 : INFO : -1.594 per-word bound, 3.0 perplexity estimate based on a held-out corpus of 1000 documents with 1931 words\n",
      "2021-02-22 04:53:34,670 : INFO : PROGRESS: pass 3, at document #1000/1000\n",
      "2021-02-22 04:53:34,671 : DEBUG : performing inference on a chunk of 1000 documents\n",
      "2021-02-22 04:53:34,903 : DEBUG : 1000/1000 documents converged within 1000 iterations\n",
      "2021-02-22 04:53:34,907 : INFO : optimized alpha [0.31811523, 0.45012698, 0.40301856]\n",
      "2021-02-22 04:53:34,908 : DEBUG : updating topics\n",
      "2021-02-22 04:53:34,909 : INFO : topic #0 (0.318): 0.332*\"motif_2\" + 0.329*\"motif_3\" + 0.323*\"motif_1\" + 0.011*\"motif_5\" + 0.006*\"motif_4\"\n",
      "2021-02-22 04:53:34,910 : INFO : topic #1 (0.450): 0.559*\"motif_1\" + 0.402*\"motif_4\" + 0.019*\"motif_2\" + 0.019*\"motif_3\" + 0.001*\"motif_5\"\n",
      "2021-02-22 04:53:34,911 : INFO : topic #2 (0.403): 0.494*\"motif_2\" + 0.446*\"motif_3\" + 0.049*\"motif_5\" + 0.008*\"motif_1\" + 0.004*\"motif_4\"\n",
      "2021-02-22 04:53:34,911 : INFO : topic diff=0.254534, rho=0.447214\n",
      "2021-02-22 04:53:34,913 : INFO : Epoch 3: Convergence estimate: 0.0\n",
      "2021-02-22 04:53:34,922 : DEBUG : bound: at document #0\n",
      "2021-02-22 04:53:35,416 : INFO : -1.566 per-word bound, 3.0 perplexity estimate based on a held-out corpus of 1000 documents with 1931 words\n",
      "2021-02-22 04:53:35,417 : INFO : PROGRESS: pass 4, at document #1000/1000\n",
      "2021-02-22 04:53:35,418 : DEBUG : performing inference on a chunk of 1000 documents\n",
      "2021-02-22 04:53:35,837 : DEBUG : 1000/1000 documents converged within 1000 iterations\n",
      "2021-02-22 04:53:35,846 : INFO : optimized alpha [0.29233158, 0.45264676, 0.4140119]\n",
      "2021-02-22 04:53:35,846 : DEBUG : updating topics\n",
      "2021-02-22 04:53:35,847 : INFO : topic #0 (0.292): 0.330*\"motif_2\" + 0.329*\"motif_3\" + 0.328*\"motif_1\" + 0.008*\"motif_5\" + 0.005*\"motif_4\"\n",
      "2021-02-22 04:53:35,847 : INFO : topic #1 (0.453): 0.573*\"motif_1\" + 0.402*\"motif_4\" + 0.012*\"motif_2\" + 0.012*\"motif_3\" + 0.001*\"motif_5\"\n",
      "2021-02-22 04:53:35,848 : INFO : topic #2 (0.414): 0.496*\"motif_2\" + 0.448*\"motif_3\" + 0.048*\"motif_5\" + 0.005*\"motif_1\" + 0.002*\"motif_4\"\n",
      "2021-02-22 04:53:35,849 : INFO : topic diff=0.224266, rho=0.408248\n",
      "2021-02-22 04:53:35,850 : INFO : Epoch 4: Convergence estimate: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.91 s, sys: 161 ms, total: 4.07 s\n",
      "Wall time: 3.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import logging\n",
    "from gensim.models.callbacks import Callback,PerplexityMetric, ConvergenceMetric, CoherenceMetric\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.DEBUG)\n",
    "convergence_logger = ConvergenceMetric(logger='shell')\n",
    "from gensim.models import LdaModel,LdaMulticore\n",
    "\n",
    "temp = dictionary[0]\n",
    "id2word = dictionary.id2token\n",
    "lda = LdaModel(corpus, id2word=id2word, alpha='auto',chunksize=10000,\n",
    "               eta='auto',num_topics=3, iterations=1000, passes = 5,\n",
    "              minimum_probability=0.0,callbacks=[convergence_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fitting-extreme",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopicDistribution(predictions,ntopics):\n",
    "    topic_count_dict={i:0 for i in range(ntopics)}\n",
    "    ndocs=len(predictions)\n",
    "    for pred in predictions:\n",
    "        top_topic=sorted(pred,key=lambda x:-x[1])[0][0]\n",
    "        topic_count_dict[top_topic]+=1\n",
    "    topic_dist_dict={k:v/ndocs for k,v in topic_count_dict.items()}\n",
    "    return topic_dist_dict\n",
    "\n",
    "def likelihoodMetric(predictions,ntopics):\n",
    "    likelihood=0\n",
    "    P_T=getTopicDistribution(predictions,ntopics)\n",
    "#     print(P_T)\n",
    "    for pred in tqdm(predictions):\n",
    "        P_Xi_M=0\n",
    "        for topic_no,P_Xi_T in pred:\n",
    "            P_Xi_M+=P_Xi_T*P_T[topic_no]\n",
    "        likelihood+=np.log10(P_Xi_M)\n",
    "    print(likelihood)\n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "amber-superior",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "def coherenceMetric_cv(model,dictionary,docs):\n",
    "    cm=CoherenceModel(model=model,dictionary=dictionary ,\n",
    "                      texts=docs, coherence='c_v',processes=30,\n",
    "                     window_size=2000)\n",
    "    coherence = cm.get_coherence()\n",
    "    print(coherence)\n",
    "    return coherence\n",
    "# coherenceMetric_cv(lda,dictionary ,docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "informational-mileage",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "def coherenceMetric_umass(model,dictionary,corpus):\n",
    "    cm = CoherenceModel(model=model, corpus=corpus, \\\n",
    "                        coherence='u_mass',processes=30)\n",
    "    coherence = cm.get_coherence()\n",
    "    print(coherence)\n",
    "    return coherence\n",
    "# coherenceMetric_umass(lda,dictionary ,corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "mysterious-baseline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-12.312024693235896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-12.312024693235896"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "def coherenceMetric_uci(model,dictionary,docs):\n",
    "    cm=CoherenceModel(model=model,dictionary=dictionary ,\n",
    "                      texts=docs, coherence='c_uci',processes=30,\n",
    "                     window_size =2000)\n",
    "    coherence = cm.get_coherence()\n",
    "    print(coherence)\n",
    "    return coherence\n",
    "coherenceMetric_uci(lda,dictionary ,docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "pharmaceutical-interpretation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexityMetric(model,corpus):\n",
    "    perplexity=model.log_perplexity(corpus)\n",
    "    print(perplexity)\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "sustainable-bottle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "\n",
    "def randIndexMetric(predictions,data):\n",
    "    pred_topic=[]\n",
    "    for pred in tqdm(predictions):\n",
    "        topic_prob=sorted(pred,key=lambda x:-x[1])\n",
    "#         print(topic_prob)\n",
    "        top_topic=topic_prob[0][0]\n",
    "        pred_topic.append(top_topic)\n",
    "    _data=data.copy()\n",
    "    _data['pred_topic']=pred_topic\n",
    "    ari=adjusted_rand_score(_data['module'], _data['pred_topic'])\n",
    "    print(ari)\n",
    "    return ari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "characteristic-retreat",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def findTopMotifs(predictions,ntopics,data,ntop=5,outdir=None):\n",
    "    pred_topic=[]\n",
    "    for pred in tqdm(predictions):\n",
    "        topic_prob=sorted(pred,key=lambda x:-x[1])\n",
    "#         print(topic_prob)\n",
    "        top_topic=topic_prob[0][0]\n",
    "        pred_topic.append(top_topic)\n",
    "    _data=data.copy()\n",
    "    _data['pred_topic']=pred_topic      \n",
    "    gb=_data[['motif_string','pred_topic']].groupby('pred_topic').\\\n",
    "    agg(lambda x: ','.join(x))\n",
    "    gb['top_motif']=gb['motif_string'].\\\n",
    "    apply(lambda x:Counter(x.split(',')).most_common(ntop))\n",
    "    gb.reset_index(inplace=True)\n",
    "    gb=gb[['pred_topic','top_motif']]\n",
    "    if outdir is not None:\n",
    "        gb.to_csv(f'{outdir}/top{ntop}_motifs_topics_{ntopics}.csv',index=False)\n",
    "    print(gb)\n",
    "    return gb\n",
    "# findTopMotifs(lda,corpus,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "south-desperate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Num of Topics = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding likelihood...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 3626.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-302.32415022479415\n",
      "\n",
      "Finding coherence_cv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2205051034908483\n",
      "\n",
      "Finding coherence_umass...\n",
      "-13.967991647765\n",
      "\n",
      "Finding coherence_uci...\n",
      "-12.312024693235895\n",
      "\n",
      "Finding perplexity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 397/1000 [00:00<00:00, 3968.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.473915368259717\n",
      "\n",
      "Finding ARI...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 3919.42it/s]\n",
      " 39%|███▉      | 390/1000 [00:00<00:00, 3897.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9192853128937568\n",
      "\n",
      "Finding Top Motifs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 4144.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pred_topic                                          top_motif\n",
      "0           0                   [(motif_1, 478), (motif_4, 325)]\n",
      "1           1  [(motif_2, 520), (motif_3, 480), (motif_1, 86)...\n",
      "\n",
      "========================================\n",
      "Num of Topics = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding likelihood...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 4051.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-364.47065932293685\n",
      "\n",
      "Finding coherence_cv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2205051034908483\n",
      "\n",
      "Finding coherence_umass...\n",
      "-13.767439729531013\n",
      "\n",
      "Finding coherence_uci...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 462/1000 [00:00<00:00, 4618.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-12.312024693235893\n",
      "\n",
      "Finding perplexity...\n",
      "-1.4967155886060644\n",
      "\n",
      "Finding ARI...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 4628.16it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 5934.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "\n",
      "Finding Top Motifs...\n",
      "   pred_topic                                        top_motif\n",
      "0           0  [(motif_2, 480), (motif_3, 480), (motif_1, 86)]\n",
      "1           1                 [(motif_1, 478), (motif_4, 325)]\n",
      "2           2                   [(motif_5, 42), (motif_2, 40)]\n",
      "\n",
      "========================================\n",
      "Num of Topics = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding likelihood...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 5793.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-375.384128621809\n",
      "\n",
      "Finding coherence_cv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22050510349084834\n",
      "\n",
      "Finding coherence_umass...\n",
      "-13.804751389115989\n",
      "\n",
      "Finding coherence_uci...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-12.312024693235895\n",
      "\n",
      "Finding perplexity...\n",
      "-1.488410741733199\n",
      "\n",
      "Finding ARI...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 4985.15it/s]\n",
      " 40%|████      | 400/1000 [00:00<00:00, 3997.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "\n",
      "Finding Top Motifs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 3873.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pred_topic                                        top_motif\n",
      "0           0                   [(motif_5, 42), (motif_2, 40)]\n",
      "1           2  [(motif_2, 480), (motif_3, 480), (motif_1, 86)]\n",
      "2           3                 [(motif_1, 478), (motif_4, 325)]\n",
      "\n",
      "========================================\n",
      "Num of Topics = 5\n",
      "\n",
      "Finding likelihood...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 2703.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-539.0296799635103\n",
      "\n",
      "Finding coherence_cv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22050510349084834\n",
      "\n",
      "Finding coherence_umass...\n",
      "-13.809686732224751\n",
      "\n",
      "Finding coherence_uci...\n",
      "-12.312024693235895\n",
      "\n",
      "Finding perplexity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 81/1000 [00:00<00:01, 808.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.7036223107517723\n",
      "\n",
      "Finding ARI...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1877.94it/s]\n",
      " 32%|███▏      | 317/1000 [00:00<00:00, 3163.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7742750476101841\n",
      "\n",
      "Finding Top Motifs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 3074.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pred_topic                                       top_motif\n",
      "0           0   [(motif_1, 85), (motif_2, 85), (motif_3, 85)]\n",
      "1           1                  [(motif_5, 42), (motif_2, 40)]\n",
      "2           2                [(motif_1, 478), (motif_4, 325)]\n",
      "3           3  [(motif_2, 343), (motif_3, 343), (motif_1, 1)]\n",
      "4           4                  [(motif_2, 52), (motif_3, 52)]\n",
      "\n",
      "========================================\n",
      "Num of Topics = 6\n",
      "\n",
      "Finding likelihood...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 2661.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-514.210144591325\n",
      "\n",
      "Finding coherence_cv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22050510349084831\n",
      "\n",
      "Finding coherence_umass...\n",
      "-13.85783076353777\n",
      "\n",
      "Finding coherence_uci...\n",
      "-12.312024693235896\n",
      "\n",
      "Finding perplexity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 236/1000 [00:00<00:00, 2354.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.7137906493002704\n",
      "\n",
      "Finding ARI...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 4084.31it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 5751.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7963700673703145\n",
      "\n",
      "Finding Top Motifs...\n",
      "   pred_topic                                        top_motif\n",
      "0           1                                 [(motif_1, 153)]\n",
      "1           2                   [(motif_5, 42), (motif_2, 40)]\n",
      "2           3                 [(motif_1, 325), (motif_4, 325)]\n",
      "3           4  [(motif_2, 480), (motif_3, 480), (motif_1, 86)]\n",
      "\n",
      "========================================\n",
      "Num of Topics = 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding likelihood...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 4270.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-513.2953131900758\n",
      "\n",
      "Finding coherence_cv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2205051034908483\n",
      "\n",
      "Finding coherence_umass...\n",
      "-13.93275525385043\n",
      "\n",
      "Finding coherence_uci...\n",
      "-12.312024693235896\n",
      "\n",
      "Finding perplexity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 5201.77it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.8041608287286783\n",
      "\n",
      "Finding ARI...\n",
      "0.8654966310752661\n",
      "\n",
      "Finding Top Motifs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 5059.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pred_topic                                       top_motif\n",
      "0           0                [(motif_1, 478), (motif_4, 325)]\n",
      "1           2   [(motif_1, 17), (motif_2, 17), (motif_3, 17)]\n",
      "2           3   [(motif_1, 62), (motif_2, 62), (motif_3, 62)]\n",
      "3           4                  [(motif_5, 42), (motif_2, 40)]\n",
      "4           5  [(motif_2, 401), (motif_3, 401), (motif_1, 7)]\n",
      "\n",
      "========================================\n",
      "Num of Topics = 8\n",
      "\n",
      "Finding likelihood...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 2960.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-543.6002878911627\n",
      "\n",
      "Finding coherence_cv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22050510349084834\n",
      "\n",
      "Finding coherence_umass...\n",
      "-13.917808724203535\n",
      "\n",
      "Finding coherence_uci...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-12.312024693235895\n",
      "\n",
      "Finding perplexity...\n",
      "-1.8570136563347943\n",
      "\n",
      "Finding ARI...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 5004.48it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 5313.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7923902843361939\n",
      "\n",
      "Finding Top Motifs...\n",
      "   pred_topic                                        top_motif\n",
      "0           3                 [(motif_1, 325), (motif_4, 325)]\n",
      "1           4                                 [(motif_1, 153)]\n",
      "2           5  [(motif_2, 480), (motif_3, 480), (motif_1, 86)]\n",
      "3           6                   [(motif_5, 42), (motif_2, 40)]\n",
      "\n",
      "========================================\n",
      "Num of Topics = 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding likelihood...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 4599.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-495.44739069563536\n",
      "\n",
      "Finding coherence_cv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22050510349084834\n",
      "\n",
      "Finding coherence_umass...\n",
      "-13.770843840832693\n",
      "\n",
      "Finding coherence_uci...\n",
      "-12.312024693235895\n",
      "\n",
      "Finding perplexity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 5118.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.85584503191353\n",
      "\n",
      "Finding ARI...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 5048.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9236961587913273\n",
      "\n",
      "Finding Top Motifs...\n",
      "   pred_topic                                        top_motif\n",
      "0           0                   [(motif_5, 42), (motif_2, 40)]\n",
      "1           2    [(motif_1, 28), (motif_2, 28), (motif_3, 28)]\n",
      "2           3  [(motif_2, 433), (motif_3, 433), (motif_1, 39)]\n",
      "3           4    [(motif_1, 19), (motif_2, 19), (motif_3, 19)]\n",
      "4           7                 [(motif_1, 478), (motif_4, 325)]\n",
      "CPU times: user 31.2 s, sys: 2.83 s, total: 34 s\n",
      "Wall time: 34.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_topics</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>coherence_cv</th>\n",
       "      <th>coherence_umass</th>\n",
       "      <th>coherence_uci</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>ARI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>-302.324150</td>\n",
       "      <td>0.220505</td>\n",
       "      <td>-13.967992</td>\n",
       "      <td>-12.312025</td>\n",
       "      <td>-1.473915</td>\n",
       "      <td>0.919285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>-364.470659</td>\n",
       "      <td>0.220505</td>\n",
       "      <td>-13.767440</td>\n",
       "      <td>-12.312025</td>\n",
       "      <td>-1.496716</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>-375.384129</td>\n",
       "      <td>0.220505</td>\n",
       "      <td>-13.804751</td>\n",
       "      <td>-12.312025</td>\n",
       "      <td>-1.488411</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>-539.029680</td>\n",
       "      <td>0.220505</td>\n",
       "      <td>-13.809687</td>\n",
       "      <td>-12.312025</td>\n",
       "      <td>-1.703622</td>\n",
       "      <td>0.774275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>-514.210145</td>\n",
       "      <td>0.220505</td>\n",
       "      <td>-13.857831</td>\n",
       "      <td>-12.312025</td>\n",
       "      <td>-1.713791</td>\n",
       "      <td>0.796370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>-513.295313</td>\n",
       "      <td>0.220505</td>\n",
       "      <td>-13.932755</td>\n",
       "      <td>-12.312025</td>\n",
       "      <td>-1.804161</td>\n",
       "      <td>0.865497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>-543.600288</td>\n",
       "      <td>0.220505</td>\n",
       "      <td>-13.917809</td>\n",
       "      <td>-12.312025</td>\n",
       "      <td>-1.857014</td>\n",
       "      <td>0.792390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>-495.447391</td>\n",
       "      <td>0.220505</td>\n",
       "      <td>-13.770844</td>\n",
       "      <td>-12.312025</td>\n",
       "      <td>-1.855845</td>\n",
       "      <td>0.923696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_topics  likelihood  coherence_cv  coherence_umass  coherence_uci  \\\n",
       "0           2 -302.324150      0.220505       -13.967992     -12.312025   \n",
       "1           3 -364.470659      0.220505       -13.767440     -12.312025   \n",
       "2           4 -375.384129      0.220505       -13.804751     -12.312025   \n",
       "3           5 -539.029680      0.220505       -13.809687     -12.312025   \n",
       "4           6 -514.210145      0.220505       -13.857831     -12.312025   \n",
       "5           7 -513.295313      0.220505       -13.932755     -12.312025   \n",
       "6           8 -543.600288      0.220505       -13.917809     -12.312025   \n",
       "7           9 -495.447391      0.220505       -13.770844     -12.312025   \n",
       "\n",
       "   perplexity       ARI  \n",
       "0   -1.473915  0.919285  \n",
       "1   -1.496716  1.000000  \n",
       "2   -1.488411  1.000000  \n",
       "3   -1.703622  0.774275  \n",
       "4   -1.713791  0.796370  \n",
       "5   -1.804161  0.865497  \n",
       "6   -1.857014  0.792390  \n",
       "7   -1.855845  0.923696  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "from gensim.models import LdaModel,LdaMulticore\n",
    "\n",
    "outdir='model_output'\n",
    "eval_dict={'num_topics':[],'likelihood':[],'coherence_cv':[],\\\n",
    "          'coherence_umass':[],'coherence_uci':[],'perplexity':[],\n",
    "          'ARI':[]}\n",
    "temp = dictionary[0]\n",
    "id2word = dictionary.id2token\n",
    "for ntopics in range(2,10):\n",
    "    print('\\n'+'='*40)\n",
    "    print('Num of Topics = '+str(ntopics))\n",
    "    model = LdaModel(corpus, id2word=id2word, alpha='auto',chunksize=10000,\n",
    "                   eta='auto',num_topics=ntopics, iterations=1000, passes = 5,\n",
    "                  minimum_probability=0.0)\n",
    "    \n",
    "    predictions=model.get_document_topics(corpus,minimum_probability=0.0)\n",
    "    print('\\nFinding likelihood...')\n",
    "    likelihood=likelihoodMetric(predictions,ntopics)\n",
    "    print('\\nFinding coherence_cv...')\n",
    "    coherence_cv=coherenceMetric_cv(model,dictionary,docs)\n",
    "    print('\\nFinding coherence_umass...')\n",
    "    coherence_umass=coherenceMetric_umass(model,dictionary ,corpus)\n",
    "    print('\\nFinding coherence_uci...')\n",
    "    coherence_uci=coherenceMetric_uci(model,dictionary,docs)\n",
    "    print('\\nFinding perplexity...')\n",
    "    perplexity=perplexityMetric(model,corpus)\n",
    "    print('\\nFinding ARI...')\n",
    "    ari=randIndexMetric(predictions,data)\n",
    "    print('\\nFinding Top Motifs...')\n",
    "    findTopMotifs(predictions,ntopics,data,outdir=outdir)\n",
    "#     print('Findng avg. distance from TSS per topic...')\n",
    "#     getAvgTssDist(predictions,ntopics,data,outdir=outdir)\n",
    "    eval_dict['num_topics'].append(ntopics)\n",
    "    eval_dict['likelihood'].append(likelihood)\n",
    "    eval_dict['coherence_cv'].append(coherence_cv)\n",
    "    eval_dict['coherence_umass'].append(coherence_umass)\n",
    "    eval_dict['coherence_uci'].append(coherence_uci)\n",
    "    eval_dict['perplexity'].append(perplexity)\n",
    "    eval_dict['ARI'].append(ari)\n",
    "eval_df=pd.DataFrame(eval_dict)\n",
    "eval_df.to_csv(f'{outdir}/metrics.csv',index=False)\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-marsh",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
