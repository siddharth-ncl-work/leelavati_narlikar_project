1. [Biology Paper] https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1001046#s2

2. [Gensim] https://www.meganstodel.com/posts/callbacks/

3. [Strand info during annotation] https://www.biostars.org/p/251361/
   -annotatePeaks.pl finds motifs from both + and - strands

4. [Gensim LDA] https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html

5. [OTHER LDA LIBRARIES]
https://ieeexplore.ieee.org/abstract/document/8250563

=======================================================

* [GENSIM PAPERS]
- https://ieeexplore.ieee.org/abstract/document/9314588

- https://airccj.org/CSCP/vol6/csit65316.pdf

=========================================================

* [HOW TO CHOOSE NO. OF PASS AND NO. OF ITERATIONS]
- https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24

- https://groups.google.com/g/gensim/c/OF7XL1lm8mY?pli=1

- https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html

- https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/#12buildingthetopicmodel

- https://www.analyticsvidhya.com/blog/2016/08/beginners-guide-to-topic-modeling-in-python/

- https://ourcodingclub.github.io/tutorials/topic-modelling-python/

- https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/

==============================================================

* [HOW TO EVALUATE LDA MODELS]
- As a rule of thumb for a good LDA model, the perplexity score should be low while coherence should be high. (https://ieeexplore.ieee.org/abstract/document/9314588)

-https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0

-https://datascienceplus.com/evaluation-of-topic-modeling-topic-coherence/

-https://ieeexplore.ieee.org/abstract/document/8501887

-https://stackabuse.com/python-for-nlp-working-with-the-gensim-library-part-2/
=======================================================================

** 16/2/2021 **

-for now 3 clusters
-absolute value of distance from TSS = kind of validation metric
-top frequently occuring motifs 
-remove similar column as duplicate columns don't have any more information
-plot color coded module vs motifs 

X=Seq
M=Model
m=Total No. of Topics

P(X|M) = sum over m P(X,T|M)

P(X,T)=P(X|T)P(T)

[TASKS]
* duplicate motifs were identified
* iterations (int, optional) – Maximum number of iterations through the corpus when inferring the topic distribution of a corpus
* https://radimrehurek.com/gensim/models/ldamodel.html

[Questions]
* which strand to use (+/-)? right now, annotatePeaks.pl finds motifs from both + and - strands
* How to measure similarity between two motif columns?
* Plot

========================================================================

** 17/2/2021 **

Leelavati Narlikar10:51 AM
cisTopic
Leelavati Narlikar10:55 AM
ATAC-seq
dnaseq
DNase-seq
RNA-seq
Leelavati Narlikar10:56 AM
don't

Train different models by increasing number of topics
rank each model by following metric
likelihood of product of probality of each seq condition on model
validation metric=prod over seq[P(Xi|M)]
P(Xi|M)=sum over topic[P(X,Ti|M)]
P(Xi,T)=P(Xi|T)P(T)
we expect the value of validation metric to increase with increasing no. of topics
validation metric: higher value is better

Do this for example data as well as on real data

Steps to use homer for example data:
- background file: /home/vanka/siddharth/leelavati_narlikar_project/homer/data/genomes/hg38/preparsed/hg38.200.seq
- convert need to convert background into 'fasta' format
- use following command 
>>findMotifs.pl <targetSequences.fa> fasta <output directory> -fasta <background.fa> [options]
targetSequences.fa = example.fa
background.fa = hg38.200.seq
[http://homer.ucsd.edu/homer/motif/fasta.html]

Future bigger picture:
cisTopic for single cells and combine it with LDA for DNA in single cell
https://www.nature.com/articles/s41592-019-0367-1

[TASKS]
* fasta2tab.pl, tab2fasta.pl - convert between HOMER-style sequence file and a FASTA file 
File conversion resources: http://homer.ucsd.edu/homer/introduction/programs.html
                           https://www.biostars.org/p/271977/
                           https://molbiol-tools.ca/Convert.htm
FASTA file Format: https://bioperl.org/formats/sequence_formats/FASTA_sequence_format
                   https://zhanglab.ccmb.med.umich.edu/FASTA/
                   https://en.wikipedia.org/wiki/FASTA_format
* P(T):
alpha ({numpy.ndarray, str}, optional) –
Can be set to an 1D array of length equal to the number of expected topics that expresses our a-priori belief for the each topics’ probability. Alternatively default prior selecting strategies can be employed by supplying a string:
’symmetric’: Default; uses a fixed symmetric prior per topic,
’asymmetric’: Uses a fixed normalized asymmetric prior of 1.0 / (topic_index + sqrt(num_topics)),
’auto’: Learns an asymmetric prior from the corpus (not available if distributed==True).

* P(Xi|T):
get_document_topics(bow, minimum_probability=None, minimum_phi_value=None, per_word_topics=False)
Returns
list of (int, float) – Topic distribution for the whole document. Each element in the list is a pair of a topic’s id, and the probability that was assigned to it.
[(0, 0.56868815), (1, 0.366404), (2, 0.064907864)]

* How to evaluate LDA models:
As a rule of thumb for a good LDA model, the perplexity score should be low while coherence should be high. (https://ieeexplore.ieee.org/abstract/document/9314588)

[QUESTIONS]
* likelihood metric is not working as expected

====================================================================

** 22/02/2021 **
[(0, 0.56868815), (1, 0.366404), (2, 0.064907864)]
This is not P(Xi|T), it is P(T|X)
my P(X|T) is actually P(T|X)

[TASKS]
1. Reverse Engineer P(X|T) and P(T|X) from 'model.show_topics()' (ie. term_topic distribtion)

2. Add 6th random motif in example.fa (whole corpus) with the probability of 10% and check the model perfomance (ie. ARI)

3. For example.fa and fixed 3 topics evaluate lda(calculate different metrics like ARI) on a grid of 'iteration' and 'passes' (ie. ARI)

4. reproduce on cisTopic results

============================================================================

** 24/02/2021 **

[TASKS]
1. check whether sum over motifs P(mj|T) is equal to one

2. Generate a clean dataset (as follows). Check the value of alpha obtained from the trained gensim model on this clean data.
45% - motif_1,2
45% - motif_3,4
10% - motif_5,6
symmetric,asymmetric,auto

3. Check how LDA Model works