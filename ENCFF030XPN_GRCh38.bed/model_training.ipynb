{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acute-accreditation",
   "metadata": {},
   "source": [
    "# LDA Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "southeast-hampshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-pension",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "downtown-phrase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PeakID</th>\n",
       "      <th>Distance to TSS</th>\n",
       "      <th>motif_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seq_40800</td>\n",
       "      <td>-81</td>\n",
       "      <td>motif_149,motif_162,motif_166,motif_166,motif_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seq_10314</td>\n",
       "      <td>-228</td>\n",
       "      <td>motif_144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seq_18866</td>\n",
       "      <td>9616</td>\n",
       "      <td>motif_104,motif_126,motif_126,motif_147,motif_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seq_45348</td>\n",
       "      <td>5770</td>\n",
       "      <td>motif_120,motif_121,motif_128,motif_128,motif_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seq_2616</td>\n",
       "      <td>-12540</td>\n",
       "      <td>motif_100,motif_103,motif_126,motif_126,motif_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60095</th>\n",
       "      <td>seq_5507</td>\n",
       "      <td>-127293</td>\n",
       "      <td>motif_137,motif_137,motif_13,motif_174,motif_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60096</th>\n",
       "      <td>seq_11070</td>\n",
       "      <td>37721</td>\n",
       "      <td>motif_132,motif_132,motif_132,motif_142,motif_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60097</th>\n",
       "      <td>seq_17945</td>\n",
       "      <td>88589</td>\n",
       "      <td>motif_161,motif_162,motif_162,motif_174,motif_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60098</th>\n",
       "      <td>seq_29137</td>\n",
       "      <td>93216</td>\n",
       "      <td>motif_104,motif_105,motif_117,motif_117,motif_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60099</th>\n",
       "      <td>seq_48859</td>\n",
       "      <td>74528</td>\n",
       "      <td>motif_136,motif_145,motif_146,motif_158,motif_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PeakID  Distance to TSS  \\\n",
       "0      seq_40800              -81   \n",
       "1      seq_10314             -228   \n",
       "2      seq_18866             9616   \n",
       "3      seq_45348             5770   \n",
       "4       seq_2616           -12540   \n",
       "...          ...              ...   \n",
       "60095   seq_5507          -127293   \n",
       "60096  seq_11070            37721   \n",
       "60097  seq_17945            88589   \n",
       "60098  seq_29137            93216   \n",
       "60099  seq_48859            74528   \n",
       "\n",
       "                                            motif_string  \n",
       "0      motif_149,motif_162,motif_166,motif_166,motif_...  \n",
       "1                                              motif_144  \n",
       "2      motif_104,motif_126,motif_126,motif_147,motif_...  \n",
       "3      motif_120,motif_121,motif_128,motif_128,motif_...  \n",
       "4      motif_100,motif_103,motif_126,motif_126,motif_...  \n",
       "...                                                  ...  \n",
       "60095  motif_137,motif_137,motif_13,motif_174,motif_1...  \n",
       "60096  motif_132,motif_132,motif_132,motif_142,motif_...  \n",
       "60097  motif_161,motif_162,motif_162,motif_174,motif_...  \n",
       "60098  motif_104,motif_105,motif_117,motif_117,motif_...  \n",
       "60099  motif_136,motif_145,motif_146,motif_158,motif_...  \n",
       "\n",
       "[60100 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file_path='DATA.csv'\n",
    "data=pd.read_csv(data_file_path)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "southern-oracle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          PeakID  Distance to TSS motif_string\n",
      "18840  seq_57232             -180          NaN\n",
      "23892  seq_20216             -147          NaN\n",
      "29667  seq_31231              483          NaN\n",
      "46832   seq_8465             -341          NaN\n",
      "47219  seq_46451             4737          NaN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PeakID</th>\n",
       "      <th>Distance to TSS</th>\n",
       "      <th>motif_string</th>\n",
       "      <th>motif_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seq_40800</td>\n",
       "      <td>-81</td>\n",
       "      <td>motif_149,motif_162,motif_166,motif_166,motif_...</td>\n",
       "      <td>[motif_149, motif_162, motif_166, motif_166, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seq_10314</td>\n",
       "      <td>-228</td>\n",
       "      <td>motif_144</td>\n",
       "      <td>[motif_144]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seq_18866</td>\n",
       "      <td>9616</td>\n",
       "      <td>motif_104,motif_126,motif_126,motif_147,motif_...</td>\n",
       "      <td>[motif_104, motif_126, motif_126, motif_147, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seq_45348</td>\n",
       "      <td>5770</td>\n",
       "      <td>motif_120,motif_121,motif_128,motif_128,motif_...</td>\n",
       "      <td>[motif_120, motif_121, motif_128, motif_128, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seq_2616</td>\n",
       "      <td>-12540</td>\n",
       "      <td>motif_100,motif_103,motif_126,motif_126,motif_...</td>\n",
       "      <td>[motif_100, motif_103, motif_126, motif_126, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60095</th>\n",
       "      <td>seq_5507</td>\n",
       "      <td>-127293</td>\n",
       "      <td>motif_137,motif_137,motif_13,motif_174,motif_1...</td>\n",
       "      <td>[motif_137, motif_137, motif_13, motif_174, mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60096</th>\n",
       "      <td>seq_11070</td>\n",
       "      <td>37721</td>\n",
       "      <td>motif_132,motif_132,motif_132,motif_142,motif_...</td>\n",
       "      <td>[motif_132, motif_132, motif_132, motif_142, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60097</th>\n",
       "      <td>seq_17945</td>\n",
       "      <td>88589</td>\n",
       "      <td>motif_161,motif_162,motif_162,motif_174,motif_...</td>\n",
       "      <td>[motif_161, motif_162, motif_162, motif_174, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60098</th>\n",
       "      <td>seq_29137</td>\n",
       "      <td>93216</td>\n",
       "      <td>motif_104,motif_105,motif_117,motif_117,motif_...</td>\n",
       "      <td>[motif_104, motif_105, motif_117, motif_117, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60099</th>\n",
       "      <td>seq_48859</td>\n",
       "      <td>74528</td>\n",
       "      <td>motif_136,motif_145,motif_146,motif_158,motif_...</td>\n",
       "      <td>[motif_136, motif_145, motif_146, motif_158, m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60095 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PeakID  Distance to TSS  \\\n",
       "0      seq_40800              -81   \n",
       "1      seq_10314             -228   \n",
       "2      seq_18866             9616   \n",
       "3      seq_45348             5770   \n",
       "4       seq_2616           -12540   \n",
       "...          ...              ...   \n",
       "60095   seq_5507          -127293   \n",
       "60096  seq_11070            37721   \n",
       "60097  seq_17945            88589   \n",
       "60098  seq_29137            93216   \n",
       "60099  seq_48859            74528   \n",
       "\n",
       "                                            motif_string  \\\n",
       "0      motif_149,motif_162,motif_166,motif_166,motif_...   \n",
       "1                                              motif_144   \n",
       "2      motif_104,motif_126,motif_126,motif_147,motif_...   \n",
       "3      motif_120,motif_121,motif_128,motif_128,motif_...   \n",
       "4      motif_100,motif_103,motif_126,motif_126,motif_...   \n",
       "...                                                  ...   \n",
       "60095  motif_137,motif_137,motif_13,motif_174,motif_1...   \n",
       "60096  motif_132,motif_132,motif_132,motif_142,motif_...   \n",
       "60097  motif_161,motif_162,motif_162,motif_174,motif_...   \n",
       "60098  motif_104,motif_105,motif_117,motif_117,motif_...   \n",
       "60099  motif_136,motif_145,motif_146,motif_158,motif_...   \n",
       "\n",
       "                                              motif_list  \n",
       "0      [motif_149, motif_162, motif_166, motif_166, m...  \n",
       "1                                            [motif_144]  \n",
       "2      [motif_104, motif_126, motif_126, motif_147, m...  \n",
       "3      [motif_120, motif_121, motif_128, motif_128, m...  \n",
       "4      [motif_100, motif_103, motif_126, motif_126, m...  \n",
       "...                                                  ...  \n",
       "60095  [motif_137, motif_137, motif_13, motif_174, mo...  \n",
       "60096  [motif_132, motif_132, motif_132, motif_142, m...  \n",
       "60097  [motif_161, motif_162, motif_162, motif_174, m...  \n",
       "60098  [motif_104, motif_105, motif_117, motif_117, m...  \n",
       "60099  [motif_136, motif_145, motif_146, motif_158, m...  \n",
       "\n",
       "[60095 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data[data['motif_string'].isna()])\n",
    "data.dropna(subset=['motif_string'],inplace=True)\n",
    "data['motif_list']=data['motif_string'].apply(lambda x:x.split(','))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "concrete-freeze",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Motif-Index to Motif-Name Mapping:\n",
      "0 - motif_149\n",
      "1 - motif_162\n",
      "2 - motif_166\n",
      "3 - motif_174\n",
      "4 - motif_199\n",
      "5 - motif_230\n",
      "6 - motif_248\n",
      "7 - motif_295\n",
      "8 - motif_60\n",
      "9 - motif_66\n",
      "10 - motif_98\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "docs=data['motif_list'].values\n",
    "dictionary=Dictionary(docs)\n",
    "\n",
    "print('Motif-Index to Motif-Name Mapping:')\n",
    "for i,v in dictionary.items():\n",
    "    print(f'{i} - {v}')\n",
    "    if i==10:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "renewable-particular",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW (Sequence-0):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['motif_149',\n",
       "  'motif_162',\n",
       "  'motif_166',\n",
       "  'motif_166',\n",
       "  'motif_174',\n",
       "  'motif_199',\n",
       "  'motif_230',\n",
       "  'motif_248',\n",
       "  'motif_295',\n",
       "  'motif_295',\n",
       "  'motif_60',\n",
       "  'motif_60',\n",
       "  'motif_66',\n",
       "  'motif_98'],\n",
       " [(0, 1),\n",
       "  (1, 1),\n",
       "  (2, 2),\n",
       "  (3, 1),\n",
       "  (4, 1),\n",
       "  (5, 1),\n",
       "  (6, 1),\n",
       "  (7, 2),\n",
       "  (8, 2),\n",
       "  (9, 1),\n",
       "  (10, 1)])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(doc) for doc in docs]\n",
    "print('BOW (Sequence-0):')\n",
    "docs[0],corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-sampling",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "unlikely-accommodation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #setup logging for trainging metrics \n",
    "# import logging\n",
    "# logging.basicConfig(filename='test_output/model_callbacks.log', filemode='w',\n",
    "#                     format=\"%(asctime)s:%(levelname)s:%(message)s\",\n",
    "#                     level=logging.NOTSET)\n",
    "\n",
    "# from gensim.models.callbacks import Callback,PerplexityMetric, ConvergenceMetric, CoherenceMetric\n",
    "# perplexity_logger = PerplexityMetric(corpus=corpus, logger='shell')\n",
    "# convergence_logger = ConvergenceMetric(logger='shell')\n",
    "# # coherence_cv_logger = CoherenceMetric(corpus=corpus, coherence = 'c_v', texts = docs)\n",
    "\n",
    "# %%time\n",
    "# from gensim.models import LdaModel,LdaMulticore\n",
    "\n",
    "# #HYPERPARAMETERS\n",
    "# #passes = epochs\n",
    "# temp = dictionary[0]\n",
    "# id2word = dictionary.id2token\n",
    "# lda = LdaModel(corpus, id2word=id2word, alpha='auto',eval_every = 1,\\\n",
    "#                eta='auto',num_topics=3, iterations=5, passes = 10,\n",
    "#               callbacks=[perplexity_logger,convergence_logger])\n",
    "\n",
    "# lda.print_topics()\n",
    "\n",
    "# %%time\n",
    "# from gensim.models import LdaModel,LdaMulticore\n",
    "\n",
    "# id2word = dictionary.id2token\n",
    "# lda = LdaMulticore(corpus, id2word=id2word,eval_every = 1,\\\n",
    "#                eta='auto',num_topics=3, iterations=500, passes = 100)\n",
    "\n",
    "# import pyLDAvis.gensim\n",
    "\n",
    "# pyLDAvis.enable_notebook()\n",
    "# pyLDAvis.gensim.prepare(lda, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "focal-sessions",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "possible-residence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 48s, sys: 78 ms, total: 1min 48s\n",
      "Wall time: 1min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from gensim.models import LdaModel,LdaMulticore\n",
    "\n",
    "temp = dictionary[0]\n",
    "id2word = dictionary.id2token\n",
    "lda = LdaModel(corpus, id2word=id2word, alpha='auto',chunksize=10000,\n",
    "               eta='auto',num_topics=3, iterations=1000, passes = 5,\n",
    "              minimum_probability=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fitting-extreme",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopicDistribution(predictions,ntopics):\n",
    "    topic_count_dict={i:0 for i in range(ntopics)}\n",
    "    ndocs=len(predictions)\n",
    "    print(ndocs)\n",
    "    for pred in predictions:\n",
    "        top_topic=sorted(pred,key=lambda x:-x[1])[0][0]\n",
    "        topic_count_dict[top_topic]+=1\n",
    "    topic_dist_dict={k:v/ndocs for k,v in topic_count_dict.items()}\n",
    "    return topic_dist_dict\n",
    "\n",
    "def likelihoodMetric(predictions,ntopics):\n",
    "    likelihood=0\n",
    "#     P_T=model.alpha\n",
    "#     predictions=lda.get_document_topics(corpus,minimum_probability=0.0)\n",
    "    P_T=getTopicDistribution(predictions,model.num_topics)\n",
    "    print(P_T)\n",
    "    for pred in predictions:\n",
    "        P_Xi_M=0\n",
    "        for topic_no,P_Xi_T in pred:\n",
    "            P_Xi_M+=P_Xi_T*P_T[topic_no]\n",
    "        likelihood+=np.log10(P_Xi_M)\n",
    "    print(likelihood)\n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "characteristic-retreat",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def findTopMotifs(predictions,ntopics,data,ntop=5,outdir=None):\n",
    "    pred_topic=[]\n",
    "#     ntopics=model.num_topics\n",
    "    for pred in predictions:\n",
    "        top_topic=sorted(pred,key=lambda x:-x[1])[0][0]\n",
    "        pred_topic.append(top_topic)\n",
    "    _data=data.copy()\n",
    "    _data['pred_topic']=pred_topic      \n",
    "    gb=_data[['motif_string','pred_topic']].groupby('pred_topic').\\\n",
    "    agg(lambda x: ','.join(x))\n",
    "    gb['top_motif']=gb['motif_string'].\\\n",
    "    apply(lambda x:Counter(x.split(',')).most_common(ntop))\n",
    "    gb.reset_index(inplace=True)\n",
    "    gb=gb[['pred_topic','top_motif']]\n",
    "    if outdir is not None:\n",
    "        gb.to_csv(f'{outdir}/top{ntop}_motifs_topics_{ntopics}.csv',index=False)\n",
    "    print(gb)\n",
    "    return gb\n",
    "# findTopMotifs(lda,corpus,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "operational-things",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAvgTssDist(predictions,ntopics,data,outdir=None):\n",
    "    pred_topic=[]\n",
    "#     ntopics=model.num_topics\n",
    "    for pred in predictions:\n",
    "        top_topic=sorted(pred,key=lambda x:-x[1])[0][0]\n",
    "        pred_topic.append(top_topic)\n",
    "    _data=data.copy()\n",
    "    _data['pred_topic']=pred_topic\n",
    "    gb=_data[['Distance to TSS','pred_topic']].groupby('pred_topic').mean()\n",
    "    gb.reset_index(inplace=True)\n",
    "    if outdir is not None:\n",
    "        gb.to_csv(f'{outdir}/avg_tss_dist_topics_{ntopics}.csv',index=False)\n",
    "    print(gb)\n",
    "    return gb\n",
    "# getAvgTssDist(lda,corpus,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "south-desperate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Topics = 2\n",
      "Finding likelihood...\n",
      "60095\n",
      "{0: 0.47805973874698393, 1: 0.5219402612530161}\n",
      "-18068.728802235655\n",
      "Num of Topics = 3\n",
      "Finding likelihood...\n",
      "60095\n",
      "{0: 0.4924203344704218, 1: 0.3915134370579915, 2: 0.11606622847158665}\n",
      "-24259.491999566286\n",
      "Num of Topics = 4\n",
      "Finding likelihood...\n",
      "60095\n",
      "{0: 0.08749479990015809, 1: 0.19722106664447958, 2: 0.334320658956652, 3: 0.3809634744987104}\n",
      "-32063.50715062038\n",
      "Num of Topics = 5\n",
      "Finding likelihood...\n",
      "60095\n",
      "{0: 0.26448123803977036, 1: 0.1906315001248024, 2: 0.10553290623179964, 3: 0.12280555786671105, 4: 0.3165487977369166}\n",
      "-39058.58057453927\n",
      "Num of Topics = 6\n",
      "Finding likelihood...\n",
      "60095\n",
      "{0: 0.1115733422081704, 1: 0.2786255096097845, 2: 0.17810133954571927, 3: 0.07305100257924953, 4: 0.30373575172643313, 5: 0.05491305433064315}\n",
      "-40719.22278258542\n",
      "Num of Topics = 7\n",
      "Finding likelihood...\n",
      "60095\n",
      "{0: 0.2614027789333555, 1: 0.1528746151926117, 2: 0.036275896497212745, 3: 0.05637740244612697, 4: 0.16087860886929028, 5: 0.043963724103502785, 6: 0.2882269739579}\n",
      "-42448.17234963217\n",
      "Num of Topics = 8\n",
      "Finding likelihood...\n",
      "60095\n",
      "{0: 0.059372659955071135, 1: 0.03912139113070971, 2: 0.076828355104418, 3: 0.13169148847657874, 4: 0.16382394541975207, 5: 0.16656959813628422, 6: 0.08300191363674182, 7: 0.2795906481404443}\n",
      "-47916.77558382828\n",
      "Num of Topics = 9\n",
      "Finding likelihood...\n",
      "60095\n",
      "{0: 0.14818204509526584, 1: 0.12010982610866129, 2: 0.07644562775605292, 3: 0.10433480322822199, 4: 0.05887345037024711, 5: 0.04068558116315833, 6: 0.16909892669939264, 7: 0.21717280971794659, 8: 0.06509692986105334}\n",
      "-52662.875742563214\n",
      "CPU times: user 19min 2s, sys: 800 ms, total: 19min 2s\n",
      "Wall time: 19min 2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_topics</th>\n",
       "      <th>likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>-18068.728802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>-24259.492000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>-32063.507151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>-39058.580575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>-40719.222783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>-42448.172350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>-47916.775584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>-52662.875743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_topics    likelihood\n",
       "0           2 -18068.728802\n",
       "1           3 -24259.492000\n",
       "2           4 -32063.507151\n",
       "3           5 -39058.580575\n",
       "4           6 -40719.222783\n",
       "5           7 -42448.172350\n",
       "6           8 -47916.775584\n",
       "7           9 -52662.875743"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "from gensim.models import LdaModel,LdaMulticore\n",
    "\n",
    "outdir='model_output'\n",
    "eval_dict={'num_topics':[],'likelihood':[]}\n",
    "temp = dictionary[0]\n",
    "id2word = dictionary.id2token\n",
    "for ntopics in range(2,10):\n",
    "    print('Num of Topics = '+str(ntopics))\n",
    "    lda = LdaModel(corpus, id2word=id2word, alpha='auto',chunksize=10000,\n",
    "                   eta='auto',num_topics=ntopics, iterations=1000, passes = 5,\n",
    "                  minimum_probability=0.0)\n",
    "    \n",
    "    predictions=lda.get_document_topics(corpus,minimum_probability=0.0)\n",
    "    print('Finding likelihood...')\n",
    "    likelihood=likelihoodMetric(predictions,ntopics)\n",
    "    print('Finding Top Motifs...')\n",
    "    findTopMotifs(predictions,ntopics,data,outdir=outdir)\n",
    "    print('Findng avg. distance from TSS per topic...')\n",
    "    getAvgTssDist(predictions,ntopics,data,outdir=outdir)\n",
    "    eval_dict['num_topics'].append(ntopics)\n",
    "    eval_dict['likelihood'].append(likelihood)\n",
    "eval_df=pd.DataFrame(eval_dict)\n",
    "eval_df.to_csv(f'{outdir}/likelihood.csv',index=False)\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-marsh",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
