{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acute-accreditation",
   "metadata": {},
   "source": [
    "# LDA Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "southeast-hampshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-pension",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "downtown-phrase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PeakID</th>\n",
       "      <th>Distance to TSS</th>\n",
       "      <th>motif_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seq_40800</td>\n",
       "      <td>-81</td>\n",
       "      <td>motif_149,motif_162,motif_166,motif_166,motif_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seq_10314</td>\n",
       "      <td>-228</td>\n",
       "      <td>motif_144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seq_18866</td>\n",
       "      <td>9616</td>\n",
       "      <td>motif_104,motif_126,motif_126,motif_147,motif_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seq_45348</td>\n",
       "      <td>5770</td>\n",
       "      <td>motif_120,motif_121,motif_128,motif_128,motif_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seq_2616</td>\n",
       "      <td>-12540</td>\n",
       "      <td>motif_100,motif_103,motif_126,motif_126,motif_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60095</th>\n",
       "      <td>seq_5507</td>\n",
       "      <td>-127293</td>\n",
       "      <td>motif_137,motif_137,motif_13,motif_174,motif_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60096</th>\n",
       "      <td>seq_11070</td>\n",
       "      <td>37721</td>\n",
       "      <td>motif_132,motif_132,motif_132,motif_142,motif_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60097</th>\n",
       "      <td>seq_17945</td>\n",
       "      <td>88589</td>\n",
       "      <td>motif_161,motif_162,motif_162,motif_174,motif_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60098</th>\n",
       "      <td>seq_29137</td>\n",
       "      <td>93216</td>\n",
       "      <td>motif_104,motif_105,motif_117,motif_117,motif_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60099</th>\n",
       "      <td>seq_48859</td>\n",
       "      <td>74528</td>\n",
       "      <td>motif_136,motif_145,motif_146,motif_158,motif_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PeakID  Distance to TSS  \\\n",
       "0      seq_40800              -81   \n",
       "1      seq_10314             -228   \n",
       "2      seq_18866             9616   \n",
       "3      seq_45348             5770   \n",
       "4       seq_2616           -12540   \n",
       "...          ...              ...   \n",
       "60095   seq_5507          -127293   \n",
       "60096  seq_11070            37721   \n",
       "60097  seq_17945            88589   \n",
       "60098  seq_29137            93216   \n",
       "60099  seq_48859            74528   \n",
       "\n",
       "                                            motif_string  \n",
       "0      motif_149,motif_162,motif_166,motif_166,motif_...  \n",
       "1                                              motif_144  \n",
       "2      motif_104,motif_126,motif_126,motif_147,motif_...  \n",
       "3      motif_120,motif_121,motif_128,motif_128,motif_...  \n",
       "4      motif_100,motif_103,motif_126,motif_126,motif_...  \n",
       "...                                                  ...  \n",
       "60095  motif_137,motif_137,motif_13,motif_174,motif_1...  \n",
       "60096  motif_132,motif_132,motif_132,motif_142,motif_...  \n",
       "60097  motif_161,motif_162,motif_162,motif_174,motif_...  \n",
       "60098  motif_104,motif_105,motif_117,motif_117,motif_...  \n",
       "60099  motif_136,motif_145,motif_146,motif_158,motif_...  \n",
       "\n",
       "[60100 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file_path='DATA.csv'\n",
    "data=pd.read_csv(data_file_path)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "southern-oracle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          PeakID  Distance to TSS motif_string\n",
      "18840  seq_57232             -180          NaN\n",
      "23892  seq_20216             -147          NaN\n",
      "29667  seq_31231              483          NaN\n",
      "46832   seq_8465             -341          NaN\n",
      "47219  seq_46451             4737          NaN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PeakID</th>\n",
       "      <th>Distance to TSS</th>\n",
       "      <th>motif_string</th>\n",
       "      <th>motif_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seq_40800</td>\n",
       "      <td>-81</td>\n",
       "      <td>motif_149,motif_162,motif_166,motif_166,motif_...</td>\n",
       "      <td>[motif_149, motif_162, motif_166, motif_166, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seq_10314</td>\n",
       "      <td>-228</td>\n",
       "      <td>motif_144</td>\n",
       "      <td>[motif_144]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seq_18866</td>\n",
       "      <td>9616</td>\n",
       "      <td>motif_104,motif_126,motif_126,motif_147,motif_...</td>\n",
       "      <td>[motif_104, motif_126, motif_126, motif_147, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seq_45348</td>\n",
       "      <td>5770</td>\n",
       "      <td>motif_120,motif_121,motif_128,motif_128,motif_...</td>\n",
       "      <td>[motif_120, motif_121, motif_128, motif_128, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seq_2616</td>\n",
       "      <td>-12540</td>\n",
       "      <td>motif_100,motif_103,motif_126,motif_126,motif_...</td>\n",
       "      <td>[motif_100, motif_103, motif_126, motif_126, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60095</th>\n",
       "      <td>seq_5507</td>\n",
       "      <td>-127293</td>\n",
       "      <td>motif_137,motif_137,motif_13,motif_174,motif_1...</td>\n",
       "      <td>[motif_137, motif_137, motif_13, motif_174, mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60096</th>\n",
       "      <td>seq_11070</td>\n",
       "      <td>37721</td>\n",
       "      <td>motif_132,motif_132,motif_132,motif_142,motif_...</td>\n",
       "      <td>[motif_132, motif_132, motif_132, motif_142, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60097</th>\n",
       "      <td>seq_17945</td>\n",
       "      <td>88589</td>\n",
       "      <td>motif_161,motif_162,motif_162,motif_174,motif_...</td>\n",
       "      <td>[motif_161, motif_162, motif_162, motif_174, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60098</th>\n",
       "      <td>seq_29137</td>\n",
       "      <td>93216</td>\n",
       "      <td>motif_104,motif_105,motif_117,motif_117,motif_...</td>\n",
       "      <td>[motif_104, motif_105, motif_117, motif_117, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60099</th>\n",
       "      <td>seq_48859</td>\n",
       "      <td>74528</td>\n",
       "      <td>motif_136,motif_145,motif_146,motif_158,motif_...</td>\n",
       "      <td>[motif_136, motif_145, motif_146, motif_158, m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60095 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PeakID  Distance to TSS  \\\n",
       "0      seq_40800              -81   \n",
       "1      seq_10314             -228   \n",
       "2      seq_18866             9616   \n",
       "3      seq_45348             5770   \n",
       "4       seq_2616           -12540   \n",
       "...          ...              ...   \n",
       "60095   seq_5507          -127293   \n",
       "60096  seq_11070            37721   \n",
       "60097  seq_17945            88589   \n",
       "60098  seq_29137            93216   \n",
       "60099  seq_48859            74528   \n",
       "\n",
       "                                            motif_string  \\\n",
       "0      motif_149,motif_162,motif_166,motif_166,motif_...   \n",
       "1                                              motif_144   \n",
       "2      motif_104,motif_126,motif_126,motif_147,motif_...   \n",
       "3      motif_120,motif_121,motif_128,motif_128,motif_...   \n",
       "4      motif_100,motif_103,motif_126,motif_126,motif_...   \n",
       "...                                                  ...   \n",
       "60095  motif_137,motif_137,motif_13,motif_174,motif_1...   \n",
       "60096  motif_132,motif_132,motif_132,motif_142,motif_...   \n",
       "60097  motif_161,motif_162,motif_162,motif_174,motif_...   \n",
       "60098  motif_104,motif_105,motif_117,motif_117,motif_...   \n",
       "60099  motif_136,motif_145,motif_146,motif_158,motif_...   \n",
       "\n",
       "                                              motif_list  \n",
       "0      [motif_149, motif_162, motif_166, motif_166, m...  \n",
       "1                                            [motif_144]  \n",
       "2      [motif_104, motif_126, motif_126, motif_147, m...  \n",
       "3      [motif_120, motif_121, motif_128, motif_128, m...  \n",
       "4      [motif_100, motif_103, motif_126, motif_126, m...  \n",
       "...                                                  ...  \n",
       "60095  [motif_137, motif_137, motif_13, motif_174, mo...  \n",
       "60096  [motif_132, motif_132, motif_132, motif_142, m...  \n",
       "60097  [motif_161, motif_162, motif_162, motif_174, m...  \n",
       "60098  [motif_104, motif_105, motif_117, motif_117, m...  \n",
       "60099  [motif_136, motif_145, motif_146, motif_158, m...  \n",
       "\n",
       "[60095 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data[data['motif_string'].isna()])\n",
    "data.dropna(subset=['motif_string'],inplace=True)\n",
    "data['motif_list']=data['motif_string'].apply(lambda x:x.split(','))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "concrete-freeze",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Motif-Index to Motif-Name Mapping:\n",
      "0 - motif_149\n",
      "1 - motif_162\n",
      "2 - motif_166\n",
      "3 - motif_174\n",
      "4 - motif_199\n",
      "5 - motif_230\n",
      "6 - motif_248\n",
      "7 - motif_295\n",
      "8 - motif_60\n",
      "9 - motif_66\n",
      "10 - motif_98\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "docs=data['motif_list'].values\n",
    "dictionary=Dictionary(docs)\n",
    "\n",
    "print('Motif-Index to Motif-Name Mapping:')\n",
    "for i,v in dictionary.items():\n",
    "    print(f'{i} - {v}')\n",
    "    if i==10:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "renewable-particular",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW (Sequence-0):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['motif_149',\n",
       "  'motif_162',\n",
       "  'motif_166',\n",
       "  'motif_166',\n",
       "  'motif_174',\n",
       "  'motif_199',\n",
       "  'motif_230',\n",
       "  'motif_248',\n",
       "  'motif_295',\n",
       "  'motif_295',\n",
       "  'motif_60',\n",
       "  'motif_60',\n",
       "  'motif_66',\n",
       "  'motif_98'],\n",
       " [(0, 1),\n",
       "  (1, 1),\n",
       "  (2, 2),\n",
       "  (3, 1),\n",
       "  (4, 1),\n",
       "  (5, 1),\n",
       "  (6, 1),\n",
       "  (7, 2),\n",
       "  (8, 2),\n",
       "  (9, 1),\n",
       "  (10, 1)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(doc) for doc in docs]\n",
    "print('BOW (Sequence-0):')\n",
    "docs[0],corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-sampling",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "unlikely-accommodation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #setup logging for trainging metrics \n",
    "# import logging\n",
    "# logging.basicConfig(filename='test_output/model_callbacks.log', filemode='w',\n",
    "#                     format=\"%(asctime)s:%(levelname)s:%(message)s\",\n",
    "#                     level=logging.NOTSET)\n",
    "\n",
    "# from gensim.models.callbacks import Callback,PerplexityMetric, ConvergenceMetric, CoherenceMetric\n",
    "# perplexity_logger = PerplexityMetric(corpus=corpus, logger='shell')\n",
    "# convergence_logger = ConvergenceMetric(logger='shell')\n",
    "# # coherence_cv_logger = CoherenceMetric(corpus=corpus, coherence = 'c_v', texts = docs)\n",
    "\n",
    "# %%time\n",
    "# from gensim.models import LdaModel,LdaMulticore\n",
    "\n",
    "# #HYPERPARAMETERS\n",
    "# #passes = epochs\n",
    "# temp = dictionary[0]\n",
    "# id2word = dictionary.id2token\n",
    "# lda = LdaModel(corpus, id2word=id2word, alpha='auto',eval_every = 1,\\\n",
    "#                eta='auto',num_topics=3, iterations=5, passes = 10,\n",
    "#               callbacks=[perplexity_logger,convergence_logger])\n",
    "\n",
    "# lda.print_topics()\n",
    "\n",
    "# %%time\n",
    "# from gensim.models import LdaModel,LdaMulticore\n",
    "\n",
    "# id2word = dictionary.id2token\n",
    "# lda = LdaMulticore(corpus, id2word=id2word,eval_every = 1,\\\n",
    "#                eta='auto',num_topics=3, iterations=500, passes = 100)\n",
    "\n",
    "# import pyLDAvis.gensim\n",
    "\n",
    "# pyLDAvis.enable_notebook()\n",
    "# pyLDAvis.gensim.prepare(lda, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "possible-residence",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-22 02:13:16,962 : INFO : using autotuned alpha, starting with [0.33333334, 0.33333334, 0.33333334]\n",
      "2021-02-22 02:13:16,963 : INFO : using serial LDA version on this node\n",
      "2021-02-22 02:13:16,965 : INFO : running online (multi-pass) LDA training, 3 topics, 5 passes over the supplied corpus of 60095 documents, updating model once every 10000 documents, evaluating perplexity every 60095 documents, iterating 1000x with a convergence threshold of 0.001000\n",
      "2021-02-22 02:13:16,969 : INFO : PROGRESS: pass 0, at document #10000/60095\n",
      "2021-02-22 02:13:16,969 : DEBUG : performing inference on a chunk of 10000 documents\n",
      "2021-02-22 02:13:36,610 : DEBUG : 9886/10000 documents converged within 1000 iterations\n",
      "2021-02-22 02:13:36,636 : INFO : optimized alpha [0.14514804, 0.1484222, 0.045556366]\n",
      "2021-02-22 02:13:36,637 : DEBUG : updating topics\n",
      "2021-02-22 02:13:36,638 : INFO : merging changes from 10000 documents into a model of 60095 documents\n",
      "2021-02-22 02:13:36,639 : INFO : topic #0 (0.145): 0.042*\"motif_60\" + 0.020*\"motif_184\" + 0.015*\"motif_84\" + 0.015*\"motif_62\" + 0.015*\"motif_262\" + 0.013*\"motif_126\" + 0.013*\"motif_12\" + 0.012*\"motif_11\" + 0.012*\"motif_218\" + 0.012*\"motif_219\"\n",
      "2021-02-22 02:13:36,640 : INFO : topic #1 (0.148): 0.043*\"motif_60\" + 0.029*\"motif_184\" + 0.027*\"motif_37\" + 0.025*\"motif_218\" + 0.024*\"motif_42\" + 0.024*\"motif_23\" + 0.019*\"motif_40\" + 0.019*\"motif_13\" + 0.018*\"motif_166\" + 0.017*\"motif_19\"\n",
      "2021-02-22 02:13:36,640 : INFO : topic #2 (0.046): 0.024*\"motif_60\" + 0.016*\"motif_126\" + 0.014*\"motif_49\" + 0.014*\"motif_48\" + 0.013*\"motif_202\" + 0.013*\"motif_174\" + 0.013*\"motif_41\" + 0.013*\"motif_50\" + 0.013*\"motif_239\" + 0.012*\"motif_84\"\n",
      "2021-02-22 02:13:36,641 : INFO : topic diff=0.972995, rho=1.000000\n",
      "2021-02-22 02:13:36,658 : INFO : PROGRESS: pass 0, at document #20000/60095\n",
      "2021-02-22 02:13:36,658 : DEBUG : performing inference on a chunk of 10000 documents\n",
      "2021-02-22 02:13:42,176 : DEBUG : 9999/10000 documents converged within 1000 iterations\n",
      "2021-02-22 02:13:42,203 : INFO : optimized alpha [0.09986668, 0.10815583, 0.045440555]\n",
      "2021-02-22 02:13:42,203 : DEBUG : updating topics\n",
      "2021-02-22 02:13:42,204 : INFO : merging changes from 10000 documents into a model of 60095 documents\n",
      "2021-02-22 02:13:42,205 : INFO : topic #0 (0.100): 0.038*\"motif_60\" + 0.017*\"motif_62\" + 0.016*\"motif_184\" + 0.016*\"motif_11\" + 0.016*\"motif_12\" + 0.016*\"motif_84\" + 0.016*\"motif_126\" + 0.016*\"motif_219\" + 0.015*\"motif_10\" + 0.014*\"motif_6\"\n",
      "2021-02-22 02:13:42,206 : INFO : topic #1 (0.108): 0.049*\"motif_60\" + 0.034*\"motif_184\" + 0.030*\"motif_37\" + 0.028*\"motif_42\" + 0.028*\"motif_218\" + 0.028*\"motif_23\" + 0.022*\"motif_40\" + 0.022*\"motif_13\" + 0.021*\"motif_166\" + 0.020*\"motif_19\"\n",
      "2021-02-22 02:13:42,206 : INFO : topic #2 (0.045): 0.022*\"motif_60\" + 0.018*\"motif_49\" + 0.018*\"motif_48\" + 0.018*\"motif_41\" + 0.017*\"motif_50\" + 0.014*\"motif_126\" + 0.014*\"motif_17\" + 0.014*\"motif_57\" + 0.013*\"motif_58\" + 0.013*\"motif_95\"\n",
      "2021-02-22 02:13:42,207 : INFO : topic diff=0.243903, rho=0.707107\n",
      "2021-02-22 02:13:42,209 : INFO : PROGRESS: pass 0, at document #30000/60095\n",
      "2021-02-22 02:13:42,209 : DEBUG : performing inference on a chunk of 10000 documents\n",
      "2021-02-22 02:13:46,172 : DEBUG : 10000/10000 documents converged within 1000 iterations\n",
      "2021-02-22 02:13:46,199 : INFO : optimized alpha [0.08681325, 0.0951985, 0.04655878]\n",
      "2021-02-22 02:13:46,200 : DEBUG : updating topics\n",
      "2021-02-22 02:13:46,201 : INFO : merging changes from 10000 documents into a model of 60095 documents\n",
      "2021-02-22 02:13:46,202 : INFO : topic #0 (0.087): 0.035*\"motif_60\" + 0.018*\"motif_11\" + 0.018*\"motif_12\" + 0.018*\"motif_219\" + 0.017*\"motif_62\" + 0.017*\"motif_84\" + 0.017*\"motif_10\" + 0.017*\"motif_126\" + 0.016*\"motif_6\" + 0.015*\"motif_9\"\n",
      "2021-02-22 02:13:46,203 : INFO : topic #1 (0.095): 0.053*\"motif_60\" + 0.037*\"motif_184\" + 0.033*\"motif_37\" + 0.030*\"motif_218\" + 0.030*\"motif_42\" + 0.030*\"motif_23\" + 0.024*\"motif_40\" + 0.024*\"motif_13\" + 0.023*\"motif_166\" + 0.022*\"motif_19\"\n",
      "2021-02-22 02:13:46,204 : INFO : topic #2 (0.047): 0.021*\"motif_60\" + 0.020*\"motif_49\" + 0.019*\"motif_48\" + 0.019*\"motif_50\" + 0.019*\"motif_41\" + 0.015*\"motif_57\" + 0.015*\"motif_58\" + 0.014*\"motif_74\" + 0.014*\"motif_17\" + 0.014*\"motif_95\"\n",
      "2021-02-22 02:13:46,204 : INFO : topic diff=0.173501, rho=0.577350\n",
      "2021-02-22 02:13:46,206 : INFO : PROGRESS: pass 0, at document #40000/60095\n",
      "2021-02-22 02:13:46,207 : DEBUG : performing inference on a chunk of 10000 documents\n",
      "2021-02-22 02:13:49,598 : DEBUG : 10000/10000 documents converged within 1000 iterations\n",
      "2021-02-22 02:13:49,626 : INFO : optimized alpha [0.080110684, 0.090461895, 0.04836379]\n",
      "2021-02-22 02:13:49,627 : DEBUG : updating topics\n",
      "2021-02-22 02:13:49,627 : INFO : merging changes from 10000 documents into a model of 60095 documents\n",
      "2021-02-22 02:13:49,629 : INFO : topic #0 (0.080): 0.033*\"motif_60\" + 0.020*\"motif_219\" + 0.019*\"motif_11\" + 0.019*\"motif_12\" + 0.018*\"motif_10\" + 0.018*\"motif_126\" + 0.017*\"motif_62\" + 0.017*\"motif_84\" + 0.017*\"motif_6\" + 0.016*\"motif_9\"\n",
      "2021-02-22 02:13:49,630 : INFO : topic #1 (0.090): 0.054*\"motif_60\" + 0.039*\"motif_184\" + 0.034*\"motif_37\" + 0.032*\"motif_218\" + 0.031*\"motif_23\" + 0.031*\"motif_42\" + 0.025*\"motif_40\" + 0.025*\"motif_13\" + 0.024*\"motif_166\" + 0.023*\"motif_19\"\n",
      "2021-02-22 02:13:49,630 : INFO : topic #2 (0.048): 0.020*\"motif_60\" + 0.020*\"motif_49\" + 0.019*\"motif_50\" + 0.019*\"motif_48\" + 0.019*\"motif_41\" + 0.015*\"motif_62\" + 0.015*\"motif_58\" + 0.015*\"motif_17\" + 0.015*\"motif_57\" + 0.014*\"motif_74\"\n",
      "2021-02-22 02:13:49,631 : INFO : topic diff=0.129909, rho=0.500000\n",
      "2021-02-22 02:13:49,633 : INFO : PROGRESS: pass 0, at document #50000/60095\n",
      "2021-02-22 02:13:49,634 : DEBUG : performing inference on a chunk of 10000 documents\n",
      "2021-02-22 02:13:53,000 : DEBUG : 10000/10000 documents converged within 1000 iterations\n",
      "2021-02-22 02:13:53,029 : INFO : optimized alpha [0.0757662, 0.087897696, 0.05058356]\n",
      "2021-02-22 02:13:53,030 : DEBUG : updating topics\n",
      "2021-02-22 02:13:53,030 : INFO : merging changes from 10000 documents into a model of 60095 documents\n",
      "2021-02-22 02:13:53,031 : INFO : topic #0 (0.076): 0.033*\"motif_60\" + 0.022*\"motif_219\" + 0.020*\"motif_11\" + 0.019*\"motif_12\" + 0.019*\"motif_126\" + 0.018*\"motif_10\" + 0.018*\"motif_84\" + 0.018*\"motif_62\" + 0.017*\"motif_6\" + 0.017*\"motif_9\"\n",
      "2021-02-22 02:13:53,032 : INFO : topic #1 (0.088): 0.056*\"motif_60\" + 0.040*\"motif_184\" + 0.036*\"motif_37\" + 0.033*\"motif_23\" + 0.032*\"motif_218\" + 0.032*\"motif_42\" + 0.026*\"motif_40\" + 0.026*\"motif_13\" + 0.025*\"motif_166\" + 0.023*\"motif_19\"\n",
      "2021-02-22 02:13:53,032 : INFO : topic #2 (0.051): 0.020*\"motif_60\" + 0.020*\"motif_49\" + 0.019*\"motif_50\" + 0.019*\"motif_48\" + 0.019*\"motif_41\" + 0.016*\"motif_62\" + 0.016*\"motif_54\" + 0.015*\"motif_17\" + 0.015*\"motif_58\" + 0.014*\"motif_57\"\n",
      "2021-02-22 02:13:53,033 : INFO : topic diff=0.112120, rho=0.447214\n",
      "2021-02-22 02:13:53,035 : INFO : PROGRESS: pass 0, at document #60000/60095\n",
      "2021-02-22 02:13:53,036 : DEBUG : performing inference on a chunk of 10000 documents\n",
      "2021-02-22 02:13:58,682 : DEBUG : 10000/10000 documents converged within 1000 iterations\n",
      "2021-02-22 02:13:58,711 : INFO : optimized alpha [0.07297021, 0.08681817, 0.05307941]\n",
      "2021-02-22 02:13:58,711 : DEBUG : updating topics\n",
      "2021-02-22 02:13:58,712 : INFO : merging changes from 10000 documents into a model of 60095 documents\n",
      "2021-02-22 02:13:58,713 : INFO : topic #0 (0.073): 0.032*\"motif_60\" + 0.023*\"motif_219\" + 0.020*\"motif_11\" + 0.020*\"motif_12\" + 0.019*\"motif_10\" + 0.019*\"motif_126\" + 0.019*\"motif_84\" + 0.018*\"motif_6\" + 0.017*\"motif_62\" + 0.017*\"motif_9\"\n",
      "2021-02-22 02:13:58,714 : INFO : topic #1 (0.087): 0.057*\"motif_60\" + 0.042*\"motif_184\" + 0.036*\"motif_37\" + 0.033*\"motif_23\" + 0.033*\"motif_218\" + 0.032*\"motif_42\" + 0.027*\"motif_40\" + 0.026*\"motif_13\" + 0.026*\"motif_166\" + 0.024*\"motif_19\"\n",
      "2021-02-22 02:13:58,715 : INFO : topic #2 (0.053): 0.020*\"motif_60\" + 0.019*\"motif_49\" + 0.019*\"motif_50\" + 0.019*\"motif_48\" + 0.018*\"motif_41\" + 0.017*\"motif_62\" + 0.017*\"motif_54\" + 0.015*\"motif_17\" + 0.014*\"motif_58\" + 0.014*\"motif_57\"\n",
      "2021-02-22 02:13:58,715 : INFO : topic diff=0.096141, rho=0.408248\n",
      "2021-02-22 02:13:58,718 : DEBUG : bound: at document #0\n",
      "2021-02-22 02:13:58,762 : INFO : -5.061 per-word bound, 33.4 perplexity estimate based on a held-out corpus of 95 documents with 2924 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-22 02:13:58,762 : INFO : PROGRESS: pass 0, at document #60095/60095\n",
      "2021-02-22 02:13:58,763 : DEBUG : performing inference on a chunk of 95 documents\n",
      "2021-02-22 02:13:58,793 : DEBUG : 95/95 documents converged within 1000 iterations\n",
      "2021-02-22 02:13:58,794 : INFO : optimized alpha [0.07235851, 0.08545494, 0.056860935]\n",
      "2021-02-22 02:13:58,795 : DEBUG : updating topics\n",
      "2021-02-22 02:13:58,795 : INFO : merging changes from 95 documents into a model of 60095 documents\n",
      "2021-02-22 02:13:58,797 : INFO : topic #0 (0.072): 0.027*\"motif_60\" + 0.024*\"motif_10\" + 0.024*\"motif_11\" + 0.024*\"motif_12\" + 0.023*\"motif_219\" + 0.023*\"motif_9\" + 0.021*\"motif_6\" + 0.019*\"motif_5\" + 0.019*\"motif_8\" + 0.018*\"motif_62\"\n",
      "2021-02-22 02:13:58,797 : INFO : topic #1 (0.085): 0.060*\"motif_60\" + 0.046*\"motif_184\" + 0.036*\"motif_218\" + 0.036*\"motif_37\" + 0.033*\"motif_23\" + 0.030*\"motif_42\" + 0.027*\"motif_166\" + 0.026*\"motif_13\" + 0.026*\"motif_40\" + 0.024*\"motif_19\"\n",
      "2021-02-22 02:13:58,798 : INFO : topic #2 (0.057): 0.022*\"motif_50\" + 0.021*\"motif_49\" + 0.021*\"motif_41\" + 0.020*\"motif_48\" + 0.018*\"motif_62\" + 0.018*\"motif_60\" + 0.016*\"motif_54\" + 0.015*\"motif_58\" + 0.015*\"motif_74\" + 0.014*\"motif_93\"\n",
      "2021-02-22 02:13:58,799 : INFO : topic diff=0.281358, rho=0.377964\n",
      "2021-02-22 02:13:58,803 : INFO : Epoch 0: Convergence estimate: 2.862531969309463\n",
      "2021-02-22 02:13:58,807 : INFO : PROGRESS: pass 1, at document #10000/60095\n",
      "2021-02-22 02:13:58,807 : DEBUG : performing inference on a chunk of 10000 documents\n",
      "2021-02-22 02:14:01,826 : DEBUG : 10000/10000 documents converged within 1000 iterations\n",
      "2021-02-22 02:14:01,855 : INFO : optimized alpha [0.06993154, 0.0864307, 0.059869368]\n",
      "2021-02-22 02:14:01,855 : DEBUG : updating topics\n",
      "2021-02-22 02:14:01,856 : INFO : merging changes from 10000 documents into a model of 60095 documents\n",
      "2021-02-22 02:14:01,857 : INFO : topic #0 (0.070): 0.027*\"motif_60\" + 0.025*\"motif_219\" + 0.024*\"motif_11\" + 0.024*\"motif_12\" + 0.024*\"motif_10\" + 0.022*\"motif_9\" + 0.021*\"motif_6\" + 0.019*\"motif_5\" + 0.018*\"motif_8\" + 0.018*\"motif_62\"\n",
      "2021-02-22 02:14:01,857 : INFO : topic #1 (0.086): 0.061*\"motif_60\" + 0.045*\"motif_184\" + 0.036*\"motif_37\" + 0.036*\"motif_218\" + 0.033*\"motif_23\" + 0.031*\"motif_42\" + 0.027*\"motif_166\" + 0.026*\"motif_40\" + 0.026*\"motif_13\" + 0.024*\"motif_19\"\n",
      "2021-02-22 02:14:01,858 : INFO : topic #2 (0.060): 0.021*\"motif_50\" + 0.020*\"motif_49\" + 0.020*\"motif_41\" + 0.020*\"motif_48\" + 0.018*\"motif_62\" + 0.018*\"motif_60\" + 0.017*\"motif_54\" + 0.015*\"motif_58\" + 0.014*\"motif_74\" + 0.014*\"motif_57\"\n",
      "2021-02-22 02:14:01,858 : INFO : topic diff=0.111446, rho=0.353344\n",
      "2021-02-22 02:14:01,860 : INFO : PROGRESS: pass 1, at document #20000/60095\n",
      "2021-02-22 02:14:01,861 : DEBUG : performing inference on a chunk of 10000 documents\n",
      "2021-02-22 02:14:04,828 : DEBUG : 10000/10000 documents converged within 1000 iterations\n",
      "2021-02-22 02:14:04,856 : INFO : optimized alpha [0.06806876, 0.08811563, 0.062775284]\n",
      "2021-02-22 02:14:04,857 : DEBUG : updating topics\n",
      "2021-02-22 02:14:04,858 : INFO : merging changes from 10000 documents into a model of 60095 documents\n",
      "2021-02-22 02:14:04,859 : INFO : topic #0 (0.068): 0.027*\"motif_60\" + 0.026*\"motif_219\" + 0.024*\"motif_11\" + 0.024*\"motif_12\" + 0.023*\"motif_10\" + 0.021*\"motif_9\" + 0.021*\"motif_6\" + 0.019*\"motif_5\" + 0.018*\"motif_8\" + 0.018*\"motif_264\"\n",
      "2021-02-22 02:14:04,859 : INFO : topic #1 (0.088): 0.062*\"motif_60\" + 0.045*\"motif_184\" + 0.036*\"motif_37\" + 0.036*\"motif_218\" + 0.034*\"motif_23\" + 0.032*\"motif_42\" + 0.027*\"motif_166\" + 0.027*\"motif_40\" + 0.026*\"motif_13\" + 0.024*\"motif_19\"\n",
      "2021-02-22 02:14:04,860 : INFO : topic #2 (0.063): 0.020*\"motif_50\" + 0.019*\"motif_49\" + 0.019*\"motif_41\" + 0.019*\"motif_48\" + 0.019*\"motif_62\" + 0.018*\"motif_60\" + 0.017*\"motif_54\" + 0.014*\"motif_58\" + 0.014*\"motif_93\" + 0.014*\"motif_17\"\n",
      "2021-02-22 02:14:04,860 : INFO : topic diff=0.092312, rho=0.353344\n",
      "2021-02-22 02:14:04,862 : INFO : PROGRESS: pass 1, at document #30000/60095\n",
      "2021-02-22 02:14:04,863 : DEBUG : performing inference on a chunk of 10000 documents\n",
      "2021-02-22 02:14:07,984 : DEBUG : 9999/10000 documents converged within 1000 iterations\n",
      "2021-02-22 02:14:08,013 : INFO : optimized alpha [0.06669787, 0.089509405, 0.06565652]\n",
      "2021-02-22 02:14:08,014 : DEBUG : updating topics\n",
      "2021-02-22 02:14:08,015 : INFO : merging changes from 10000 documents into a model of 60095 documents\n",
      "2021-02-22 02:14:08,016 : INFO : topic #0 (0.067): 0.027*\"motif_219\" + 0.026*\"motif_60\" + 0.024*\"motif_11\" + 0.024*\"motif_12\" + 0.023*\"motif_10\" + 0.021*\"motif_9\" + 0.021*\"motif_6\" + 0.019*\"motif_5\" + 0.019*\"motif_264\" + 0.019*\"motif_8\"\n",
      "2021-02-22 02:14:08,017 : INFO : topic #1 (0.090): 0.062*\"motif_60\" + 0.045*\"motif_184\" + 0.037*\"motif_37\" + 0.036*\"motif_218\" + 0.034*\"motif_23\" + 0.033*\"motif_42\" + 0.027*\"motif_40\" + 0.027*\"motif_166\" + 0.027*\"motif_13\" + 0.024*\"motif_19\"\n",
      "2021-02-22 02:14:08,018 : INFO : topic #2 (0.066): 0.019*\"motif_50\" + 0.019*\"motif_62\" + 0.019*\"motif_49\" + 0.019*\"motif_60\" + 0.018*\"motif_48\" + 0.018*\"motif_41\" + 0.018*\"motif_54\" + 0.014*\"motif_17\" + 0.014*\"motif_58\" + 0.014*\"motif_93\"\n",
      "2021-02-22 02:14:08,018 : INFO : topic diff=0.087302, rho=0.353344\n",
      "2021-02-22 02:14:08,020 : INFO : PROGRESS: pass 1, at document #40000/60095\n",
      "2021-02-22 02:14:08,021 : DEBUG : performing inference on a chunk of 10000 documents\n",
      "2021-02-22 02:14:11,019 : DEBUG : 10000/10000 documents converged within 1000 iterations\n",
      "2021-02-22 02:14:11,047 : INFO : optimized alpha [0.065462105, 0.09137454, 0.06891089]\n",
      "2021-02-22 02:14:11,048 : DEBUG : updating topics\n",
      "2021-02-22 02:14:11,049 : INFO : merging changes from 10000 documents into a model of 60095 documents\n",
      "2021-02-22 02:14:11,050 : INFO : topic #0 (0.065): 0.029*\"motif_219\" + 0.026*\"motif_60\" + 0.025*\"motif_11\" + 0.024*\"motif_12\" + 0.024*\"motif_10\" + 0.021*\"motif_6\" + 0.021*\"motif_9\" + 0.020*\"motif_264\" + 0.020*\"motif_5\" + 0.019*\"motif_8\"\n",
      "2021-02-22 02:14:11,051 : INFO : topic #1 (0.091): 0.062*\"motif_60\" + 0.046*\"motif_184\" + 0.037*\"motif_37\" + 0.036*\"motif_218\" + 0.034*\"motif_23\" + 0.033*\"motif_42\" + 0.027*\"motif_40\" + 0.027*\"motif_166\" + 0.027*\"motif_13\" + 0.025*\"motif_19\"\n",
      "2021-02-22 02:14:11,051 : INFO : topic #2 (0.069): 0.019*\"motif_62\" + 0.019*\"motif_60\" + 0.019*\"motif_50\" + 0.019*\"motif_49\" + 0.018*\"motif_54\" + 0.018*\"motif_48\" + 0.018*\"motif_41\" + 0.015*\"motif_17\" + 0.014*\"motif_93\" + 0.014*\"motif_58\"\n",
      "2021-02-22 02:14:11,052 : INFO : topic diff=0.080623, rho=0.353344\n",
      "2021-02-22 02:14:11,054 : INFO : PROGRESS: pass 1, at document #50000/60095\n",
      "2021-02-22 02:14:11,055 : DEBUG : performing inference on a chunk of 10000 documents\n",
      "2021-02-22 02:14:14,078 : DEBUG : 10000/10000 documents converged within 1000 iterations\n",
      "2021-02-22 02:14:14,104 : INFO : optimized alpha [0.06419662, 0.09320507, 0.07244666]\n",
      "2021-02-22 02:14:14,104 : DEBUG : updating topics\n",
      "2021-02-22 02:14:14,105 : INFO : merging changes from 10000 documents into a model of 60095 documents\n",
      "2021-02-22 02:14:14,105 : INFO : topic #0 (0.064): 0.030*\"motif_219\" + 0.026*\"motif_60\" + 0.025*\"motif_11\" + 0.025*\"motif_12\" + 0.024*\"motif_10\" + 0.021*\"motif_6\" + 0.021*\"motif_9\" + 0.021*\"motif_264\" + 0.020*\"motif_5\" + 0.019*\"motif_8\"\n",
      "2021-02-22 02:14:14,106 : INFO : topic #1 (0.093): 0.062*\"motif_60\" + 0.046*\"motif_184\" + 0.038*\"motif_37\" + 0.036*\"motif_218\" + 0.035*\"motif_23\" + 0.033*\"motif_42\" + 0.028*\"motif_40\" + 0.027*\"motif_13\" + 0.027*\"motif_166\" + 0.025*\"motif_19\"\n",
      "2021-02-22 02:14:14,106 : INFO : topic #2 (0.072): 0.020*\"motif_62\" + 0.019*\"motif_60\" + 0.018*\"motif_54\" + 0.018*\"motif_50\" + 0.018*\"motif_49\" + 0.017*\"motif_48\" + 0.017*\"motif_41\" + 0.015*\"motif_17\" + 0.014*\"motif_93\" + 0.014*\"motif_86\"\n",
      "2021-02-22 02:14:14,107 : INFO : topic diff=0.079008, rho=0.353344\n",
      "2021-02-22 02:14:14,109 : INFO : PROGRESS: pass 1, at document #60000/60095\n",
      "2021-02-22 02:14:14,110 : DEBUG : performing inference on a chunk of 10000 documents\n",
      "2021-02-22 02:14:16,745 : DEBUG : 10000/10000 documents converged within 1000 iterations\n",
      "2021-02-22 02:14:16,771 : INFO : optimized alpha [0.06308265, 0.09502419, 0.0762507]\n",
      "2021-02-22 02:14:16,772 : DEBUG : updating topics\n",
      "2021-02-22 02:14:16,772 : INFO : merging changes from 10000 documents into a model of 60095 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-22 02:14:16,774 : INFO : topic #0 (0.063): 0.031*\"motif_219\" + 0.026*\"motif_60\" + 0.026*\"motif_11\" + 0.025*\"motif_12\" + 0.024*\"motif_10\" + 0.022*\"motif_6\" + 0.022*\"motif_9\" + 0.021*\"motif_264\" + 0.020*\"motif_5\" + 0.020*\"motif_8\"\n",
      "2021-02-22 02:14:16,774 : INFO : topic #1 (0.095): 0.062*\"motif_60\" + 0.046*\"motif_184\" + 0.038*\"motif_37\" + 0.036*\"motif_218\" + 0.035*\"motif_23\" + 0.034*\"motif_42\" + 0.028*\"motif_40\" + 0.027*\"motif_13\" + 0.027*\"motif_166\" + 0.025*\"motif_19\"\n",
      "2021-02-22 02:14:16,775 : INFO : topic #2 (0.076): 0.020*\"motif_62\" + 0.019*\"motif_60\" + 0.019*\"motif_54\" + 0.018*\"motif_50\" + 0.018*\"motif_49\" + 0.017*\"motif_48\" + 0.017*\"motif_41\" + 0.015*\"motif_17\" + 0.014*\"motif_93\" + 0.014*\"motif_86\"\n",
      "2021-02-22 02:14:16,776 : INFO : topic diff=0.075821, rho=0.353344\n",
      "2021-02-22 02:14:16,778 : DEBUG : bound: at document #0\n",
      "2021-02-22 02:14:16,817 : INFO : -5.024 per-word bound, 32.5 perplexity estimate based on a held-out corpus of 95 documents with 2924 words\n",
      "2021-02-22 02:14:16,818 : INFO : PROGRESS: pass 1, at document #60095/60095\n",
      "2021-02-22 02:14:16,818 : DEBUG : performing inference on a chunk of 95 documents\n",
      "2021-02-22 02:14:16,845 : DEBUG : 95/95 documents converged within 1000 iterations\n",
      "2021-02-22 02:14:16,846 : INFO : optimized alpha [0.06379957, 0.09432667, 0.081689924]\n",
      "2021-02-22 02:14:16,847 : DEBUG : updating topics\n",
      "2021-02-22 02:14:16,848 : INFO : merging changes from 95 documents into a model of 60095 documents\n",
      "2021-02-22 02:14:16,850 : INFO : topic #0 (0.064): 0.030*\"motif_219\" + 0.029*\"motif_10\" + 0.029*\"motif_11\" + 0.029*\"motif_12\" + 0.027*\"motif_9\" + 0.025*\"motif_6\" + 0.023*\"motif_60\" + 0.022*\"motif_5\" + 0.022*\"motif_8\" + 0.020*\"motif_264\"\n",
      "2021-02-22 02:14:16,850 : INFO : topic #1 (0.094): 0.065*\"motif_60\" + 0.049*\"motif_184\" + 0.039*\"motif_218\" + 0.038*\"motif_37\" + 0.035*\"motif_23\" + 0.032*\"motif_42\" + 0.029*\"motif_166\" + 0.028*\"motif_13\" + 0.028*\"motif_40\" + 0.025*\"motif_19\"\n",
      "2021-02-22 02:14:16,851 : INFO : topic #2 (0.082): 0.020*\"motif_50\" + 0.020*\"motif_62\" + 0.019*\"motif_49\" + 0.019*\"motif_41\" + 0.019*\"motif_48\" + 0.017*\"motif_60\" + 0.017*\"motif_54\" + 0.015*\"motif_93\" + 0.014*\"motif_58\" + 0.013*\"motif_74\"\n",
      "2021-02-22 02:14:16,852 : INFO : topic diff=0.252065, rho=0.353344\n",
      "2021-02-22 02:14:16,856 : INFO : Epoch 1: Convergence estimate: 2.593120266974714\n",
      "2021-02-22 02:14:16,867 : INFO : PROGRESS: pass 2, at document #10000/60095\n",
      "2021-02-22 02:14:16,868 : DEBUG : performing inference on a chunk of 10000 documents\n",
      "2021-02-22 02:14:20,144 : DEBUG : 10000/10000 documents converged within 1000 iterations\n",
      "2021-02-22 02:14:20,187 : INFO : optimized alpha [0.062647626, 0.0972969, 0.08636845]\n",
      "2021-02-22 02:14:20,188 : DEBUG : updating topics\n",
      "2021-02-22 02:14:20,189 : INFO : merging changes from 10000 documents into a model of 60095 documents\n",
      "2021-02-22 02:14:20,191 : INFO : topic #0 (0.063): 0.032*\"motif_219\" + 0.029*\"motif_11\" + 0.029*\"motif_12\" + 0.028*\"motif_10\" + 0.026*\"motif_9\" + 0.025*\"motif_6\" + 0.023*\"motif_60\" + 0.022*\"motif_5\" + 0.022*\"motif_8\" + 0.022*\"motif_264\"\n",
      "2021-02-22 02:14:20,191 : INFO : topic #1 (0.097): 0.065*\"motif_60\" + 0.048*\"motif_184\" + 0.038*\"motif_218\" + 0.038*\"motif_37\" + 0.035*\"motif_23\" + 0.032*\"motif_42\" + 0.028*\"motif_166\" + 0.028*\"motif_40\" + 0.027*\"motif_13\" + 0.025*\"motif_19\"\n",
      "2021-02-22 02:14:20,192 : INFO : topic #2 (0.086): 0.020*\"motif_62\" + 0.019*\"motif_50\" + 0.018*\"motif_49\" + 0.018*\"motif_60\" + 0.018*\"motif_41\" + 0.018*\"motif_48\" + 0.018*\"motif_54\" + 0.015*\"motif_93\" + 0.013*\"motif_58\" + 0.013*\"motif_86\"\n",
      "2021-02-22 02:14:20,193 : INFO : topic diff=0.101761, rho=0.333158\n",
      "2021-02-22 02:14:20,196 : INFO : PROGRESS: pass 2, at document #20000/60095\n",
      "2021-02-22 02:14:20,197 : DEBUG : performing inference on a chunk of 10000 documents\n",
      "2021-02-22 02:14:23,251 : DEBUG : 10000/10000 documents converged within 1000 iterations\n",
      "2021-02-22 02:14:23,282 : INFO : optimized alpha [0.061636053, 0.100660324, 0.09108037]\n",
      "2021-02-22 02:14:23,283 : DEBUG : updating topics\n",
      "2021-02-22 02:14:23,283 : INFO : merging changes from 10000 documents into a model of 60095 documents\n",
      "2021-02-22 02:14:23,284 : INFO : topic #0 (0.062): 0.034*\"motif_219\" + 0.029*\"motif_11\" + 0.029*\"motif_12\" + 0.028*\"motif_10\" + 0.026*\"motif_9\" + 0.025*\"motif_6\" + 0.023*\"motif_264\" + 0.023*\"motif_5\" + 0.023*\"motif_60\" + 0.022*\"motif_8\"\n",
      "2021-02-22 02:14:23,285 : INFO : topic #1 (0.101): 0.065*\"motif_60\" + 0.048*\"motif_184\" + 0.038*\"motif_37\" + 0.038*\"motif_218\" + 0.035*\"motif_23\" + 0.033*\"motif_42\" + 0.028*\"motif_166\" + 0.028*\"motif_40\" + 0.027*\"motif_13\" + 0.025*\"motif_19\"\n",
      "2021-02-22 02:14:23,286 : INFO : topic #2 (0.091): 0.020*\"motif_62\" + 0.019*\"motif_60\" + 0.018*\"motif_50\" + 0.018*\"motif_54\" + 0.018*\"motif_49\" + 0.017*\"motif_41\" + 0.017*\"motif_48\" + 0.014*\"motif_93\" + 0.014*\"motif_17\" + 0.013*\"motif_86\"\n",
      "2021-02-22 02:14:23,287 : INFO : topic diff=0.085953, rho=0.333158\n",
      "2021-02-22 02:14:23,289 : INFO : PROGRESS: pass 2, at document #30000/60095\n",
      "2021-02-22 02:14:23,290 : DEBUG : performing inference on a chunk of 10000 documents\n",
      "2021-02-22 02:14:26,419 : DEBUG : 10000/10000 documents converged within 1000 iterations\n",
      "2021-02-22 02:14:26,448 : INFO : optimized alpha [0.060624205, 0.103646375, 0.09579678]\n",
      "2021-02-22 02:14:26,448 : DEBUG : updating topics\n",
      "2021-02-22 02:14:26,449 : INFO : merging changes from 10000 documents into a model of 60095 documents\n",
      "2021-02-22 02:14:26,450 : INFO : topic #0 (0.061): 0.035*\"motif_219\" + 0.030*\"motif_11\" + 0.029*\"motif_12\" + 0.029*\"motif_10\" + 0.026*\"motif_9\" + 0.025*\"motif_6\" + 0.024*\"motif_264\" + 0.023*\"motif_5\" + 0.023*\"motif_8\" + 0.022*\"motif_60\"\n",
      "2021-02-22 02:14:26,451 : INFO : topic #1 (0.104): 0.065*\"motif_60\" + 0.048*\"motif_184\" + 0.038*\"motif_37\" + 0.038*\"motif_218\" + 0.035*\"motif_23\" + 0.034*\"motif_42\" + 0.028*\"motif_40\" + 0.028*\"motif_166\" + 0.027*\"motif_13\" + 0.025*\"motif_19\"\n",
      "2021-02-22 02:14:26,451 : INFO : topic #2 (0.096): 0.020*\"motif_62\" + 0.019*\"motif_60\" + 0.018*\"motif_50\" + 0.018*\"motif_54\" + 0.017*\"motif_49\" + 0.017*\"motif_48\" + 0.016*\"motif_41\" + 0.014*\"motif_17\" + 0.014*\"motif_93\" + 0.013*\"motif_86\"\n",
      "2021-02-22 02:14:26,452 : INFO : topic diff=0.081247, rho=0.333158\n",
      "2021-02-22 02:14:26,455 : INFO : PROGRESS: pass 2, at document #40000/60095\n",
      "2021-02-22 02:14:26,456 : DEBUG : performing inference on a chunk of 10000 documents\n",
      "2021-02-22 02:14:29,023 : DEBUG : 10000/10000 documents converged within 1000 iterations\n",
      "2021-02-22 02:14:29,052 : INFO : optimized alpha [0.059704397, 0.10673907, 0.10142236]\n",
      "2021-02-22 02:14:29,053 : DEBUG : updating topics\n",
      "2021-02-22 02:14:29,054 : INFO : merging changes from 10000 documents into a model of 60095 documents\n",
      "2021-02-22 02:14:29,056 : INFO : topic #0 (0.060): 0.037*\"motif_219\" + 0.030*\"motif_11\" + 0.030*\"motif_12\" + 0.029*\"motif_10\" + 0.026*\"motif_6\" + 0.026*\"motif_9\" + 0.025*\"motif_264\" + 0.024*\"motif_5\" + 0.023*\"motif_8\" + 0.022*\"motif_60\"\n",
      "2021-02-22 02:14:29,056 : INFO : topic #1 (0.107): 0.064*\"motif_60\" + 0.048*\"motif_184\" + 0.039*\"motif_37\" + 0.038*\"motif_218\" + 0.035*\"motif_23\" + 0.034*\"motif_42\" + 0.028*\"motif_40\" + 0.028*\"motif_13\" + 0.027*\"motif_166\" + 0.025*\"motif_19\"\n",
      "2021-02-22 02:14:29,057 : INFO : topic #2 (0.101): 0.021*\"motif_62\" + 0.020*\"motif_60\" + 0.018*\"motif_54\" + 0.017*\"motif_50\" + 0.017*\"motif_49\" + 0.016*\"motif_48\" + 0.016*\"motif_41\" + 0.014*\"motif_17\" + 0.014*\"motif_93\" + 0.014*\"motif_126\"\n",
      "2021-02-22 02:14:29,058 : INFO : topic diff=0.077350, rho=0.333158\n",
      "2021-02-22 02:14:29,060 : INFO : PROGRESS: pass 2, at document #50000/60095\n",
      "2021-02-22 02:14:29,061 : DEBUG : performing inference on a chunk of 10000 documents\n",
      "2021-02-22 02:14:31,440 : DEBUG : 10000/10000 documents converged within 1000 iterations\n",
      "2021-02-22 02:14:31,469 : INFO : optimized alpha [0.058560446, 0.109783724, 0.10763232]\n",
      "2021-02-22 02:14:31,469 : DEBUG : updating topics\n",
      "2021-02-22 02:14:31,470 : INFO : merging changes from 10000 documents into a model of 60095 documents\n",
      "2021-02-22 02:14:31,471 : INFO : topic #0 (0.059): 0.039*\"motif_219\" + 0.031*\"motif_11\" + 0.031*\"motif_12\" + 0.030*\"motif_10\" + 0.027*\"motif_6\" + 0.026*\"motif_9\" + 0.026*\"motif_264\" + 0.025*\"motif_5\" + 0.024*\"motif_8\" + 0.022*\"motif_60\"\n",
      "2021-02-22 02:14:31,472 : INFO : topic #1 (0.110): 0.064*\"motif_60\" + 0.047*\"motif_184\" + 0.039*\"motif_37\" + 0.037*\"motif_218\" + 0.036*\"motif_23\" + 0.034*\"motif_42\" + 0.029*\"motif_40\" + 0.028*\"motif_13\" + 0.027*\"motif_166\" + 0.025*\"motif_19\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-22 02:14:31,473 : INFO : topic #2 (0.108): 0.021*\"motif_62\" + 0.020*\"motif_60\" + 0.018*\"motif_54\" + 0.017*\"motif_50\" + 0.016*\"motif_49\" + 0.016*\"motif_48\" + 0.015*\"motif_41\" + 0.014*\"motif_126\" + 0.014*\"motif_17\" + 0.013*\"motif_121\"\n",
      "2021-02-22 02:14:31,473 : INFO : topic diff=0.075316, rho=0.333158\n",
      "2021-02-22 02:14:31,475 : INFO : PROGRESS: pass 2, at document #60000/60095\n",
      "2021-02-22 02:14:31,476 : DEBUG : performing inference on a chunk of 10000 documents\n",
      "2021-02-22 02:14:34,013 : DEBUG : 10000/10000 documents converged within 1000 iterations\n",
      "2021-02-22 02:14:34,064 : INFO : optimized alpha [0.057604365, 0.112797245, 0.11429829]\n",
      "2021-02-22 02:14:34,065 : DEBUG : updating topics\n",
      "2021-02-22 02:14:34,066 : INFO : merging changes from 10000 documents into a model of 60095 documents\n",
      "2021-02-22 02:14:34,067 : INFO : topic #0 (0.058): 0.040*\"motif_219\" + 0.032*\"motif_11\" + 0.032*\"motif_12\" + 0.031*\"motif_10\" + 0.027*\"motif_264\" + 0.027*\"motif_6\" + 0.027*\"motif_9\" + 0.026*\"motif_5\" + 0.025*\"motif_8\" + 0.021*\"motif_60\"\n",
      "2021-02-22 02:14:34,068 : INFO : topic #1 (0.113): 0.064*\"motif_60\" + 0.047*\"motif_184\" + 0.039*\"motif_37\" + 0.037*\"motif_218\" + 0.036*\"motif_23\" + 0.034*\"motif_42\" + 0.029*\"motif_40\" + 0.028*\"motif_13\" + 0.027*\"motif_166\" + 0.026*\"motif_19\"\n",
      "2021-02-22 02:14:34,068 : INFO : topic #2 (0.114): 0.021*\"motif_62\" + 0.021*\"motif_60\" + 0.018*\"motif_54\" + 0.016*\"motif_50\" + 0.016*\"motif_49\" + 0.015*\"motif_48\" + 0.015*\"motif_41\" + 0.015*\"motif_126\" + 0.014*\"motif_17\" + 0.013*\"motif_84\"\n",
      "2021-02-22 02:14:34,071 : INFO : topic diff=0.072594, rho=0.333158\n",
      "2021-02-22 02:14:34,073 : DEBUG : bound: at document #0\n",
      "2021-02-22 02:14:34,127 : INFO : -5.004 per-word bound, 32.1 perplexity estimate based on a held-out corpus of 95 documents with 2924 words\n",
      "2021-02-22 02:14:34,127 : INFO : PROGRESS: pass 2, at document #60095/60095\n",
      "2021-02-22 02:14:34,128 : DEBUG : performing inference on a chunk of 95 documents\n",
      "2021-02-22 02:14:34,164 : DEBUG : 95/95 documents converged within 1000 iterations\n",
      "2021-02-22 02:14:34,166 : INFO : optimized alpha [0.05786347, 0.111988574, 0.12218874]\n",
      "2021-02-22 02:14:34,167 : DEBUG : updating topics\n",
      "2021-02-22 02:14:34,168 : INFO : merging changes from 95 documents into a model of 60095 documents\n",
      "2021-02-22 02:14:34,169 : INFO : topic #0 (0.058): 0.038*\"motif_219\" + 0.035*\"motif_10\" + 0.035*\"motif_11\" + 0.035*\"motif_12\" + 0.033*\"motif_9\" + 0.030*\"motif_6\" + 0.027*\"motif_5\" + 0.027*\"motif_8\" + 0.025*\"motif_264\" + 0.021*\"motif_4\"\n",
      "2021-02-22 02:14:34,170 : INFO : topic #1 (0.112): 0.066*\"motif_60\" + 0.050*\"motif_184\" + 0.040*\"motif_218\" + 0.039*\"motif_37\" + 0.036*\"motif_23\" + 0.032*\"motif_42\" + 0.029*\"motif_166\" + 0.029*\"motif_13\" + 0.028*\"motif_40\" + 0.026*\"motif_19\"\n",
      "2021-02-22 02:14:34,170 : INFO : topic #2 (0.122): 0.022*\"motif_62\" + 0.019*\"motif_60\" + 0.018*\"motif_50\" + 0.017*\"motif_49\" + 0.017*\"motif_41\" + 0.017*\"motif_48\" + 0.016*\"motif_54\" + 0.014*\"motif_93\" + 0.013*\"motif_126\" + 0.012*\"motif_58\"\n",
      "2021-02-22 02:14:34,171 : INFO : topic diff=0.237336, rho=0.333158\n",
      "2021-02-22 02:14:34,175 : INFO : Epoch 2: Convergence estimate: 1.8609683355542863\n",
      "2021-02-22 02:14:34,183 : INFO : PROGRESS: pass 3, at document #10000/60095\n",
      "2021-02-22 02:14:34,184 : DEBUG : performing inference on a chunk of 10000 documents\n",
      "2021-02-22 02:14:36,877 : DEBUG : 10000/10000 documents converged within 1000 iterations\n",
      "2021-02-22 02:14:36,906 : INFO : optimized alpha [0.057083085, 0.115726896, 0.12920094]\n",
      "2021-02-22 02:14:36,907 : DEBUG : updating topics\n",
      "2021-02-22 02:14:36,907 : INFO : merging changes from 10000 documents into a model of 60095 documents\n",
      "2021-02-22 02:14:36,909 : INFO : topic #0 (0.057): 0.040*\"motif_219\" + 0.035*\"motif_11\" + 0.035*\"motif_12\" + 0.035*\"motif_10\" + 0.032*\"motif_9\" + 0.030*\"motif_6\" + 0.028*\"motif_5\" + 0.027*\"motif_264\" + 0.027*\"motif_8\" + 0.022*\"motif_4\"\n",
      "2021-02-22 02:14:36,909 : INFO : topic #1 (0.116): 0.066*\"motif_60\" + 0.049*\"motif_184\" + 0.039*\"motif_218\" + 0.039*\"motif_37\" + 0.036*\"motif_23\" + 0.033*\"motif_42\" + 0.029*\"motif_166\" + 0.028*\"motif_40\" + 0.028*\"motif_13\" + 0.025*\"motif_19\"\n",
      "2021-02-22 02:14:36,910 : INFO : topic #2 (0.129): 0.022*\"motif_62\" + 0.019*\"motif_60\" + 0.017*\"motif_50\" + 0.017*\"motif_49\" + 0.016*\"motif_54\" + 0.016*\"motif_41\" + 0.016*\"motif_48\" + 0.014*\"motif_126\" + 0.014*\"motif_93\" + 0.013*\"motif_84\"\n",
      "2021-02-22 02:14:36,911 : INFO : topic diff=0.090705, rho=0.316078\n",
      "2021-02-22 02:14:36,913 : INFO : PROGRESS: pass 3, at document #20000/60095\n",
      "2021-02-22 02:14:36,914 : DEBUG : performing inference on a chunk of 10000 documents\n",
      "2021-02-22 02:14:39,186 : DEBUG : 10000/10000 documents converged within 1000 iterations\n",
      "2021-02-22 02:14:39,215 : INFO : optimized alpha [0.05651418, 0.119950056, 0.1358755]\n",
      "2021-02-22 02:14:39,216 : DEBUG : updating topics\n",
      "2021-02-22 02:14:39,217 : INFO : merging changes from 10000 documents into a model of 60095 documents\n",
      "2021-02-22 02:14:39,218 : INFO : topic #0 (0.057): 0.043*\"motif_219\" + 0.036*\"motif_11\" + 0.036*\"motif_12\" + 0.035*\"motif_10\" + 0.032*\"motif_9\" + 0.031*\"motif_6\" + 0.029*\"motif_264\" + 0.028*\"motif_5\" + 0.027*\"motif_8\" + 0.023*\"motif_4\"\n",
      "2021-02-22 02:14:39,219 : INFO : topic #1 (0.120): 0.066*\"motif_60\" + 0.049*\"motif_184\" + 0.039*\"motif_37\" + 0.038*\"motif_218\" + 0.036*\"motif_23\" + 0.034*\"motif_42\" + 0.029*\"motif_40\" + 0.029*\"motif_166\" + 0.028*\"motif_13\" + 0.026*\"motif_19\"\n",
      "2021-02-22 02:14:39,219 : INFO : topic #2 (0.136): 0.022*\"motif_62\" + 0.020*\"motif_60\" + 0.017*\"motif_50\" + 0.017*\"motif_54\" + 0.016*\"motif_49\" + 0.015*\"motif_41\" + 0.015*\"motif_48\" + 0.015*\"motif_126\" + 0.014*\"motif_84\" + 0.013*\"motif_93\"\n",
      "2021-02-22 02:14:39,220 : INFO : topic diff=0.078975, rho=0.316078\n",
      "2021-02-22 02:14:39,223 : INFO : PROGRESS: pass 3, at document #30000/60095\n",
      "2021-02-22 02:14:39,223 : DEBUG : performing inference on a chunk of 10000 documents\n",
      "2021-02-22 02:14:41,474 : DEBUG : 10000/10000 documents converged within 1000 iterations\n",
      "2021-02-22 02:14:41,501 : INFO : optimized alpha [0.05604883, 0.12353281, 0.14242515]\n",
      "2021-02-22 02:14:41,502 : DEBUG : updating topics\n",
      "2021-02-22 02:14:41,503 : INFO : merging changes from 10000 documents into a model of 60095 documents\n",
      "2021-02-22 02:14:41,504 : INFO : topic #0 (0.056): 0.044*\"motif_219\" + 0.036*\"motif_11\" + 0.036*\"motif_12\" + 0.035*\"motif_10\" + 0.032*\"motif_9\" + 0.031*\"motif_6\" + 0.030*\"motif_264\" + 0.029*\"motif_5\" + 0.028*\"motif_8\" + 0.023*\"motif_4\"\n",
      "2021-02-22 02:14:41,506 : INFO : topic #1 (0.124): 0.066*\"motif_60\" + 0.049*\"motif_184\" + 0.039*\"motif_37\" + 0.038*\"motif_218\" + 0.036*\"motif_23\" + 0.034*\"motif_42\" + 0.029*\"motif_40\" + 0.028*\"motif_13\" + 0.028*\"motif_166\" + 0.026*\"motif_19\"\n",
      "2021-02-22 02:14:41,506 : INFO : topic #2 (0.142): 0.022*\"motif_62\" + 0.021*\"motif_60\" + 0.016*\"motif_54\" + 0.016*\"motif_50\" + 0.016*\"motif_49\" + 0.015*\"motif_126\" + 0.015*\"motif_48\" + 0.015*\"motif_41\" + 0.014*\"motif_84\" + 0.013*\"motif_17\"\n",
      "2021-02-22 02:14:41,507 : INFO : topic diff=0.073420, rho=0.316078\n",
      "2021-02-22 02:14:41,510 : INFO : PROGRESS: pass 3, at document #40000/60095\n",
      "2021-02-22 02:14:41,510 : DEBUG : performing inference on a chunk of 10000 documents\n",
      "2021-02-22 02:14:43,730 : DEBUG : 10000/10000 documents converged within 1000 iterations\n",
      "2021-02-22 02:14:43,755 : INFO : optimized alpha [0.055817574, 0.12715802, 0.14956346]\n",
      "2021-02-22 02:14:43,756 : DEBUG : updating topics\n",
      "2021-02-22 02:14:43,757 : INFO : merging changes from 10000 documents into a model of 60095 documents\n",
      "2021-02-22 02:14:43,758 : INFO : topic #0 (0.056): 0.045*\"motif_219\" + 0.037*\"motif_11\" + 0.036*\"motif_12\" + 0.035*\"motif_10\" + 0.032*\"motif_9\" + 0.031*\"motif_6\" + 0.031*\"motif_264\" + 0.029*\"motif_5\" + 0.028*\"motif_8\" + 0.024*\"motif_4\"\n",
      "2021-02-22 02:14:43,760 : INFO : topic #1 (0.127): 0.065*\"motif_60\" + 0.049*\"motif_184\" + 0.039*\"motif_37\" + 0.038*\"motif_218\" + 0.036*\"motif_23\" + 0.034*\"motif_42\" + 0.029*\"motif_40\" + 0.028*\"motif_13\" + 0.028*\"motif_166\" + 0.026*\"motif_19\"\n",
      "2021-02-22 02:14:43,761 : INFO : topic #2 (0.150): 0.022*\"motif_62\" + 0.021*\"motif_60\" + 0.017*\"motif_54\" + 0.016*\"motif_126\" + 0.016*\"motif_50\" + 0.015*\"motif_49\" + 0.015*\"motif_48\" + 0.015*\"motif_41\" + 0.015*\"motif_84\" + 0.013*\"motif_17\"\n",
      "2021-02-22 02:14:43,761 : INFO : topic diff=0.067197, rho=0.316078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-22 02:14:43,764 : INFO : PROGRESS: pass 3, at document #50000/60095\n",
      "2021-02-22 02:14:43,764 : DEBUG : performing inference on a chunk of 10000 documents\n",
      "2021-02-22 02:14:46,165 : DEBUG : 10000/10000 documents converged within 1000 iterations\n",
      "2021-02-22 02:14:46,191 : INFO : optimized alpha [0.055419255, 0.13056453, 0.15670875]\n",
      "2021-02-22 02:14:46,192 : DEBUG : updating topics\n",
      "2021-02-22 02:14:46,193 : INFO : merging changes from 10000 documents into a model of 60095 documents\n",
      "2021-02-22 02:14:46,194 : INFO : topic #0 (0.055): 0.047*\"motif_219\" + 0.037*\"motif_11\" + 0.037*\"motif_12\" + 0.035*\"motif_10\" + 0.032*\"motif_264\" + 0.032*\"motif_6\" + 0.032*\"motif_9\" + 0.030*\"motif_5\" + 0.028*\"motif_8\" + 0.024*\"motif_4\"\n",
      "2021-02-22 02:14:46,195 : INFO : topic #1 (0.131): 0.065*\"motif_60\" + 0.049*\"motif_184\" + 0.040*\"motif_37\" + 0.038*\"motif_218\" + 0.037*\"motif_23\" + 0.035*\"motif_42\" + 0.029*\"motif_40\" + 0.029*\"motif_13\" + 0.028*\"motif_166\" + 0.026*\"motif_19\"\n",
      "2021-02-22 02:14:46,196 : INFO : topic #2 (0.157): 0.022*\"motif_62\" + 0.022*\"motif_60\" + 0.017*\"motif_126\" + 0.017*\"motif_54\" + 0.015*\"motif_50\" + 0.015*\"motif_84\" + 0.015*\"motif_49\" + 0.014*\"motif_48\" + 0.014*\"motif_41\" + 0.013*\"motif_17\"\n",
      "2021-02-22 02:14:46,196 : INFO : topic diff=0.064762, rho=0.316078\n",
      "2021-02-22 02:14:46,198 : INFO : PROGRESS: pass 3, at document #60000/60095\n",
      "2021-02-22 02:14:46,198 : DEBUG : performing inference on a chunk of 10000 documents\n",
      "2021-02-22 02:14:48,476 : DEBUG : 10000/10000 documents converged within 1000 iterations\n",
      "2021-02-22 02:14:48,504 : INFO : optimized alpha [0.05527561, 0.13388464, 0.1636866]\n",
      "2021-02-22 02:14:48,505 : DEBUG : updating topics\n",
      "2021-02-22 02:14:48,506 : INFO : merging changes from 10000 documents into a model of 60095 documents\n",
      "2021-02-22 02:14:48,508 : INFO : topic #0 (0.055): 0.048*\"motif_219\" + 0.038*\"motif_11\" + 0.037*\"motif_12\" + 0.036*\"motif_10\" + 0.033*\"motif_264\" + 0.032*\"motif_6\" + 0.032*\"motif_9\" + 0.030*\"motif_5\" + 0.029*\"motif_8\" + 0.025*\"motif_4\"\n",
      "2021-02-22 02:14:48,509 : INFO : topic #1 (0.134): 0.065*\"motif_60\" + 0.049*\"motif_184\" + 0.040*\"motif_37\" + 0.038*\"motif_218\" + 0.037*\"motif_23\" + 0.035*\"motif_42\" + 0.029*\"motif_40\" + 0.029*\"motif_13\" + 0.028*\"motif_166\" + 0.026*\"motif_19\"\n",
      "2021-02-22 02:14:48,509 : INFO : topic #2 (0.164): 0.022*\"motif_60\" + 0.022*\"motif_62\" + 0.017*\"motif_126\" + 0.017*\"motif_54\" + 0.015*\"motif_84\" + 0.015*\"motif_50\" + 0.015*\"motif_49\" + 0.014*\"motif_48\" + 0.014*\"motif_41\" + 0.013*\"motif_17\"\n",
      "2021-02-22 02:14:48,510 : INFO : topic diff=0.059835, rho=0.316078\n",
      "2021-02-22 02:14:48,512 : DEBUG : bound: at document #0\n",
      "2021-02-22 02:14:48,552 : INFO : -4.994 per-word bound, 31.9 perplexity estimate based on a held-out corpus of 95 documents with 2924 words\n",
      "2021-02-22 02:14:48,552 : INFO : PROGRESS: pass 3, at document #60095/60095\n",
      "2021-02-22 02:14:48,553 : DEBUG : performing inference on a chunk of 95 documents\n",
      "2021-02-22 02:14:48,577 : DEBUG : 95/95 documents converged within 1000 iterations\n",
      "2021-02-22 02:14:48,578 : INFO : optimized alpha [0.05612126, 0.13378604, 0.17102082]\n",
      "2021-02-22 02:14:48,579 : DEBUG : updating topics\n",
      "2021-02-22 02:14:48,579 : INFO : merging changes from 95 documents into a model of 60095 documents\n",
      "2021-02-22 02:14:48,581 : INFO : topic #0 (0.056): 0.044*\"motif_219\" + 0.040*\"motif_10\" + 0.040*\"motif_11\" + 0.040*\"motif_12\" + 0.037*\"motif_9\" + 0.034*\"motif_6\" + 0.031*\"motif_5\" + 0.031*\"motif_8\" + 0.030*\"motif_264\" + 0.025*\"motif_4\"\n",
      "2021-02-22 02:14:48,581 : INFO : topic #1 (0.134): 0.066*\"motif_60\" + 0.051*\"motif_184\" + 0.040*\"motif_218\" + 0.040*\"motif_37\" + 0.037*\"motif_23\" + 0.033*\"motif_42\" + 0.029*\"motif_166\" + 0.029*\"motif_13\" + 0.029*\"motif_40\" + 0.026*\"motif_19\"\n",
      "2021-02-22 02:14:48,582 : INFO : topic #2 (0.171): 0.022*\"motif_62\" + 0.020*\"motif_60\" + 0.017*\"motif_50\" + 0.016*\"motif_49\" + 0.016*\"motif_41\" + 0.016*\"motif_54\" + 0.016*\"motif_48\" + 0.015*\"motif_126\" + 0.014*\"motif_84\" + 0.014*\"motif_93\"\n",
      "2021-02-22 02:14:48,583 : INFO : topic diff=0.220987, rho=0.316078\n",
      "2021-02-22 02:14:48,586 : INFO : Epoch 3: Convergence estimate: 1.819571277516101\n",
      "2021-02-22 02:14:48,596 : INFO : PROGRESS: pass 4, at document #10000/60095\n",
      "2021-02-22 02:14:48,597 : DEBUG : performing inference on a chunk of 10000 documents\n",
      "2021-02-22 02:14:50,817 : DEBUG : 10000/10000 documents converged within 1000 iterations\n",
      "2021-02-22 02:14:50,845 : INFO : optimized alpha [0.055938147, 0.13758187, 0.17808272]\n",
      "2021-02-22 02:14:50,846 : DEBUG : updating topics\n",
      "2021-02-22 02:14:50,847 : INFO : merging changes from 10000 documents into a model of 60095 documents\n",
      "2021-02-22 02:14:50,848 : INFO : topic #0 (0.056): 0.046*\"motif_219\" + 0.040*\"motif_11\" + 0.040*\"motif_12\" + 0.040*\"motif_10\" + 0.036*\"motif_9\" + 0.034*\"motif_6\" + 0.031*\"motif_5\" + 0.031*\"motif_264\" + 0.031*\"motif_8\" + 0.025*\"motif_4\"\n",
      "2021-02-22 02:14:50,848 : INFO : topic #1 (0.138): 0.066*\"motif_60\" + 0.050*\"motif_184\" + 0.040*\"motif_37\" + 0.039*\"motif_218\" + 0.036*\"motif_23\" + 0.034*\"motif_42\" + 0.029*\"motif_166\" + 0.029*\"motif_40\" + 0.029*\"motif_13\" + 0.026*\"motif_19\"\n",
      "2021-02-22 02:14:50,849 : INFO : topic #2 (0.178): 0.022*\"motif_62\" + 0.021*\"motif_60\" + 0.017*\"motif_50\" + 0.016*\"motif_54\" + 0.016*\"motif_49\" + 0.015*\"motif_126\" + 0.015*\"motif_41\" + 0.015*\"motif_48\" + 0.015*\"motif_84\" + 0.013*\"motif_93\"\n",
      "2021-02-22 02:14:50,850 : INFO : topic diff=0.076875, rho=0.301381\n",
      "2021-02-22 02:14:50,852 : INFO : PROGRESS: pass 4, at document #20000/60095\n",
      "2021-02-22 02:14:50,852 : DEBUG : performing inference on a chunk of 10000 documents\n",
      "2021-02-22 02:14:53,012 : DEBUG : 10000/10000 documents converged within 1000 iterations\n",
      "2021-02-22 02:14:53,040 : INFO : optimized alpha [0.055922013, 0.14187954, 0.18420145]\n",
      "2021-02-22 02:14:53,040 : DEBUG : updating topics\n",
      "2021-02-22 02:14:53,041 : INFO : merging changes from 10000 documents into a model of 60095 documents\n",
      "2021-02-22 02:14:53,042 : INFO : topic #0 (0.056): 0.048*\"motif_219\" + 0.040*\"motif_11\" + 0.040*\"motif_12\" + 0.039*\"motif_10\" + 0.035*\"motif_9\" + 0.034*\"motif_6\" + 0.033*\"motif_264\" + 0.032*\"motif_5\" + 0.031*\"motif_8\" + 0.025*\"motif_4\"\n",
      "2021-02-22 02:14:53,042 : INFO : topic #1 (0.142): 0.066*\"motif_60\" + 0.050*\"motif_184\" + 0.040*\"motif_37\" + 0.039*\"motif_218\" + 0.037*\"motif_23\" + 0.034*\"motif_42\" + 0.029*\"motif_40\" + 0.029*\"motif_166\" + 0.029*\"motif_13\" + 0.026*\"motif_19\"\n",
      "2021-02-22 02:14:53,043 : INFO : topic #2 (0.184): 0.022*\"motif_62\" + 0.021*\"motif_60\" + 0.016*\"motif_50\" + 0.016*\"motif_54\" + 0.016*\"motif_126\" + 0.015*\"motif_49\" + 0.015*\"motif_84\" + 0.015*\"motif_41\" + 0.015*\"motif_48\" + 0.013*\"motif_93\"\n",
      "2021-02-22 02:14:53,043 : INFO : topic diff=0.067452, rho=0.301381\n",
      "2021-02-22 02:14:53,045 : INFO : PROGRESS: pass 4, at document #30000/60095\n",
      "2021-02-22 02:14:53,046 : DEBUG : performing inference on a chunk of 10000 documents\n",
      "2021-02-22 02:14:55,229 : DEBUG : 10000/10000 documents converged within 1000 iterations\n",
      "2021-02-22 02:14:55,258 : INFO : optimized alpha [0.055927992, 0.14542815, 0.19009057]\n",
      "2021-02-22 02:14:55,258 : DEBUG : updating topics\n",
      "2021-02-22 02:14:55,259 : INFO : merging changes from 10000 documents into a model of 60095 documents\n",
      "2021-02-22 02:14:55,260 : INFO : topic #0 (0.056): 0.049*\"motif_219\" + 0.040*\"motif_11\" + 0.040*\"motif_12\" + 0.039*\"motif_10\" + 0.035*\"motif_9\" + 0.034*\"motif_6\" + 0.033*\"motif_264\" + 0.032*\"motif_5\" + 0.031*\"motif_8\" + 0.026*\"motif_4\"\n",
      "2021-02-22 02:14:55,261 : INFO : topic #1 (0.145): 0.066*\"motif_60\" + 0.050*\"motif_184\" + 0.040*\"motif_37\" + 0.039*\"motif_218\" + 0.037*\"motif_23\" + 0.035*\"motif_42\" + 0.029*\"motif_40\" + 0.029*\"motif_13\" + 0.028*\"motif_166\" + 0.026*\"motif_19\"\n",
      "2021-02-22 02:14:55,261 : INFO : topic #2 (0.190): 0.022*\"motif_62\" + 0.022*\"motif_60\" + 0.016*\"motif_126\" + 0.016*\"motif_54\" + 0.016*\"motif_50\" + 0.016*\"motif_84\" + 0.015*\"motif_49\" + 0.014*\"motif_48\" + 0.014*\"motif_41\" + 0.013*\"motif_17\"\n",
      "2021-02-22 02:14:55,262 : INFO : topic diff=0.061829, rho=0.301381\n",
      "2021-02-22 02:14:55,264 : INFO : PROGRESS: pass 4, at document #40000/60095\n",
      "2021-02-22 02:14:55,264 : DEBUG : performing inference on a chunk of 10000 documents\n",
      "2021-02-22 02:14:57,497 : DEBUG : 10000/10000 documents converged within 1000 iterations\n",
      "2021-02-22 02:14:57,525 : INFO : optimized alpha [0.05610874, 0.148872, 0.19644341]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-22 02:14:57,525 : DEBUG : updating topics\n",
      "2021-02-22 02:14:57,526 : INFO : merging changes from 10000 documents into a model of 60095 documents\n",
      "2021-02-22 02:14:57,527 : INFO : topic #0 (0.056): 0.050*\"motif_219\" + 0.040*\"motif_11\" + 0.040*\"motif_12\" + 0.039*\"motif_10\" + 0.035*\"motif_9\" + 0.035*\"motif_6\" + 0.034*\"motif_264\" + 0.032*\"motif_5\" + 0.031*\"motif_8\" + 0.026*\"motif_4\"\n",
      "2021-02-22 02:14:57,528 : INFO : topic #1 (0.149): 0.065*\"motif_60\" + 0.050*\"motif_184\" + 0.040*\"motif_37\" + 0.039*\"motif_218\" + 0.037*\"motif_23\" + 0.035*\"motif_42\" + 0.029*\"motif_40\" + 0.029*\"motif_13\" + 0.028*\"motif_166\" + 0.026*\"motif_19\"\n",
      "2021-02-22 02:14:57,528 : INFO : topic #2 (0.196): 0.022*\"motif_62\" + 0.022*\"motif_60\" + 0.017*\"motif_126\" + 0.016*\"motif_54\" + 0.016*\"motif_84\" + 0.015*\"motif_50\" + 0.015*\"motif_49\" + 0.014*\"motif_48\" + 0.014*\"motif_41\" + 0.013*\"motif_17\"\n",
      "2021-02-22 02:14:57,529 : INFO : topic diff=0.055364, rho=0.301381\n",
      "2021-02-22 02:14:57,531 : INFO : PROGRESS: pass 4, at document #50000/60095\n",
      "2021-02-22 02:14:57,532 : DEBUG : performing inference on a chunk of 10000 documents\n",
      "2021-02-22 02:14:59,637 : DEBUG : 10000/10000 documents converged within 1000 iterations\n",
      "2021-02-22 02:14:59,663 : INFO : optimized alpha [0.056086574, 0.1520588, 0.20278905]\n",
      "2021-02-22 02:14:59,663 : DEBUG : updating topics\n",
      "2021-02-22 02:14:59,664 : INFO : merging changes from 10000 documents into a model of 60095 documents\n",
      "2021-02-22 02:14:59,665 : INFO : topic #0 (0.056): 0.052*\"motif_219\" + 0.040*\"motif_11\" + 0.040*\"motif_12\" + 0.038*\"motif_10\" + 0.035*\"motif_264\" + 0.035*\"motif_6\" + 0.035*\"motif_9\" + 0.032*\"motif_5\" + 0.031*\"motif_8\" + 0.027*\"motif_4\"\n",
      "2021-02-22 02:14:59,666 : INFO : topic #1 (0.152): 0.065*\"motif_60\" + 0.049*\"motif_184\" + 0.041*\"motif_37\" + 0.039*\"motif_218\" + 0.037*\"motif_23\" + 0.035*\"motif_42\" + 0.030*\"motif_40\" + 0.029*\"motif_13\" + 0.028*\"motif_166\" + 0.026*\"motif_19\"\n",
      "2021-02-22 02:14:59,667 : INFO : topic #2 (0.203): 0.023*\"motif_60\" + 0.022*\"motif_62\" + 0.017*\"motif_126\" + 0.016*\"motif_54\" + 0.016*\"motif_84\" + 0.015*\"motif_50\" + 0.014*\"motif_49\" + 0.014*\"motif_48\" + 0.014*\"motif_41\" + 0.013*\"motif_17\"\n",
      "2021-02-22 02:14:59,668 : INFO : topic diff=0.053868, rho=0.301381\n",
      "2021-02-22 02:14:59,670 : INFO : PROGRESS: pass 4, at document #60000/60095\n",
      "2021-02-22 02:14:59,670 : DEBUG : performing inference on a chunk of 10000 documents\n",
      "2021-02-22 02:15:01,736 : DEBUG : 10000/10000 documents converged within 1000 iterations\n",
      "2021-02-22 02:15:01,763 : INFO : optimized alpha [0.056270905, 0.1550852, 0.20892778]\n",
      "2021-02-22 02:15:01,764 : DEBUG : updating topics\n",
      "2021-02-22 02:15:01,764 : INFO : merging changes from 10000 documents into a model of 60095 documents\n",
      "2021-02-22 02:15:01,766 : INFO : topic #0 (0.056): 0.052*\"motif_219\" + 0.041*\"motif_11\" + 0.040*\"motif_12\" + 0.039*\"motif_10\" + 0.035*\"motif_264\" + 0.035*\"motif_6\" + 0.035*\"motif_9\" + 0.033*\"motif_5\" + 0.031*\"motif_8\" + 0.027*\"motif_4\"\n",
      "2021-02-22 02:15:01,767 : INFO : topic #1 (0.155): 0.065*\"motif_60\" + 0.049*\"motif_184\" + 0.040*\"motif_37\" + 0.038*\"motif_218\" + 0.037*\"motif_23\" + 0.036*\"motif_42\" + 0.030*\"motif_40\" + 0.029*\"motif_13\" + 0.028*\"motif_166\" + 0.026*\"motif_19\"\n",
      "2021-02-22 02:15:01,768 : INFO : topic #2 (0.209): 0.023*\"motif_60\" + 0.022*\"motif_62\" + 0.017*\"motif_126\" + 0.016*\"motif_54\" + 0.016*\"motif_84\" + 0.015*\"motif_50\" + 0.014*\"motif_49\" + 0.014*\"motif_48\" + 0.014*\"motif_41\" + 0.013*\"motif_17\"\n",
      "2021-02-22 02:15:01,769 : INFO : topic diff=0.049757, rho=0.301381\n",
      "2021-02-22 02:15:01,771 : DEBUG : bound: at document #0\n",
      "2021-02-22 02:15:01,809 : INFO : -4.988 per-word bound, 31.7 perplexity estimate based on a held-out corpus of 95 documents with 2924 words\n",
      "2021-02-22 02:15:01,809 : INFO : PROGRESS: pass 4, at document #60095/60095\n",
      "2021-02-22 02:15:01,810 : DEBUG : performing inference on a chunk of 95 documents\n",
      "2021-02-22 02:15:01,830 : DEBUG : 95/95 documents converged within 1000 iterations\n",
      "2021-02-22 02:15:01,831 : INFO : optimized alpha [0.05694592, 0.1533857, 0.21286753]\n",
      "2021-02-22 02:15:01,831 : DEBUG : updating topics\n",
      "2021-02-22 02:15:01,832 : INFO : merging changes from 95 documents into a model of 60095 documents\n",
      "2021-02-22 02:15:01,833 : INFO : topic #0 (0.057): 0.048*\"motif_219\" + 0.043*\"motif_10\" + 0.043*\"motif_11\" + 0.043*\"motif_12\" + 0.040*\"motif_9\" + 0.037*\"motif_6\" + 0.033*\"motif_5\" + 0.033*\"motif_8\" + 0.032*\"motif_264\" + 0.026*\"motif_4\"\n",
      "2021-02-22 02:15:01,834 : INFO : topic #1 (0.153): 0.066*\"motif_60\" + 0.051*\"motif_184\" + 0.040*\"motif_37\" + 0.040*\"motif_218\" + 0.037*\"motif_23\" + 0.034*\"motif_42\" + 0.030*\"motif_13\" + 0.029*\"motif_40\" + 0.029*\"motif_166\" + 0.026*\"motif_19\"\n",
      "2021-02-22 02:15:01,835 : INFO : topic #2 (0.213): 0.022*\"motif_62\" + 0.021*\"motif_60\" + 0.017*\"motif_50\" + 0.016*\"motif_49\" + 0.015*\"motif_54\" + 0.015*\"motif_41\" + 0.015*\"motif_126\" + 0.015*\"motif_48\" + 0.015*\"motif_84\" + 0.013*\"motif_93\"\n",
      "2021-02-22 02:15:01,835 : INFO : topic diff=0.205695, rho=0.301381\n",
      "2021-02-22 02:15:01,839 : INFO : Epoch 4: Convergence estimate: 2.504950495049506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 44s, sys: 331 ms, total: 1min 45s\n",
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import logging\n",
    "from gensim.models.callbacks import Callback,PerplexityMetric, ConvergenceMetric, CoherenceMetric\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.DEBUG)\n",
    "convergence_logger = ConvergenceMetric(logger='shell')\n",
    "from gensim.models import LdaModel,LdaMulticore\n",
    "\n",
    "temp = dictionary[0]\n",
    "id2word = dictionary.id2token\n",
    "lda = LdaModel(corpus, id2word=id2word, alpha='auto',chunksize=10000,\n",
    "               eta='auto',num_topics=3, iterations=1000, passes = 5,\n",
    "              minimum_probability=0.0,callbacks=[convergence_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fitting-extreme",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopicDistribution(predictions,ntopics):\n",
    "    topic_count_dict={i:0 for i in range(ntopics)}\n",
    "    ndocs=len(predictions)\n",
    "    for pred in predictions:\n",
    "        top_topic=sorted(pred,key=lambda x:-x[1])[0][0]\n",
    "        topic_count_dict[top_topic]+=1\n",
    "    topic_dist_dict={k:v/ndocs for k,v in topic_count_dict.items()}\n",
    "    return topic_dist_dict\n",
    "\n",
    "def likelihoodMetric(predictions,ntopics):\n",
    "    likelihood=0\n",
    "    P_T=getTopicDistribution(predictions,ntopics)\n",
    "#     print(P_T)\n",
    "    for pred in tqdm(predictions):\n",
    "        P_Xi_M=0\n",
    "        for topic_no,P_Xi_T in pred:\n",
    "            P_Xi_M+=P_Xi_T*P_T[topic_no]\n",
    "        likelihood+=np.log10(P_Xi_M)\n",
    "    print(likelihood)\n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "straight-diagnosis",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "def coherenceMetric_cv(model,dictionary,docs):\n",
    "    cm=CoherenceModel(model=model,dictionary=dictionary ,\n",
    "                      texts=docs, coherence='c_v',processes=30)\n",
    "    coherence = cm.get_coherence()\n",
    "    print(coherence)\n",
    "    return coherence\n",
    "# coherenceMetric_cv(lda,dictionary ,docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "automated-gasoline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.555826726271897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.555826726271897"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "def coherenceMetric_umass(model,dictionary,corpus):\n",
    "    cm = CoherenceModel(model=model, corpus=corpus, \\\n",
    "                        coherence='u_mass',processes=30)\n",
    "    coherence = cm.get_coherence()\n",
    "    print(coherence)\n",
    "    return coherence\n",
    "# coherenceMetric_umass(lda,dictionary ,corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "constitutional-liver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3525572782664838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3525572782664838"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "def coherenceMetric_uci(model,dictionary,docs):\n",
    "    cm=CoherenceModel(model=model,dictionary=dictionary ,\n",
    "                      texts=docs, coherence='c_uci',processes=30,\n",
    "                     window_size =2000)\n",
    "    coherence = cm.get_coherence()\n",
    "    print(coherence)\n",
    "    return coherence\n",
    "# coherenceMetric_uci(lda,dictionary ,docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "turkish-temple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.1017669144749425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-5.1017669144749425"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def perplexityMetric(model,corpus):\n",
    "    perplexity=model.log_perplexity(corpus)\n",
    "    print(perplexity)\n",
    "    return perplexity\n",
    "# perplexityMetric(lda,corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "characteristic-retreat",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def findTopMotifs(predictions,ntopics,data,ntop=5,outdir=None):\n",
    "    pred_topic=[]\n",
    "    for pred in tqdm(predictions):\n",
    "        topic_prob=sorted(pred,key=lambda x:-x[1])\n",
    "#         print(topic_prob)\n",
    "        top_topic=topic_prob[0][0]\n",
    "        pred_topic.append(top_topic)\n",
    "    _data=data.copy()\n",
    "    _data['pred_topic']=pred_topic      \n",
    "    gb=_data[['motif_string','pred_topic']].groupby('pred_topic').\\\n",
    "    agg(lambda x: ','.join(x))\n",
    "    gb['top_motif']=gb['motif_string'].\\\n",
    "    apply(lambda x:Counter(x.split(',')).most_common(ntop))\n",
    "    gb.reset_index(inplace=True)\n",
    "    gb=gb[['pred_topic','top_motif']]\n",
    "    if outdir is not None:\n",
    "        gb.to_csv(f'{outdir}/top{ntop}_motifs_topics_{ntopics}.csv',index=False)\n",
    "    print(gb)\n",
    "    return gb\n",
    "# findTopMotifs(lda,corpus,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "operational-things",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAvgTssDist(predictions,ntopics,data,outdir=None):\n",
    "    pred_topic=[]\n",
    "    for pred in tqdm(predictions):\n",
    "        top_topic=sorted(pred,key=lambda x:-x[1])[0][0]\n",
    "        pred_topic.append(top_topic)\n",
    "    _data=data.copy()\n",
    "    _data['pred_topic']=pred_topic\n",
    "    gb=_data[['Distance to TSS','pred_topic']].groupby('pred_topic').mean()\n",
    "    gb.reset_index(inplace=True)\n",
    "    if outdir is not None:\n",
    "        gb.to_csv(f'{outdir}/avg_tss_dist_topics_{ntopics}.csv',index=False)\n",
    "    print(gb)\n",
    "    return gb\n",
    "# getAvgTssDist(lda,corpus,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-desperate",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Num of Topics = 2\n",
      "\n",
      "Finding likelihood...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60095/60095 [00:18<00:00, 3163.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-15064.758488495485\n",
      "\n",
      "Finding coherence_cv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5225679165253173\n",
      "\n",
      "Finding coherence_umass...\n",
      "-1.5896094769998963\n",
      "\n",
      "Finding coherence_uci...\n",
      "0.4109764283332333\n",
      "\n",
      "Finding perplexity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 280/60095 [00:00<00:21, 2790.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.096255175798838\n",
      "\n",
      "Finding Top Motifs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60095/60095 [00:18<00:00, 3260.85it/s]\n",
      "  0%|          | 229/60095 [00:00<00:26, 2288.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pred_topic                                          top_motif\n",
      "0           0  [(motif_60, 29533), (motif_37, 26686), (motif_...\n",
      "1           1  [(motif_60, 38974), (motif_184, 27939), (motif...\n",
      "\n",
      "Findng avg. distance from TSS per topic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60095/60095 [00:18<00:00, 3254.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pred_topic  Distance to TSS\n",
      "0           0     10336.827239\n",
      "1           1      9386.069989\n",
      "\n",
      "========================================\n",
      "Num of Topics = 3\n",
      "\n",
      "Finding likelihood...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60095/60095 [00:18<00:00, 3291.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-23482.054811504648\n",
      "\n",
      "Finding coherence_cv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5403626272996208\n",
      "\n",
      "Finding coherence_umass...\n",
      "-1.716956873492414\n",
      "\n",
      "Finding coherence_uci...\n",
      "0.4966598396084556\n",
      "\n",
      "Finding perplexity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 361/60095 [00:00<00:16, 3602.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.997750812663312\n",
      "\n",
      "Finding Top Motifs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60095/60095 [00:20<00:00, 2866.28it/s]\n",
      "  1%|          | 335/60095 [00:00<00:18, 3275.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pred_topic                                          top_motif\n",
      "0           0  [(motif_11, 7736), (motif_12, 7563), (motif_10...\n",
      "1           1  [(motif_60, 23369), (motif_62, 15830), (motif_...\n",
      "2           2  [(motif_60, 39484), (motif_184, 26309), (motif...\n",
      "\n",
      "Findng avg. distance from TSS per topic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60095/60095 [00:19<00:00, 3105.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pred_topic  Distance to TSS\n",
      "0           0      9413.750600\n",
      "1           1     13333.580354\n",
      "2           2      5699.994912\n",
      "\n",
      "========================================\n",
      "Num of Topics = 4\n",
      "\n",
      "Finding likelihood...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60095/60095 [00:18<00:00, 3277.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-34443.49925633707\n",
      "\n",
      "Finding coherence_cv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.686070632588859\n",
      "\n",
      "Finding coherence_umass...\n",
      "-1.4632317921022289\n",
      "\n",
      "Finding coherence_uci...\n",
      "0.7455236200065576\n",
      "\n",
      "Finding perplexity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 364/60095 [00:00<00:16, 3631.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.901239691344312\n",
      "\n",
      "Finding Top Motifs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60095/60095 [00:19<00:00, 3090.92it/s]\n",
      "  1%|          | 351/60095 [00:00<00:17, 3506.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pred_topic                                          top_motif\n",
      "0           0  [(motif_60, 18440), (motif_126, 10965), (motif...\n",
      "1           1  [(motif_54, 7565), (motif_60, 6905), (motif_49...\n",
      "2           2  [(motif_60, 35150), (motif_184, 24481), (motif...\n",
      "3           3  [(motif_37, 20622), (motif_23, 19199), (motif_...\n",
      "\n",
      "Findng avg. distance from TSS per topic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60095/60095 [00:18<00:00, 3320.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pred_topic  Distance to TSS\n",
      "0           0     14315.663081\n",
      "1           1     11424.363071\n",
      "2           2      8650.966309\n",
      "3           3      3872.322116\n",
      "\n",
      "========================================\n",
      "Num of Topics = 5\n",
      "\n",
      "Finding likelihood...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60095/60095 [00:18<00:00, 3186.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-38028.7004338297\n",
      "\n",
      "Finding coherence_cv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6608678266683806\n",
      "\n",
      "Finding coherence_umass...\n",
      "-1.5466900928181788\n",
      "\n",
      "Finding coherence_uci...\n",
      "0.7610939054690984\n",
      "\n",
      "Finding perplexity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 341/60095 [00:00<00:17, 3398.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.8402715340708875\n",
      "\n",
      "Finding Top Motifs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60095/60095 [00:17<00:00, 3419.08it/s]\n",
      "  1%|          | 399/60095 [00:00<00:15, 3973.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pred_topic                                          top_motif\n",
      "0           0  [(motif_60, 15227), (motif_219, 10130), (motif...\n",
      "1           1  [(motif_11, 8250), (motif_12, 8061), (motif_10...\n",
      "2           2  [(motif_54, 8345), (motif_62, 6723), (motif_12...\n",
      "3           3  [(motif_60, 32811), (motif_184, 23555), (motif...\n",
      "4           4  [(motif_37, 21641), (motif_23, 20165), (motif_...\n",
      "\n",
      "Findng avg. distance from TSS per topic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60095/60095 [00:19<00:00, 3091.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pred_topic  Distance to TSS\n",
      "0           0     13088.673068\n",
      "1           1     12077.198188\n",
      "2           2     15453.950773\n",
      "3           3      8666.348130\n",
      "4           4      4496.180643\n",
      "\n",
      "========================================\n",
      "Num of Topics = 6\n",
      "\n",
      "Finding likelihood...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60095/60095 [00:21<00:00, 2839.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-43008.298729632115\n",
      "\n",
      "Finding coherence_cv...\n",
      "0.6852262566695272\n",
      "\n",
      "Finding coherence_umass...\n",
      "-1.4966415033929898\n",
      "\n",
      "Finding coherence_uci...\n",
      "0.8133070839086761\n",
      "\n",
      "Finding perplexity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 306/60095 [00:00<00:19, 3059.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.786798035477909\n",
      "\n",
      "Finding Top Motifs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 49466/60095 [00:14<00:03, 3278.05it/s]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "from gensim.models import LdaModel,LdaMulticore\n",
    "\n",
    "outdir='model_output'\n",
    "eval_dict={'num_topics':[],'likelihood':[],'coherence_cv':[],\\\n",
    "          'coherence_umass':[],'coherence_uci':[],'perplexity':[]}\n",
    "temp = dictionary[0]\n",
    "id2word = dictionary.id2token\n",
    "for ntopics in range(2,10):\n",
    "    print('\\n'+'='*40)\n",
    "    print('Num of Topics = '+str(ntopics))\n",
    "    model = LdaModel(corpus, id2word=id2word, alpha='auto',chunksize=10000,\n",
    "                   eta='auto',num_topics=ntopics, iterations=1000, passes = 5,\n",
    "                  minimum_probability=0.0)\n",
    "    \n",
    "    predictions=model.get_document_topics(corpus,minimum_probability=0.0)\n",
    "    print('\\nFinding likelihood...')\n",
    "    likelihood=likelihoodMetric(predictions,ntopics)\n",
    "    print('\\nFinding coherence_cv...')\n",
    "    coherence_cv=coherenceMetric_cv(model,dictionary,docs)\n",
    "    print('\\nFinding coherence_umass...')\n",
    "    coherence_umass=coherenceMetric_umass(model,dictionary ,corpus)\n",
    "    print('\\nFinding coherence_uci...')\n",
    "    coherence_uci=coherenceMetric_uci(model,dictionary,docs)\n",
    "    print('\\nFinding perplexity...')\n",
    "    perplexity=perplexityMetric(model,corpus)\n",
    "    print('\\nFinding Top Motifs...')\n",
    "    findTopMotifs(predictions,ntopics,data,outdir=outdir)\n",
    "    print('\\nFindng avg. distance from TSS per topic...')\n",
    "    getAvgTssDist(predictions,ntopics,data,outdir=outdir)\n",
    "    eval_dict['num_topics'].append(ntopics)\n",
    "    eval_dict['likelihood'].append(likelihood)\n",
    "    eval_dict['coherence_cv'].append(coherence_cv)\n",
    "    eval_dict['coherence_umass'].append(coherence_umass)\n",
    "    eval_dict['coherence_uci'].append(coherence_uci)\n",
    "    eval_dict['perplexity'].append(perplexity)\n",
    "eval_df=pd.DataFrame(eval_dict)\n",
    "eval_df.to_csv(f'{outdir}/metrics.csv',index=False)\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-marsh",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
